import os
import h5py
import pyBigWig
import numpy as np
import tqdm
import click

def ask_to_continue():
    resp = input("Continue? [y|N]: ")
    if resp.lower() in ("y", "yes"):
        return
    else:
        raise Exception("Aborted")


def fetch_bigwig_paths(base_path, tf_name, tf_cont_mapping_path):
    """
    Reads in the set of BigWig paths corresponding to TF-ChIPseq profiles and
    control profiles. These BigWigs should be generated by
    `generate_ENCODE_profile_labels.sh`. This function performs error-checking
    to ensure that the proper files are there under `base_path`.
    Arguments:
        `base_path`: path containing the BigWig profiles
        `tf_name`: name of the TF (i.e. the profiles for the TF-ChIPseq runs
            should start with this name)
        `tf_cont_mapping_path`: path to TSV mapping TF-ChIPseq experiment IDs
            to their matched control ChIPseq experiment IDs
    Returns a list of pairs, where each pair is the BigWig tracks for the
    negative and positive strands (in that order). The first half of this
    list-of-pairs is for the TF-ChIPseq profiles, and the second half are the
    corresponding control profiles. The BigWigs are ordered such that the
    TF-ChIPseq experiment IDs are in sorted order, and the control experiment
    IDs are in a parallel matched order.
    """
    tf_cont_mapping = {}
    with open(tf_cont_mapping_path, "r") as f:
        for line in f:
            tokens = line.strip().split("\t")
            tf_cont_mapping[tokens[0]] = tokens[1]  # Map TF ID to control ID

    bigwig_list = [
        item for item in os.listdir(base_path) if item.endswith(".bw")
    ]

    # Read in names, organizing into
    # tf_name/control : experiment/cell line : strand
    bigwig_dict = {}
    for name in bigwig_list:
        tokens = name[:-3].split("_")
        assert len(tokens) == 4, \
            "Found BigWig of improperly formatted name: %s" % name
        cond = tokens[0]
        expid_cline = (tokens[1], tokens[2])
        strand = tokens[3]
        assert cond in (tf_name, "control"), \
            "Found BigWig not of type %s or control" % tf_name
        assert strand in ("neg", "pos"), "Found BigWig of strand other than pos/neg"
    
        if cond not in bigwig_dict:
            bigwig_dict[cond] = {}
        if expid_cline not in bigwig_dict[cond]:
            bigwig_dict[cond][expid_cline] = {}
        assert strand not in bigwig_dict[cond][expid_cline], \
            "Found duplicate BigWig for %s, %s, %s" % \
            (cond, expid_cline, strand)
        bigwig_dict[cond][expid_cline][strand] = os.path.join(base_path, name)

    # Get list of TF-ChIPseq experiment IDs/cell lines with matched controls
    tf_expids, tf_expid_clines = [], []
    for expid_cline in sorted(bigwig_dict[tf_name].keys(), key=lambda p: p[0]):
        expid = expid_cline[0]
        if expid not in tf_cont_mapping.keys():
            print(
                "Did not matching control for TF-ChIPseq experiment %s" % \
                expid_cline
            )
            ask_to_continue()
            continue
        tf_expids.append(expid)
        tf_expid_clines.append(expid_cline)

    assert len(tf_expids) == len(set(tf_expids)), \
        "Found duplicate TF-ChIPseq experiment IDs"

    # Generate list of paired paths
    tf_paths, cont_paths = [], []
    for i in range(len(tf_expids)):
        tf_expid, tf_expid_cline = tf_expids[i], tf_expid_clines[i]
        cont_expid = tf_cont_mapping[tf_expid]
        cont_expid_cline = [
            key for key in bigwig_dict["control"] if key[0] == cont_expid
        ]
        if len(cont_expid_cline) != 1:
            print(
                "Did not find exactly 1 experiment for mapped control %s" % \
                cont_expid
            )
            ask_to_continue()
            continue
        tf_strand_dict = bigwig_dict[tf_name][tf_expid_cline]
        tf_paths.append([tf_strand_dict["neg"], tf_strand_dict["pos"]])
        cont_strand_dict = bigwig_dict["control"][cont_expid_cline[0]]
        cont_paths.append([cont_strand_dict["neg"], cont_strand_dict["pos"]])

    print("Found the following experiments/cell lines:")
    for i in range(len(tf_paths)):
        print("%s\t%s" % (
            os.path.basename(tf_paths[i][0]), os.path.basename(cont_paths[i][0])
        ))
        print("%s\t%s" % (
            os.path.basename(tf_paths[i][1]), os.path.basename(cont_paths[i][1])
        ))
        print()
    print("Total pairs: %d" % len(tf_paths))
    ask_to_continue()

    return tf_paths + cont_paths


def create_hdf5(
    bigwig_paths, chrom_sizes_path, out_path, chunk_size, batch_size=100
):
    """
    Creates an HDF5 file containing all BigWig tracks.
    Arguments:
        `bigwig_paths`: a list of pairs of paths, as returned by
            `fetch_bigwig_paths`
        `chrom_sizes_path`: path to canonical chromosome sizes
        `out_path`: where to write the HDF5
        `chunk_size`: chunk size to use in HDF5 along the chromosome size
            dimension; this is recommended to be the expected size of the
            queries made
        `batch_size`: number of chunks to write at a time
    This creates an HDF5 file, containing a dataset for each chromosome. Each
    dataset will be a large array of shape L x 2T x 2, where L is the length of
    the chromosome, T is the number of tasks (i.e. T experiment/cell lines, one
    for each TF and one for matched control), 2 is for both strands. The HDF5
    will also contain a dataset which has the paths to the corresponding source
    BigWigs, stored as a 2T x 2 array of paths.
    """
    bigwig_readers = [
        [pyBigWig.open(path1), pyBigWig.open(path2)]
        for path1, path2 in bigwig_paths
    ]
   
    # Read in chromosome sizes
    with open(chrom_sizes_path, "r") as f:
        chrom_sizes = {}
        for line in f:
            tokens = line.strip().split("\t")
            chrom_sizes[tokens[0]] = int(tokens[1])
   
    # Convert batch size to be in terms of rows, not number of chunks
    batch_size = batch_size * chunk_size

    with h5py.File(out_path, "w") as f:
        # Store source paths
        f.create_dataset("bigwig_paths", data=np.array(bigwig_paths, dtype="S"))
        for chrom in sorted(chrom_sizes.keys()):
            chrom_size = chrom_sizes[chrom]
            num_batches = int(np.ceil(chrom_size / batch_size))
            chrom_dset = f.create_dataset(
                chrom, (chrom_size, len(bigwig_paths), 2), dtype="f",
                compression="gzip", chunks=(chunk_size, len(bigwig_paths), 2)
            )
            for i in tqdm.trange(num_batches, desc=chrom):
                start = i * batch_size
                end = min(chrom_size, (i + 1) * batch_size)

                values = np.stack([
                    np.stack([
                        np.nan_to_num(reader1.values(chrom, start, end)),
                        np.nan_to_num(reader2.values(chrom, start, end))
                    ], axis=1) for reader1, reader2 in bigwig_readers
                ], axis=1)

                chrom_dset[start : end] = values

@click.command()
@click.option(
    "--tf-name", "-t", required=True,
    help="Name of TF, needs to match prefix of TF-ChIPseq BigWig files"
)
@click.option(
    "--base-path", "-b", default=None,
    help="Path to directory containing BigWigs; defaults to /users/amtseng/tfmodisco/data/interim/ENCODE/{tf_name}/"
)
@click.option(
    "--tf-cont-mapping-path", "-m", default=None,
    help="Path to mapping between TF-ChIPseq and control ChIPseq experiment IDs; defaults to /users/amtseng/tfmodisco/data/raw/ENCODE/{tf_name}/tf_cont_mapping.tsv"
)
@click.option(
    "--chrom-sizes-path", "-c",
    default="/users/amtseng/genomes/hg38.canon.chrom.sizes",
    help="Path to canonical chromosome sizes"
)
@click.option(
    "--out-path", "-o", default=None,
    help="Destination for new HDF5; defaults to /users/amtseng/tfmodisco/data/processed/ENCODE/labels/{tf_name}/{tf_name}_profiles.h5"
)
@click.option(
    "--chunk-size", "-s", default=1500,
    help="Chunk size along chromosome length dimension for HDF5"
)
def main(
    tf_name, base_path, tf_cont_mapping_path, chrom_sizes_path, out_path,
    chunk_size
):
    """
    Converts TF-ChIPseq and control ChIPseq profile BigWigs into an HDF5 file.
    HDF5 has separate datasets for each chromosome. Each chromosome's dataset
    is stored as an L x 2T x 2 array, where L is the size of the chromosome,
    T is the number of matched experiments (i.e. tasks), and 2 is for each
    strand. The dataset under the key `bigwig_paths` stores the paths for the
    source BigWigs.
    """
    if not base_path: 
        base_path = "/users/amtseng/tfmodisco/data/interim/ENCODE/%s" % tf_name
    if not tf_cont_mapping_path:
        tf_cont_mapping_path = \
            "/users/amtseng/tfmodisco/data/raw/ENCODE/%s/tf_cont_mapping.tsv" % tf_name
    if not out_path:
        out_path = \
            "/users/amtseng/tfmodisco/data/processed/ENCODE/labels/%s/%s_profiles.h5" % (tf_name, tf_name)
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    bigwig_paths = fetch_bigwig_paths(base_path, tf_name, tf_cont_mapping_path)
    print("Found %d matched experiments/tasks" % (len(bigwig_paths) // 2))
    create_hdf5(bigwig_paths, chrom_sizes_path, out_path, chunk_size)


if __name__ == "__main__":
    main()
