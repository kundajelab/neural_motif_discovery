import feature.util as feature_util
import h5py
import os
import numpy as np
import tqdm
from collections import OrderedDict
import modisco
import click
import tqdm

def prepare_tfm_inputs(
    shap_score_hdf5_path, reference_fasta, padded_size, score_type="profile"
):
    """
    Imports the Shap scores generated/saved by `generate_scores.py`, and returns
    the actual and hypothetical importance scores.
    Arguments:
        `shap_score_hdf5_path`: path to HDF5 of Shap scores generated by
            `generate_scores.py`
        `reference_fasta`: path to reference fasta for importing sequences
        `padded_size`: size of peaks used for generating importance scores, and
            the size of sequence to use for TF-MoDISco
        `score_type`: one of "profile" or "count", determines which set of
            importance scores to return
    Returns the hypothetical importance scores, actual importance scores, and
    corresponding one-hot encoded input sequences. The scores are returned as
    an OrderedDict. Scores and sequences have shape N x P x 4, where N is the
    number of explained sequences, and P is the padded size.
    """
    assert score_type in ("profile", "count")

    score_reader = h5py.File(shap_score_hdf5_path, "r")

    # Maps coordinates to 1-hot encoded sequence
    coords_to_seq = feature_util.CoordsToSeq(
        reference_fasta, center_size_to_use=padded_size
    )

    # Get shapes; we'll need to cut off inputs outside the central `padded_size`
    num_seqs, input_length, _ = score_reader["prof_scores"].shape
    center_start = (input_length // 2) - (padded_size // 2)
    center_end = center_start + padded_size
   
    # For batching up data loading
    batch_size = 1000
    num_batches = int(np.ceil(num_seqs / batch_size))

    # Read in hypothetical scores, cutting off everything outside central `padded_size`
    hyp_scores = np.empty((num_seqs, padded_size, 4), dtype=float)
    if score_type == "profile":
        scores = score_reader["prof_scores"]
    else:
        scores = score_reader["count_scores"]
    for i in tqdm.trange(num_batches, desc="Importing hypothetical scores"):
        s, e = i * batch_size, (i + 1) * batch_size
        hyp_scores[s : e, :, :] = scores[s : e, center_start : center_end, :]
    
    # Read in coordinates and compute 1-hot encoding
    coords = np.empty((num_seqs, 3), dtype=object)
    coords[:, 0] = score_reader["coords_chrom"][:].astype(str)
    coords[:, 1] = score_reader["coords_start"][:]
    coords[:, 2] = score_reader["coords_end"][:]
    
    input_seqs = np.empty((num_seqs, padded_size, 4), dtype=float)
    
    for i in tqdm.trange(num_batches, desc="Computing 1-hot encoded sequences"):
        s, e = i * batch_size, (i + 1) * batch_size
        input_seqs[s : e, :, :] = coords_to_seq(coords[s : e])
    
    # Compute actual scores
    act_scores = hyp_scores * input_seqs

    # Put scores into OrderedDict
    task_to_hyp_scores, task_to_act_scores = OrderedDict(), OrderedDict()
    task_to_hyp_scores["task0"] = hyp_scores
    task_to_act_scores["task0"] = act_scores

    return task_to_hyp_scores, task_to_act_scores, input_seqs


@click.command()
@click.option(
    "--reference-fasta", "-r", default="/users/amtseng/genomes/hg38.fasta",
    help="Path to reference genome Fasta"
)
@click.option(
    "--padded-size", "-s", default=400,
    help="Size of input sequences to compute explanations for"
)
@click.option(
    "--score-type", "-t", default="profile",
    type=click.Choice(["profile", "count"], case_sensitive=False)
)
@click.option(
    "--outfile", "-o", required=True,
    help="Where to store the hdf5 with TF-MoDISco results"
)
@click.argument("shap_score_hdf5_path", nargs=1)
def main(
    shap_score_hdf5_path, reference_fasta, padded_size, score_type, outfile
):
    """
    Takes the set of importance scores generated by `generate_scores.py` and
    runs TF-MoDISco on them.
    """
    task_to_hyp_scores, task_to_act_scores, input_seqs = prepare_tfm_inputs(
        shap_score_hdf5_path, reference_fasta, padded_size,
        score_type=score_type
    )

    # Construct workflow pipeline
    null_per_pos_scores = modisco.coordproducers.LaplaceNullDist(
        num_to_samp=5000
    )
    tfm_workflow = modisco.tfmodisco_workflow.workflow.TfModiscoWorkflow(
    	sliding_window_size=15,
    	flank_size=5,
    	target_seqlet_fdr=0.15,
    	seqlets_to_patterns_factory=modisco.tfmodisco_workflow.seqlets_to_patterns.TfModiscoSeqletsToPatternsFactory(
    	    trim_to_window_size=15,
    	    initial_flank_to_add=5,
    	    kmer_len=5,
    	    num_gaps=1,
    	    num_mismatches=0,
    	    final_min_cluster_size=60
    	)
    )

    # Move to output directory to do work
    cwd = os.getcwd()
    os.chdir(os.path.dirname(outfile))

    tfm_results = tfm_workflow(
        task_names=list(task_to_act_scores.keys()),
        contrib_scores=task_to_act_scores,
        hypothetical_contribs=task_to_hyp_scores,
        one_hot=input_seqs,
        null_per_pos_scores = null_per_pos_scores
    )

    os.chdir(cwd)
    print("Saving results to %s" % outfile)
    with h5py.File(outfile, "w") as f:
        tfm_results.save_hdf5(f)


if __name__ == "__main__":
    main()
