apiVersion: batch/v1
kind: Job
metadata:
  name: run-hypertune-{tflower}-task{task}
spec:
  completions: 20
  parallelism: 20
  template:
    spec:
      containers:
      - name: run-hypertune-{tflower}-task{task}
        image: kundajelab/genome-keras-sacred:gcp
        imagePullPolicy: Always
        resources:
          requests:
            cpu: 7
            memory: 25Gi
            nvidia.com/gpu: 1
          limits:
            cpu: 7
            memory: 25Gi
            nvidia.com/gpu: 1
        command:
        - /bin/bash
        - -c
        args:
        - gsutil cp gs://gbsc-gcp-lab-kundaje-user-amtseng/run_hyperparam.py ~;
          cd ~;
          MODEL_DIR={modeldir} python run_hyperparam.py -t profile -f /users/amtseng/tfmodisco/data/processed/ENCODE/config/{tf}/{tf}_training_paths.json -c /users/amtseng/tfmodisco/data/processed/ENCODE/config/{tf}/{tf}_config.json -p /users/amtseng/tfmodisco/data/processed/ENCODE/hyperparam_specs/counts_loss_learn_rate.json -s /users/amtseng/tfmodisco/data/processed/ENCODE/chrom_splits.json -k {foldnum} -n 1 {taskarg} train.num_epochs=5;
      restartPolicy: Never
  backoffLimit: 0
