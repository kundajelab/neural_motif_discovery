{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric(models_path, metric_extract_func, metric_compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    where the metric value is fetched by `metric_extract_func`. This function must\n",
    "    take the imported metrics JSON and return the (scalar) value to use for\n",
    "    comparison. The best metric value is determiend by `metric_compare_func`, which\n",
    "    must take in two arguments, and return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the value associated with that run, and a list of\n",
    "    all the values used for comparison.\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_val, all_vals = None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            val = metric_extract_func(metrics[run_num])\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to extract metric for run %s\" % run_num)\n",
    "            continue\n",
    "        all_vals[run_num] = val\n",
    "        if best_val is None or metric_compare_func(val, best_val):\n",
    "            best_val, best_run = val, run_num\n",
    "    return best_run, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Was not able to extract metric for run 24\n",
      "Warning: Was not able to extract metric for run 13\n",
      "Best run: 1\n",
      "Associated value: 153.54793947399247\n"
     ]
    }
   ],
   "source": [
    "models_path = \"/users/amtseng/tfmodisco/models/trained_models/SPI1/\"\n",
    "best_run, best_val, all_vals = get_best_metric(\n",
    "    models_path,\n",
    "    lambda metrics: np.mean(metrics[\"summit_prof_nll\"][\"values\"][0]),\n",
    "    lambda x, y: x < y\n",
    ")\n",
    "print(\"Best run: %s\" % best_run)\n",
    "print(\"Associated value: %s\" % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 153.54793947399247\n",
      "2 226.16465030266193\n",
      "3 154.67320674900674\n",
      "4 226.16370786839664\n",
      "5 226.16432397203155\n",
      "6 166.8852087779198\n",
      "7 153.92978690030122\n",
      "8 226.16666338690862\n",
      "9 156.80632273905965\n",
      "10 162.54583435052035\n",
      "11 226.1755197358771\n",
      "12 157.01017634035634\n",
      "14 154.1111828598224\n",
      "15 226.16998388074\n",
      "16 165.55251039109362\n",
      "17 155.17937774691393\n",
      "18 157.66106714824517\n",
      "19 159.91977544091895\n",
      "20 154.5057103706613\n",
      "21 226.1637362810328\n",
      "22 153.91011901812507\n",
      "23 153.69814584858167\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(all_vals.keys(), key=lambda x: int(x)):\n",
    "    print(key, all_vals[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
