{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import model.util as model_util\n",
    "import model.profile_models as profile_models\n",
    "import model.train_profile_model as train_profile_model\n",
    "import model.profile_performance as profile_performance\n",
    "import feature.util as feature_util\n",
    "import feature.make_profile_dataset as make_profile_dataset\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the peak BEDs and profile BigWigs\n",
    "base_path = \"/users/amtseng/tfmodisco/data/interim/ENCODE/\"\n",
    "\n",
    "peaks_bed = os.path.join(base_path, \"SPI1/SPI1_ENCSR000BGQ_GM12878_train_peakints.bed.gz\")\n",
    "\n",
    "prof_bigwigs = [\n",
    "    (os.path.join(base_path, e_1), os.path.join(base_path, e_2)) \\\n",
    "    for e_1, e_2 in [\n",
    "        (\"SPI1/SPI1_ENCSR000BGQ_GM12878_neg.bw\",\n",
    "        \"SPI1/SPI1_ENCSR000BGQ_GM12878_pos.bw\"),\n",
    "        (\"SPI1/SPI1_ENCSR000BGW_K562_neg.bw\",\n",
    "        \"SPI1/SPI1_ENCSR000BGW_K562_pos.bw\"),\n",
    "        (\"SPI1/SPI1_ENCSR000BIJ_GM12891_neg.bw\",\n",
    "        \"SPI1/SPI1_ENCSR000BIJ_GM12891_pos.bw\"),\n",
    "        (\"SPI1/SPI1_ENCSR000BUW_HL-60_neg.bw\",\n",
    "        \"SPI1/SPI1_ENCSR000BUW_HL-60_pos.bw\"),\n",
    "        (\"SPI1/control_ENCSR000BGH_GM12878_neg.bw\",\n",
    "        \"SPI1/control_ENCSR000BGH_GM12878_pos.bw\"),\n",
    "        (\"SPI1/control_ENCSR000BGG_K562_neg.bw\",\n",
    "        \"SPI1/control_ENCSR000BGG_K562_pos.bw\"),\n",
    "        (\"SPI1/control_ENCSR000BIH_GM12891_neg.bw\",\n",
    "        \"SPI1/control_ENCSR000BIH_GM12891_pos.bw\"),\n",
    "        (\"SPI1/control_ENCSR000BVU_HL-60_neg.bw\",\n",
    "        \"SPI1/control_ENCSR000BVU_HL-60_pos.bw\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "num_tasks = int(len(prof_bigwigs) / 2)\n",
    "# Path to saved model\n",
    "model_path = \"/users/amtseng/tfmodisco/models/trained_models/SPI1_nocounts_nohyperparam/1/model_ckpt_epoch_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "reference_fasta = \"/users/amtseng/genomes/hg38.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/hg38.canon.chrom.sizes\"\n",
    "input_length = 1346\n",
    "profile_length = 1000\n",
    "num_tasks = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "custom_objects = {\n",
    "    \"kb\": keras.backend,\n",
    "    \"profile_loss\": train_profile_model.get_profile_loss_function(num_tasks, profile_length),\n",
    "    \"count_loss\": train_profile_model.get_count_loss_function(num_tasks)\n",
    "}\n",
    "model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Use classes from `make_profile_dataset` to prepare positive and negative inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps coordinates to 1-hot encoded sequence\n",
    "coords_to_seq = feature_util.CoordsToSeq(reference_fasta, center_size_to_use=input_length)\n",
    "\n",
    "# Maps coordinates to profiles, in order of BigWigs given in `prof_bigwigs`\n",
    "coords_to_vals_list = [\n",
    "    (\n",
    "        make_profile_dataset.CoordsToVals(path_1, profile_length),\n",
    "        make_profile_dataset.CoordsToVals(path_2, profile_length)\n",
    "    )\n",
    "    for path_1, path_2 in prof_bigwigs\n",
    "]\n",
    "def coords_to_profs(coords):\n",
    "    return np.stack([\n",
    "        np.stack([ctv_1(coords), ctv_2(coords)], axis=2)\n",
    "        for ctv_1, ctv_2 in coords_to_vals_list\n",
    "    ], axis=1)\n",
    "# Maps many coordinates to inputs sequences and profiles for the network\n",
    "def coords_to_network_inputs(coords):\n",
    "    input_seq = coords_to_seq(coords)\n",
    "    profs = coords_to_profs(coords)\n",
    "    return input_seq, profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import set of positive peaks\n",
    "pos_coords_table = pd.read_csv(peaks_bed, sep=\"\\t\", header=None, compression=\"gzip\")\n",
    "\n",
    "# Negative coordinate sampling\n",
    "neg_coord_sampler = make_profile_dataset.GenomeIntervalSampler(chrom_sizes, input_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and plotting profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_coords(coords):\n",
    "    \"\"\"\n",
    "    Fetches the necessary data from the given coordinate and runs it through the\n",
    "    network. Returns the network predictions AND the true values from the dataset.\n",
    "    The returned predicted profiles are in terms of log probabilities, and the\n",
    "    returned predicted counts are also log. Returned values are all NumPy arrays.\n",
    "    \"\"\"\n",
    "    input_seq, profiles = coords_to_network_inputs(coords)\n",
    "    \n",
    "    true_profs = profiles[:, :num_tasks, :, :]\n",
    "    cont_profs = profiles[:, num_tasks:, :, :]\n",
    "    true_counts = np.sum(true_profs, axis=2)\n",
    "\n",
    "    # Run through the model\n",
    "    logit_pred_profs, log_pred_counts = model.predict([input_seq, cont_profs])\n",
    "    \n",
    "    # Convert logit profile predictions to probabilities\n",
    "    log_pred_profs = profile_models.profile_logits_to_log_probs(\n",
    "        logit_pred_profs\n",
    "    )\n",
    "    \n",
    "    return log_pred_profs, log_pred_counts, true_profs, true_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(pred_profs, true_profs, normalize=True, title=None):\n",
    "    \"\"\"\n",
    "    Plots the given profiles.\n",
    "    Both arguments should be T x O x 2 NumPy arrays, where the subarrays are the\n",
    "    tracks for the plus and minus strand, for each task.\n",
    "    If `normalize` is True, normalize the profiles to be probabilities (i.e.\n",
    "    each track sums to 1)\n",
    "    \"\"\"\n",
    "    pred_profs, true_profs = np.squeeze(pred_profs), np.squeeze(true_profs)\n",
    "    num_tasks, prof_length = pred_profs.shape[0], pred_profs.shape[1]\n",
    "    if normalize:\n",
    "        pred_profs = pred_profs / np.expand_dims(np.sum(pred_profs, axis=1), axis=1)\n",
    "        true_profs = true_profs / np.expand_dims(np.sum(true_profs, axis=1), axis=1)\n",
    "    fig, ax = plt.subplots(num_tasks, figsize=(15, 20))\n",
    "    for i in range(num_tasks):\n",
    "        ax[i].plot(true_profs[i,:,0], color=\"royalblue\", alpha=0.5)\n",
    "        ax[i].plot(-true_profs[i,:,1], color=\"goldenrod\", alpha=0.5)\n",
    "        ax[i].plot(pred_profs[i,:,0], color=\"darkslateblue\")\n",
    "        ax[i].plot(-pred_profs[i,:,1], color=\"darkorange\")\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some positive coordinates\n",
    "pos_coords_table.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some negative coordinates\n",
    "neg_coord_sampler.sample_intervals(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred_profs, log_pred_counts, true_profs, true_counts = predict_coords([(\"chr3\", 138875547, 138876547)])\n",
    "pred_prof_probs = np.exp(log_pred_profs)\n",
    "true_prof_probs = true_profs / np.sum(true_profs, axis=2, keepdims=True)\n",
    "plot_profiles(pred_prof_probs, true_prof_probs, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred_profs, log_pred_counts, true_profs, true_counts = predict_coords([(\"chr3\", 130377839, 130378839)])\n",
    "pred_prof_probs = np.exp(log_pred_profs)\n",
    "true_prof_probs = true_profs / np.sum(true_profs, axis=2, keepdims=True)\n",
    "plot_profiles(pred_prof_probs, true_prof_probs, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred_profs, log_pred_counts, true_profs, true_counts = predict_coords([(\"chr1\", 1000, 2000)])\n",
    "pred_prof_probs = np.exp(log_pred_profs)\n",
    "true_prof_probs = true_profs / np.sum(true_profs, axis=2, keepdims=True)\n",
    "plot_profiles(pred_prof_probs, true_prof_probs, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
