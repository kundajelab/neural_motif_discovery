{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import model.profile_models as profile_models\n",
    "import model.train_profile_model as train_profile_model\n",
    "import model.spline as spline\n",
    "import feature.util as feature_util\n",
    "import feature.make_profile_dataset as make_profile_dataset\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import json\n",
    "import pyBigWig\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook(range(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tasks = 9\n",
    "# fold_num = 8\n",
    "# run_num = 2\n",
    "# epoch_num = 7\n",
    "# files_spec_path = \"/users/amtseng/tfmodisco/data/processed/ENCODE/config/{0}/{0}_training_paths.json\".format(tf_name)\n",
    "# # model_path = \"/users/amtseng/tfmodisco/models/trained_models/%s_fold%d/%d/model_ckpt_epoch_%d.h5\" % (tf_name, fold_num, run_num, epoch_num)\n",
    "\n",
    "# model_path = \"/users/amtseng/tfmodisco/models/trained_models/MAFK_finetune/tasks_separate_twoconv_univspline_concatlater/54/model_ckpt_epoch_7.h5\"\n",
    "# # model_path = \"/users/amtseng/tfmodisco/models/trained_models/MAFK_finetune/tasks_separate_twoconv_univspline/27/model_ckpt_epoch_15.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_name = \"SPI1\"\n",
    "num_tasks = 4\n",
    "fold_num = 7\n",
    "\n",
    "files_spec_path = \"/users/amtseng/tfmodisco/data/processed/ENCODE/config/{0}/{0}_training_paths.json\".format(tf_name)\n",
    "# model_path = \"/users/amtseng/tfmodisco/models/trained_models/SPI1_fold7/3/model_ckpt_epoch_9.h5\"\n",
    "model_path = \"/users/amtseng/tfmodisco/models/trained_models/SPI1_finetune/tasks_separate_twoconv_univspline_concatlater/23/model_ckpt_epoch_6.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the files and model, and some constants\n",
    "reference_fasta = \"/users/amtseng/genomes/hg38.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/hg38.canon.chrom.sizes\"\n",
    "chrom_splits_json = \"/users/amtseng/tfmodisco/data/processed/ENCODE/chrom_splits.json\"\n",
    "input_length = 1346\n",
    "profile_length = 1000\n",
    "\n",
    "mappability_path = \"/users/amtseng/tfmodisco/data/processed/mappability/hg38.k24.umap.bw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the file specs\n",
    "with open(files_spec_path, \"r\") as f:\n",
    "    files_spec = json.load(f)\n",
    "peaks_beds = files_spec[\"peak_beds\"]\n",
    "profile_hdf5 = files_spec[\"profile_hdf5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chromosome sets\n",
    "with open(chrom_splits_json, \"r\") as f:\n",
    "    chrom_splits = json.load(f)\n",
    "split = chrom_splits[str(fold_num)]\n",
    "train_chroms, val_chroms, test_chroms = split[\"train\"], split[\"val\"], split[\"test\"]\n",
    "all_chroms = train_chroms + val_chroms + test_chroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "custom_objects = {\n",
    "    \"kb\": keras.backend,\n",
    "    \"profile_loss\": train_profile_model.get_profile_loss_function(num_tasks, profile_length),\n",
    "    \"count_loss\": train_profile_model.get_count_loss_function(num_tasks),\n",
    "    \"SplineWeight1D\": spline.SplineWeight1D\n",
    "}\n",
    "model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Use classes from `make_profile_dataset` to prepare positive and negative inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps coordinates to 1-hot encoded sequence\n",
    "coords_to_seq = feature_util.CoordsToSeq(reference_fasta, center_size_to_use=input_length)\n",
    "\n",
    "# Maps coordinates to profiles\n",
    "coords_to_vals = make_profile_dataset.CoordsToVals(profile_hdf5, profile_length)\n",
    "\n",
    "# Maps many coordinates to inputs sequences and profiles for the network\n",
    "def coords_to_network_inputs(coords):\n",
    "    input_seq = coords_to_seq(coords)\n",
    "    profs = coords_to_vals(coords)\n",
    "    return input_seq, np.swapaxes(profs, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import set of positive peaks\n",
    "pos_coords = []\n",
    "for task_index in range(num_tasks):\n",
    "    pos_coords_table = pd.read_csv(peaks_beds[task_index], sep=\"\\t\", header=None, compression=\"gzip\")\n",
    "    pos_coords_table = pos_coords_table[pos_coords_table[0].isin(all_chroms)]\n",
    "    pos_coords.append(pos_coords_table.values[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappability of regions\n",
    "mappability_reader = pyBigWig.open(mappability_path, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_coords(coords):\n",
    "    \"\"\"\n",
    "    Fetches the necessary data from the given coordinate and runs it through the\n",
    "    network. Returns the network predictions AND the true values from the dataset.\n",
    "    The returned predicted profiles are in terms of log probabilities, and the\n",
    "    returned predicted counts are also log. Returned values are all NumPy arrays.\n",
    "    \"\"\"\n",
    "    input_seq, profiles = coords_to_network_inputs(coords)\n",
    "    \n",
    "    true_profs = profiles[:, :num_tasks, :, :]\n",
    "    cont_profs = profiles[:, num_tasks:, :, :]\n",
    "    true_counts = np.sum(true_profs, axis=2)\n",
    "\n",
    "    # Run through the model\n",
    "    logit_pred_profs, log_pred_counts = model.predict([input_seq, cont_profs])\n",
    "    \n",
    "    # Convert logit profile predictions to log probabilities\n",
    "    log_pred_profs = profile_models.profile_logits_to_log_probs(\n",
    "        logit_pred_profs\n",
    "    )\n",
    "    \n",
    "    return log_pred_profs, log_pred_counts, true_profs, true_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappability(coords):\n",
    "    \"\"\"\n",
    "    From a B x 3 object array of coordinates, gets the mappability of the region,\n",
    "    by taking the average mappability within each interval. Returns a B-array\n",
    "    of mappability values.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        np.mean(np.nan_to_num(mappability_reader.values(row[0], row[1], row[2])))\n",
    "        for row in coords\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for task_index in range(num_tasks):\n",
    "    print(\"Predicting on task %d\" % task_index)\n",
    "    num_coords = len(pos_coords[task_index])\n",
    "    log_pred_profs = np.empty((num_coords, profile_length, 2))\n",
    "    log_pred_counts = np.empty((num_coords, 2))\n",
    "    true_profs = np.empty((num_coords, profile_length, 2))\n",
    "    true_counts = np.empty((num_coords, 2))\n",
    "    mappability = np.empty((num_coords,))\n",
    "\n",
    "    batch_size = 128\n",
    "    num_batches = int(np.ceil(num_coords / batch_size))\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        b_log_pred_profs, b_log_pred_counts, b_true_profs, b_true_counts =\\\n",
    "            predict_coords(pos_coords[task_index][batch_slice])\n",
    "        b_mappability = get_mappability(pos_coords[task_index][batch_slice])\n",
    "\n",
    "        log_pred_profs[batch_slice] = b_log_pred_profs[:, task_index]\n",
    "        log_pred_counts[batch_slice] = b_log_pred_counts[:, task_index]\n",
    "        true_profs[batch_slice] = b_true_profs[:, task_index]\n",
    "        true_counts[batch_slice] = b_true_counts[:, task_index]\n",
    "        mappability[batch_slice] = b_mappability\n",
    "        \n",
    "    preds.append({\n",
    "        \"log_pred_profs\": log_pred_profs,\n",
    "        \"log_pred_counts\": log_pred_counts,\n",
    "        \"true_profs\": true_profs,\n",
    "        \"true_counts\": true_counts,\n",
    "        \"mappability\": mappability\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View count correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for task_index in range(num_tasks):\n",
    "    log_true_counts = np.log(preds[task_index][\"true_counts\"] + 1)\n",
    "    log_pred_counts = preds[task_index][\"log_pred_counts\"]\n",
    "    mappability = preds[task_index][\"mappability\"]\n",
    "    mappability = np.stack([mappability, mappability], axis=1)  # Tile into N x 2 to match counts\n",
    "    pos_coords_chroms = pos_coords[task_index][:, 0]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(40, 10))\n",
    "    for i, (desc, chroms) in enumerate([\n",
    "        (\"train\", train_chroms), (\"val\", val_chroms), (\"test\", test_chroms), (\"all\", all_chroms)\n",
    "    ]):\n",
    "        mask = np.isin(pos_coords_chroms, chroms)\n",
    "        # Plot counts scatterplot of the specified index, treating strands separately\n",
    "        ax[i].scatter(\n",
    "            np.ravel(log_true_counts[mask]), np.ravel(log_pred_counts[mask]),\n",
    "            c=np.ravel(mappability[mask]), cmap=cm.plasma, alpha=0.1,\n",
    "        )\n",
    "        \n",
    "        # Draw y = x, but don't change axes\n",
    "        xlims = ax[i].get_xlim()\n",
    "        ylims = ax[i].get_ylim()\n",
    "        min_limit, max_limit = np.min([xlims, ylims]), np.max([xlims, ylims])\n",
    "        ax[i].plot([min_limit, max_limit], [min_limit, max_limit], color=\"black\") \n",
    "        ax[i].set_xlim(xlims)\n",
    "        ax[i].set_ylim(ylims)\n",
    "\n",
    "        ax[i].set_xlabel(\"Log true counts\")\n",
    "        ax[i].set_ylabel(\"Log predicted counts\")\n",
    "        ax[i].set_title(\"Count predictions of task %d on %s chromosomes\" % (task_index, desc))\n",
    "    fig.colorbar(cm.ScalarMappable(norm=colors.Normalize(), cmap=cm.plasma), ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
