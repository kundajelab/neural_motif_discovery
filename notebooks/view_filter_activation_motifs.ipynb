{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[Motifs](#motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import deeplift.visualization.viz_sequence as viz_sequence\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pyfaidx\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "filter_activations_path = os.environ[\"TFM_RESULTS_FILTER_ACTIVATIONS\"]\n",
    "    \n",
    "print(\"Path to filter activations: %s\" % filter_activations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants/paths\n",
    "input_length = 2114\n",
    "filter_width = 21\n",
    "reference_genome_path = \"/users/amtseng/genomes/hg38.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For extracting motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_to_one_hot(seqs):\n",
    "    \"\"\"\n",
    "    Converts a list of DNA (\"ACGT\") sequences to one-hot encodings, where the\n",
    "    position of 1s is ordered alphabetically by \"ACGT\". `seqs` must be a list\n",
    "    of N strings, where every string is the same length L. Returns an N x L x 4\n",
    "    NumPy array of one-hot encodings, in the same order as the input sequences.\n",
    "    All bases will be converted to upper-case prior to performing the encoding.\n",
    "    Any bases that are not \"ACGT\" will be given an encoding of all 0s.\n",
    "    \"\"\"\n",
    "    seq_len = len(seqs[0])\n",
    "    assert np.all(np.array([len(s) for s in seqs]) == seq_len)\n",
    "\n",
    "    # Join all sequences together into one long string, all uppercase\n",
    "    seq_concat = \"\".join(seqs).upper()\n",
    "\n",
    "    one_hot_map = np.identity(5)[:, :-1]\n",
    "\n",
    "    # Convert string into array of ASCII character codes;\n",
    "    base_vals = np.frombuffer(bytearray(seq_concat, \"utf8\"), dtype=np.int8)\n",
    "\n",
    "    # Anything that's not an A, C, G, or T gets assigned a higher code\n",
    "    base_vals[~np.isin(base_vals, np.array([65, 67, 71, 84]))] = 85\n",
    "\n",
    "    # Convert the codes into indices in [0, 4], in ascending order by code\n",
    "    _, base_inds = np.unique(base_vals, return_inverse=True)\n",
    "\n",
    "    # Get the one-hot encoding for those indices, and reshape back to separate\n",
    "    return one_hot_map[base_inds].reshape((len(seqs), seq_len, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_motifs(filter_activations_path, reference_genome_path):\n",
    "    \"\"\"\n",
    "    Extracts the motifs that correspond to each filter. Returns an\n",
    "    F x W x 4 array, where F is the number of filters and W is the width\n",
    "    of each filter. The order of filters matches those in the saved HDF5/model.\n",
    "    \"\"\"\n",
    "    reader = h5py.File(filter_activations_path, \"r\")\n",
    "    activations_reader = reader[\"activations\"]\n",
    "    num_coords, two, num_windows, num_filters = activations_reader.shape\n",
    "    \n",
    "    assert two == 2\n",
    "    assert num_windows == input_length - filter_width + 1\n",
    "    \n",
    "    print(\"Importing coordinates...\")\n",
    "    coords = np.empty((num_coords, 3), dtype=object)\n",
    "    coords[:, 0] = reader[\"coords\"][\"coords_chrom\"][:].astype(str)\n",
    "    coords[:, 1] = reader[\"coords\"][\"coords_start\"][:]\n",
    "    coords[:, 2] = reader[\"coords\"][\"coords_end\"][:]\n",
    "    \n",
    "    print(\"Fetching one-hot sequences...\")\n",
    "    genome_reader = pyfaidx.Fasta(reference_genome_path)\n",
    "    one_hot_seqs = np.empty((num_coords, input_length, 4))\n",
    "    batch_size = 128\n",
    "    num_batches = int(np.ceil(num_coords / batch_size))\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        one_hot_seqs[batch_slice] = dna_to_one_hot([\n",
    "            genome_reader[chrom][start:end].seq for chrom, start, end in coords[batch_slice]\n",
    "        ])\n",
    "    \n",
    "    pfms = np.empty((num_filters, filter_width, 4))\n",
    "    for filter_index in range(num_filters):\n",
    "        print(\"Extracting motif for filter %d...\" % filter_index)\n",
    "    \n",
    "        print(\"\\tComputing maximum activation...\")\n",
    "        acts = activations_reader[:, :, :, filter_index]\n",
    "        max_act = np.max(acts)\n",
    "        \n",
    "        inds = np.where(acts >= 0.5 * max_act)\n",
    "        \n",
    "        windows, num_windows = np.zeros((filter_width, 4)), 0\n",
    "        for coord_index, strand_index, pos_index in tqdm.notebook.tqdm(\n",
    "            zip(*inds), total=len(inds[0]), desc=\"Extracting windows...\"\n",
    "        ):\n",
    "            if strand_index == 0:\n",
    "                window = one_hot_seqs[coord_index, pos_index : pos_index + filter_width]\n",
    "            else:\n",
    "                # Reverse complement; the positions are flipped\n",
    "                window = np.flip(\n",
    "                    one_hot_seqs[coord_index, input_length - filter_width - pos_index : input_length - pos_index],\n",
    "                    axis=(0, 1)\n",
    "                )\n",
    "            windows = windows + window\n",
    "            num_windows += 1\n",
    "        \n",
    "        pfms[filter_index] = windows / num_windows\n",
    "    \n",
    "    return pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filter_influence(filter_activations_path):\n",
    "    \"\"\"\n",
    "    Extracts the influence of each filter by computing the difference\n",
    "    in normalized NLL when each filter is nullified.\n",
    "    Returns an F-array, where F is the number of filters, containing the\n",
    "    change in average normalized NLL (after nullification - before\n",
    "    nullification). The order of filters matches those in the saved\n",
    "    HDF5/model.\n",
    "    \"\"\"\n",
    "    reader = h5py.File(filter_activations_path, \"r\")\n",
    "    print(\"Reading in normalized NLLs...\")\n",
    "    before_null_norm_nlls = reader[\"predictions\"][\"norm_nlls\"][:]\n",
    "    after_null_norm_nlls = reader[\"nullified_predictions\"][\"norm_nlls\"][:]\n",
    "    \n",
    "    before_null = np.nanmean(before_null_norm_nlls)\n",
    "    \n",
    "    num_filters = after_null_norm_nlls.shape[1]\n",
    "    \n",
    "    influences = []\n",
    "    for filter_index in tqdm.notebook.trange(num_filters):\n",
    "        after_null = np.nanmean(after_null_norm_nlls[:, filter_index])\n",
    "        influences.append(after_null - before_null)\n",
    "        \n",
    "    return np.array(influences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_freqs = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "def info_content(track, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    Given an L x 4 track, computes information content for each base and\n",
    "    returns it as an L-array.\n",
    "    \"\"\"\n",
    "    num_bases = track.shape[1]\n",
    "    # Normalize track to probabilities along base axis\n",
    "    track_norm = (track + pseudocount) / (np.sum(track, axis=1, keepdims=True) + (num_bases * pseudocount))\n",
    "    ic = track_norm * np.log2(track_norm / np.expand_dims(background_freqs, axis=0))\n",
    "    return np.sum(ic, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract motifs\n",
    "Extract the motifs derived from each filter, ranked by filter influence.\n",
    "\n",
    "Deriving a filter's motif: \n",
    "1. Identify the top 10000 most well-predicted input sequences, ranked by normalized NLL\n",
    "2. For each window in each of these sequences, compute the filter activation for each 1st-layer filter\n",
    "3. A filter's motif is the aggregation of sequence windows which activate that filter to at least half its maximum activation (over the top 10000 most well-predicted inputs)\n",
    "\n",
    "Deriving a filter's influence:\n",
    "1. Identify the top 10000 most well-predicted input sequences, ranked by normalized NLL\n",
    "2. Nullify each filter by setting it to the average activation over these 10000 most well-predicted inputs\n",
    "3. A filter's influence is the average change in normalized NLL before and after nullification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_pfms = extract_motifs(filter_activations_path, reference_genome_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_influences = compute_filter_influence(filter_activations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"motifs\"></a>\n",
    "### Show motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, filter_index in enumerate(np.flip(np.argsort(filter_influences))):\n",
    "    print(\"%d) Filter %d (influence = %.3f)\" % (i, filter_index, filter_influences[filter_index]))\n",
    "    \n",
    "    pfm = filter_pfms[filter_index]\n",
    "    pwm = pfm * np.expand_dims(info_content(pfm), axis=1)\n",
    "    viz_sequence.plot_weights(pwm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
