{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/notebooks/reports/\"))\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "import motif.tfmodisco_hit_scoring as tfmodisco_hit_scoring\n",
    "import motif.match_motifs as match_motifs\n",
    "import plot.viz_sequence as viz_sequence\n",
    "from util import figure_to_vdom_image, create_motif_similarity_matrix, aggregate_motifs, aggregate_motifs_from_inds\n",
    "import tempfile\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import scipy.signal\n",
    "import scipy.cluster.hierarchy\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"svg.fonttype\": \"none\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"TFM_TF_NAME\" in os.environ:\n",
    "    tf_name = os.environ[\"TFM_TF_NAME\"]\n",
    "else:\n",
    "    tf_name = \"E2F6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define the clusters of core motifs\n",
    "\n",
    "if tf_name == \"E2F6\":\n",
    "    core_motif_defs = [\n",
    "        (\"MAX\", [\"T0:C0_0:P0_0\", \"T1:C0_0:P0_0\"]),\n",
    "        (\"E2F6\", [\"T0:C0_1:P0_1\", \"T1:C0_1:P0_1\"]),\n",
    "        (\"AP-1\", [\"T0:C0_5\", \"T0:P0_9\", \"T1:C0_7:P0_11\"]),\n",
    "        (\"other E2F\", [\"T0:C0_4\", \"T0:P0_4\", \"T0:P0_6\", \"T1:C0_3:P0_3\"]),\n",
    "        (\"weak MAX v1\", [\"T1:C0_2:P0_7\", \"T1:C0_6:P0_2\"]),\n",
    "        (\"weak MAX v2\", [\"T0:C0_2:P0_2\", \"T1:C0_5\", \"T1:P0_4\"])\n",
    "    ]\n",
    "elif tf_name == \"SPI1\":\n",
    "    core_motif_defs = [\n",
    "        (\"SPI1\", [\"T1:C0_0:P0_0\", \"T3:C0_0:P0_0\", \"T1:P0_7\", \"T0:C0_4\", \"T0:C0_0:P0_0\", \"T2:C0_0:P0_0\"]),\n",
    "        (\"SPI1 v2\", [\"T1:C0_4\", \"T1:P0_5\", \"T3:C0_2\"]),\n",
    "        (\"AP-1\", [\"T2:C0_5\", \"T1:C0_3\", \"T2:C0_6\", \"T2:P0_7\", \"T2:C0_2\"]),\n",
    "        (\"CEBP\", [\"T3:C0_1:P0_1\"]),\n",
    "        (\"RUNX\", [\"T2:C0_8\", \"T3:C0_3\", \"T3:P0_5\", \"T3:P0_7\"]),\n",
    "        (\"GATA\", [\"T1:C0_1\"])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_num_tasks = {\n",
    "    \"E2F6\": 2,\n",
    "    \"FOXA2\": 4,\n",
    "    \"SPI1\": 4,\n",
    "    \"CEBPB\": 7,\n",
    "    \"MAX\": 7,\n",
    "    \"GABPA\": 9,\n",
    "    \"MAFK\": 9,\n",
    "    \"JUND\": 14,\n",
    "    \"NR3C1-reddytime\": 16,\n",
    "    \"REST\": 20\n",
    "}\n",
    "\n",
    "tf_best_model_types = {\n",
    "    \"E2F6\": list(\"MM\"),\n",
    "    \"FOXA2\": list(\"SSMM\"),\n",
    "    \"SPI1\": list(\"MSSS\"),\n",
    "    \"CEBPB\": list(\"MMMMSMM\"),\n",
    "    \"MAX\": list(\"MMSMMSS\"),\n",
    "    \"GABPA\": list(\"MMMSMMMMM\"),\n",
    "    \"MAFK\": list(\"MMMMMMMMM\"),\n",
    "    \"JUND\": list(\"SMMSMSSSSSSSMS\"),\n",
    "    \"NR3C1-reddytime\": list(\"MMMSMMSMMMMSMMMM\"),\n",
    "    \"REST\": list(\"MMMMMMMMMSMMSMMSMMMM\")\n",
    "}\n",
    "\n",
    "num_tasks = tf_num_tasks[tf_name]\n",
    "best_model_types = tf_best_model_types[tf_name]\n",
    "\n",
    "tfm_motif_file = \"/users/amtseng/tfmodisco/results/motifs/tfmodisco/%s_tfmodisco_cpmerged_motifs.h5\" % tf_name\n",
    "meme_motif_file = \"/users/amtseng/tfmodisco/results/motifs/meme/%s_meme_motifs.h5\" % tf_name\n",
    "homer_motif_file = \"/users/amtseng/tfmodisco/results/motifs/homer/%s_homer_motifs.h5\" % tf_name\n",
    "dichipmunk_motif_file = \"/users/amtseng/tfmodisco/results/motifs/dichipmunk/%s_dichipmunk_motifs.h5\" % tf_name\n",
    "\n",
    "multitask_finetune_model_def_tsv = \"/users/amtseng/tfmodisco/results/model_stats/multitask_profile_finetune_stats.tsv\"\n",
    "singletask_finetune_model_def_tsv = \"/users/amtseng/tfmodisco/results/model_stats/singletask_profile_finetune_stats.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_database_path = \"/users/amtseng/tfmodisco/data/processed/motif_databases/JASPAR2020_CORE_vertebrates_non-redundant_pfms_meme.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif_hit_paths():\n",
    "    \"\"\"\n",
    "    Returns a list of pairs, where each pair is the count and profile\n",
    "    motif hit paths for the task.\n",
    "    \"\"\"\n",
    "    # First, import the best fold definitions\n",
    "    \n",
    "    # Finetuned multi-task model\n",
    "    best_mt_fold = None\n",
    "    with open(multitask_finetune_model_def_tsv, \"r\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split(\"\\t\")\n",
    "            if tokens[0] == tf_name and int(tokens[1]) == num_tasks - 1:\n",
    "                assert best_mt_fold is None\n",
    "                best_mt_fold = int(tokens[2])\n",
    "\n",
    "    # Finetuned single-task models\n",
    "    best_st_folds = []\n",
    "    with open(singletask_finetune_model_def_tsv, \"r\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split(\"\\t\")\n",
    "            if tokens[0] == tf_name:\n",
    "                best_st_folds.append(int(tokens[2]))\n",
    "                \n",
    "    assert len(best_st_folds) == num_tasks\n",
    "\n",
    "    # Get paths to motif hits\n",
    "    task_motif_hit_paths = []\n",
    "    base_path = \"/users/amtseng/tfmodisco/results/tfmodisco_hit_scoring\"\n",
    "    for task_index, model_type in enumerate(best_model_types):\n",
    "        if model_type == \"M\":\n",
    "            path = os.path.join(\n",
    "                base_path,\n",
    "                \"multitask_profile_finetune\",\n",
    "                \"%s_multitask_profile_finetune_task%d_fold%d_{0}\" % (tf_name, task_index, best_mt_fold),\n",
    "                \"tfm_matches.bed\"\n",
    "            )\n",
    "        else:\n",
    "            path = os.path.join(\n",
    "                base_path,\n",
    "                \"singletask_profile_finetune\",\n",
    "                \"%s_singletask_profile_finetune_fold%d_{0}\" % (tf_name, best_st_folds[task_index]),\n",
    "                \"task_%d\" % task_index,\n",
    "                \"tfm_matches.bed\"\n",
    "            )\n",
    "        task_motif_hit_paths.append(\n",
    "            (path.format(\"count\"), path.format(\"profile\"))\n",
    "        )\n",
    "    return task_motif_hit_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purine_rich_motif(motif):\n",
    "    \"\"\"\n",
    "    Flip motif to be the purine-rich orientation\n",
    "    \"\"\"\n",
    "    if np.sum(motif[:, [0, 2]]) < 0.5 * np.sum(motif):\n",
    "        return np.flip(motif, axis=(0, 1))\n",
    "    return motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_motifs(motif_file, model_types, motif_type=\"cwm_trimmed\"):\n",
    "    \"\"\"\n",
    "    From a file containing all motifs for that TF, imports the\n",
    "    trimmed CWMs (or another kind of motif type) of the fine-tuned models\n",
    "    corresponding to the model type for each task.\n",
    "    Returns a list of dictionaries (one for each task), where\n",
    "    each dictionary maps motif key to motif.\n",
    "    \"\"\"\n",
    "    motifs = []\n",
    "    with h5py.File(motif_file, \"r\") as f:\n",
    "        mtft = f[\"multitask_finetune\"]\n",
    "        stft = f[\"singletask_finetune\"]\n",
    "        for i, model_type in enumerate(model_types):\n",
    "            task = \"task_%d\" % i\n",
    "            if model_type == \"M\":\n",
    "                dset = mtft[task]\n",
    "            else:\n",
    "                dset = stft[task]\n",
    "            task_motifs = {}\n",
    "            for motif_key in dset.keys():\n",
    "                if \"0_\" in motif_key:\n",
    "                    # Motifs that are (or are constructed from) positive metacluster only\n",
    "                    task_motifs[\"T%d:%s\" % (i, motif_key)] = purine_rich_motif(dset[motif_key][motif_type][:])\n",
    "            motifs.append(task_motifs)\n",
    "    return motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_classic_benchmark_motifs(motif_file, mode):\n",
    "    \"\"\"\n",
    "    From a file containing all motifs for that TF from a benchmark\n",
    "    method, imports the PFMs of the motifs for each task.\n",
    "    Returns a list of dictionaries (one for each task), where\n",
    "    each dictionary maps motif key to motif.\n",
    "    \"\"\"\n",
    "    if mode == \"dichipmunk\":\n",
    "        score_key = \"supporting_seqs\"\n",
    "    elif mode == \"homer\":\n",
    "        score_key = \"log_enrichment\"\n",
    "    elif mode == \"meme\":\n",
    "        score_key = \"evalue\"\n",
    "    motifs = []\n",
    "    with h5py.File(motif_file, \"r\") as f:\n",
    "        tasks = sorted([int(key[5:]) for key in f.keys() if key != \"task_agg\"])\n",
    "        for i in tasks:\n",
    "            dset = f[\"task_%d\" % i]\n",
    "            task_motifs = {}\n",
    "            for motif_key in dset.keys():\n",
    "                if motif_key == score_key:\n",
    "                    continue\n",
    "                task_motifs[\"T%d:%s\" % (i, motif_key)] = purine_rich_motif(dset[motif_key][:])\n",
    "            motifs.append(task_motifs)\n",
    "    return motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_database_pfms(database_path):\n",
    "    \"\"\"\n",
    "    Imports the database of PFMs by reading through the entire database and\n",
    "    constructing a dictionary mapping motif IDs to NumPy arrays of PFMs.\n",
    "    \"\"\"\n",
    "    motif_dict = {}\n",
    "    with open(database_path, \"r\") as f:\n",
    "        try:\n",
    "            while True:\n",
    "                line = next(f)\n",
    "                if line.startswith(\"MOTIF\"):\n",
    "                    key = line.strip().split()[1]\n",
    "                    header = next(f)\n",
    "                    motif_width = int(header.split()[5])\n",
    "                    motif = np.empty((motif_width, 4))\n",
    "                    for i in range(motif_width):\n",
    "                        motif[i] = np.array([\n",
    "                            float(x) for x in next(f).strip().split()\n",
    "                        ])\n",
    "                    # Add the motif with a shortened key\n",
    "                    motif_dict[key.split(\"_\")[1]] = purine_rich_motif(motif)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "    return motif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_tomtom_motif_similarities(query_dict, target_dict):\n",
    "    \"\"\"\n",
    "    From a dictionary mapping N motif keys to query motifs, and a\n",
    "    dictionary mapping M motif keys to target motifs, returns a\n",
    "    dictionary mapping the N query motif keys to the similarity and\n",
    "    key of the closest target motif (a pair). Similarity is the\n",
    "    -log(p) from TOMTOM.\n",
    "    \"\"\"\n",
    "    query_keys, query_pfms = list(zip(*query_dict.items()))\n",
    "    target_keys, target_pfms = list(zip(*target_dict.items()))\n",
    "    \n",
    "    # Create temporary directory to do work in\n",
    "    temp_dir_obj = tempfile.TemporaryDirectory()\n",
    "    temp_dir = temp_dir_obj.name\n",
    "\n",
    "    # Convert motifs to MEME format\n",
    "    query_motif_file = os.path.join(temp_dir, \"query_motifs.txt\")\n",
    "    target_motif_file = os.path.join(temp_dir, \"target_motifs.txt\")\n",
    "    match_motifs.export_pfms_to_meme_format(query_pfms, query_motif_file)\n",
    "    match_motifs.export_pfms_to_meme_format(target_pfms, target_motif_file)\n",
    "\n",
    "    # Run TOMTOM\n",
    "    tomtom_dir = os.path.join(temp_dir, \"tomtom\")\n",
    "    match_motifs.run_tomtom(\n",
    "        query_motif_file, target_motif_file, tomtom_dir,\n",
    "        show_output=False\n",
    "    )\n",
    "\n",
    "    # Find results, mapping each query motif to target index\n",
    "    # The query/target IDs are the indices\n",
    "    tomtom_table = match_motifs.import_tomtom_results(tomtom_dir)\n",
    "    matches = []\n",
    "    for i in range(len(query_pfms)):\n",
    "        rows = tomtom_table[tomtom_table[\"Query_ID\"] == i]\n",
    "        if rows.empty:\n",
    "            matches.append((0, \"N/A\"))\n",
    "            continue\n",
    "        min_row = rows.loc[rows[\"p-value\"].idxmin()]\n",
    "        score = -np.log10(min_row[\"p-value\"])\n",
    "        target_key = target_keys[min_row[\"Target_ID\"]]\n",
    "        matches.append((score, target_key))\n",
    "\n",
    "    temp_dir_obj.cleanup()\n",
    "    \n",
    "    return dict(zip(query_keys, matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_cwm_motifs = import_tfmodisco_motifs(tfm_motif_file, best_model_types, \"cwm_trimmed\")\n",
    "tfm_pfm_motifs = import_tfmodisco_motifs(tfm_motif_file, best_model_types, \"pfm_trimmed\")\n",
    "meme_motifs = import_classic_benchmark_motifs(meme_motif_file, \"meme\")\n",
    "homer_motifs = import_classic_benchmark_motifs(homer_motif_file, \"homer\")\n",
    "dichipmunk_motifs = import_classic_benchmark_motifs(dichipmunk_motif_file, \"dichipmunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the TF-MoDISco motifs across each task\n",
    "We need to decide which ones to merge together. We start with a best guess for clustering, and then manually decide on the right motifs from each task to cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all TF-MoDISco motifs across all tasks into a single list\n",
    "tfm_motif_keys = [list(d.keys()) for d in tfm_cwm_motifs]\n",
    "tfm_motif_cwms = [[tfm_cwm_motifs[i][key] for key in tfm_motif_keys[i]] for i in range(len(tfm_motif_keys))]\n",
    "tfm_motif_pfms = [[tfm_pfm_motifs[i][key] for key in tfm_motif_keys[i]] for i in range(len(tfm_motif_keys))]\n",
    "tfm_motif_keys = sum(tfm_motif_keys, [])\n",
    "tfm_motif_cwms = sum(tfm_motif_cwms, [])\n",
    "tfm_motif_pfms = sum(tfm_motif_pfms, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix\n",
    "sim_matrix = create_motif_similarity_matrix(tfm_motif_cwms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linkage and clusters\n",
    "dist_matrix = 1 - sim_matrix\n",
    "np.fill_diagonal(dist_matrix, 0)\n",
    "dist_vec = scipy.spatial.distance.squareform(dist_matrix)\n",
    "\n",
    "cluster_distance = 0.6  # On the greedy side\n",
    "linkage = scipy.cluster.hierarchy.linkage(dist_vec, method=\"ward\")\n",
    "clusters = scipy.cluster.hierarchy.fcluster(\n",
    "    linkage, cluster_distance, criterion=\"distance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show aggregated and constituent motifs for each cluster\n",
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"45%\"}),\n",
    "    vdomh.col(style={\"width\": \"45%\"}),\n",
    "    vdomh.col(style={\"width\": \"10%\"})\n",
    ")\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Aggregate motif\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Constituent motifs\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Constituent motif IDs\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "cluster_ids, counts = np.unique(clusters, return_counts=True)\n",
    "for i, cluster_id in enumerate(cluster_ids):\n",
    "    match_inds = np.where(clusters == cluster_id)[0]\n",
    "    match_cwms = [tfm_motif_cwms[j] for j in match_inds]\n",
    "    match_keys = [tfm_motif_keys[j] for j in match_inds]\n",
    "    \n",
    "    consensus_cwm = aggregate_motifs(match_cwms)\n",
    "    \n",
    "    display(vdomh.h3(\"Cluster %d (%d/%d)\" % (cluster_id, i + 1, len(cluster_ids))))\n",
    "    display(vdomh.h4(\"%d motifs\" % len(match_cwms)))\n",
    "    \n",
    "    agg_fig = viz_sequence.plot_weights(consensus_cwm, figsize=(20, 4), return_fig=True)\n",
    "    agg_fig.tight_layout()\n",
    "    \n",
    "    const_figs = []\n",
    "    for cwm in match_cwms:\n",
    "        fig = viz_sequence.plot_weights(cwm, figsize=(20, 4), return_fig=True)\n",
    "        fig.tight_layout()\n",
    "        const_figs.append(figure_to_vdom_image(fig))\n",
    "\n",
    "    body = vdomh.tbody(*([\n",
    "        vdomh.tr(\n",
    "            vdomh.td(figure_to_vdom_image(agg_fig), rowspan=str(len(match_cwms))),\n",
    "            vdomh.td(const_figs[0]),\n",
    "            vdomh.td(match_keys[0])\n",
    "        )] + [\n",
    "            vdomh.tr(\n",
    "                vdomh.td(const_figs[j + 1]),\n",
    "                vdomh.td(match_keys[j + 1])\n",
    "            ) for j in range(len(match_cwms) - 1)\n",
    "        ]\n",
    "    ))\n",
    "    display(vdomh.table(colgroup, header, body))\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show aggregated and constituent motifs for the final clusterings\n",
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"45%\"}),\n",
    "    vdomh.col(style={\"width\": \"45%\"}),\n",
    "    vdomh.col(style={\"width\": \"10%\"})\n",
    ")\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Aggregate motif\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Constituent motifs\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Constituent motif IDs\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    "    )\n",
    "\n",
    "core_motif_cwms = {}\n",
    "core_motif_pfms = {}\n",
    "for agg_motif_name, const_motif_keys in core_motif_defs:    \n",
    "    const_motif_cwms = [tfm_motif_cwms[tfm_motif_keys.index(key)] for key in const_motif_keys]\n",
    "    const_motif_pfms = [tfm_motif_pfms[tfm_motif_keys.index(key)] for key in const_motif_keys]\n",
    "    \n",
    "    agg_cwm, (const_inds, agg_inds) = aggregate_motifs(const_motif_cwms, return_inds=True)\n",
    "    core_motif_cwms[agg_motif_name] = agg_cwm\n",
    "    \n",
    "    # Construct aggregate PFM\n",
    "    agg_pfm = aggregate_motifs_from_inds(const_motif_pfms, const_inds, agg_inds)\n",
    "    agg_pfm = agg_pfm / np.sum(agg_pfm, axis=1, keepdims=True)\n",
    "    core_motif_pfms[agg_motif_name] = agg_pfm\n",
    "        \n",
    "    display(vdomh.h3(agg_motif_name))\n",
    "    \n",
    "    agg_fig = viz_sequence.plot_weights(agg_cwm, figsize=(20, 4), return_fig=True)\n",
    "    agg_fig.tight_layout()\n",
    "    \n",
    "    const_figs = []\n",
    "    for motif in const_motif_cwms:\n",
    "        fig = viz_sequence.plot_weights(motif, figsize=(20, 4), return_fig=True)\n",
    "        fig.tight_layout()\n",
    "        const_figs.append(figure_to_vdom_image(fig))\n",
    "\n",
    "    body = vdomh.tbody(*([\n",
    "        vdomh.tr(\n",
    "            vdomh.td(figure_to_vdom_image(agg_fig), rowspan=str(len(const_motif_keys))),\n",
    "            vdomh.td(const_figs[0]),\n",
    "            vdomh.td(const_motif_keys[0])\n",
    "        )] + [\n",
    "            vdomh.tr(\n",
    "                vdomh.td(const_figs[j + 1]),\n",
    "                vdomh.td(const_motif_keys[j + 1])\n",
    "            ) for j in range(len(const_motif_keys) - 1)\n",
    "        ]\n",
    "    ))\n",
    "    display(vdomh.table(colgroup, header, body))\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract constituent motif prevalences\n",
    "For each aggregated motif, extract the prevalence of the constituent motifs (by task) in the peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the motif hits for each task\n",
    "task_motif_hit_paths = get_motif_hit_paths()\n",
    "task_motif_hits = []\n",
    "for count_path, profile_path in task_motif_hit_paths:\n",
    "    count_table = tfmodisco_hit_scoring.import_tfmodisco_hits(count_path)[[\"key\", \"peak_index\"]]\n",
    "    profile_table = tfmodisco_hit_scoring.import_tfmodisco_hits(profile_path)[[\"key\", \"peak_index\"]]\n",
    "    # We only need the key and peak index\n",
    "    task_motif_hits.append({\"C\": count_table, \"P\": profile_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_prevalence(hit_table, motif_keys):\n",
    "    \"\"\"\n",
    "    Computes the motif prevalence from the hit table, as the proportion of\n",
    "    peaks which have hits in the given motif keys.\n",
    "    \"\"\"\n",
    "    total_peaks = len(np.unique(hit_table[\"peak_index\"]))\n",
    "    hit_peaks = len(np.unique(hit_table[np.isin(hit_table[\"key\"], motif_keys)][\"peak_index\"]))\n",
    "    return hit_peaks / total_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of motif prevalences\n",
    "motif_prevalences = np.zeros((len(core_motif_defs), len(task_motif_hits)))\n",
    "for i, (_, motif_keys) in enumerate(core_motif_defs):\n",
    "    # Map each task index to the motif keys belonging to this aggregate motif (if any)\n",
    "    task_const_keys = {j : [] for j in range(len(task_motif_hits))}\n",
    "    for const_key in motif_keys:\n",
    "        tokens = const_key.split(\":\")\n",
    "        task_index = int(tokens[0][1:])\n",
    "        task_const_keys[task_index].append(\":\".join(tokens[1:]))\n",
    "        \n",
    "    # Get the sum of prevalences for each task\n",
    "    for j in task_const_keys:\n",
    "        # Extract the set of motif keys, separately for counts/profiles\n",
    "        motif_keys = {}\n",
    "        for key in task_const_keys[j]:\n",
    "            tokens = key.split(\":\")\n",
    "            # May be compound key\n",
    "            for token in tokens:\n",
    "                head, motif_key = token[0], token[1:]\n",
    "                try:\n",
    "                    motif_keys[head].append(motif_key)\n",
    "                except KeyError:\n",
    "                    motif_keys[head] = [motif_key]\n",
    "        \n",
    "        # Compute prevalence over the motif keys, taking the maximum over the count/profile heads\n",
    "        motif_prevalences[i, j] = max(\n",
    "            get_hit_prevalence(task_motif_hits[j][head], motif_keys[head])\n",
    "            for head in motif_keys.keys()\n",
    "        ) if motif_keys else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity of benchmark motifs to aggregated motifs\n",
    "For each aggregated motif, compute the similarity of the closest motif in each benchmark for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_motifs(query_motifs, target_motifs):\n",
    "    \"\"\"\n",
    "    From a list of N target CWMs in `target_motifs`, and a list of\n",
    "    M query CWMs in `query_motifs`, computes the most similar target\n",
    "    motif to each query motif. Returns an N-array.\n",
    "    \"\"\"\n",
    "    # Build similarity matrix\n",
    "    sim_matrix = create_motif_similarity_matrix(query_motifs, target_motifs, show_progress=False)\n",
    "    return np.max(sim_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_similarities(query_motifs, benchmark_motifs):\n",
    "    \"\"\"\n",
    "    From a list of N target CWMs and a list of T dictionaries mapping\n",
    "    motif keys to CWMs, computes an N x T matrix of the best motif\n",
    "    similarity in each task to each query motif.\n",
    "    \"\"\"\n",
    "    matrix = np.empty((len(query_motifs), len(benchmark_motifs)))\n",
    "    for i in range(len(query_motifs)):\n",
    "        for j in range(len(benchmark_motifs)):\n",
    "            matrix[:, j] = get_closest_motifs(query_motifs, list(benchmark_motifs[j].values()))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_motifs = [core_motif_cwms[pair[0]] for pair in core_motif_defs]\n",
    "\n",
    "meme_best_sims = get_benchmark_similarities(query_motifs, meme_motifs)\n",
    "homer_best_sims = get_benchmark_similarities(query_motifs, homer_motifs)\n",
    "dichipmunk_best_sims = get_benchmark_similarities(query_motifs, dichipmunk_motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity of benchmark motifs to aggregated motifs\n",
    "For each aggregated motif, compute the similarity of the closest motif in the database of motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_motifs = import_database_pfms(motif_database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_motifs = {\n",
    "    pair[0] : core_motif_pfms[pair[0]] for pair in core_motif_defs\n",
    "}\n",
    "\n",
    "database_best_sims = get_closest_tomtom_motif_similarities(\n",
    "    query_motifs, database_motifs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = motif_prevalences.shape[0] * 2\n",
    "width = motif_prevalences.shape[1] * 4 + 1\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    ncols=3, figsize=(width, height),\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [(width - 1) * (1/2), (width - 1) * (3/8), (width - 1) * (1/8)],\n",
    "        \"wspace\": 0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot motif prevalences in each task\n",
    "\n",
    "y, x = np.unravel_index(np.arange(motif_prevalences.size), motif_prevalences.shape)\n",
    "x, y = x + 0.5, y + 0.5\n",
    "\n",
    "# Set the radius such that the area is proportional to the prevalence\n",
    "max_area = np.pi * (0.5 ** 2)\n",
    "assert np.min(motif_prevalences) >= 0 and np.max(motif_prevalences) <= 1\n",
    "area = motif_prevalences * max_area\n",
    "radius = np.sqrt(area / np.pi)\n",
    "\n",
    "# Plot the data\n",
    "ax[0].set_xlim(0, motif_prevalences.shape[1])\n",
    "ax[0].set_ylim(0, motif_prevalences.shape[0])\n",
    "ax[0].set_xticks(np.arange(0.5, motif_prevalences.shape[1] + 0.5))\n",
    "ax[0].set_yticks(np.arange(0.5, motif_prevalences.shape[0] + 0.5))\n",
    "ax[0].set_xticklabels([\"task_%d\" % i for i in np.arange(0, motif_prevalences.shape[1])])\n",
    "ax[0].set_yticklabels([pair[0] for pair in core_motif_defs][::-1])  # Flip y-axis\n",
    "for i in range(motif_prevalences.shape[1]):\n",
    "    ax[0].axvline(i, color=\"gray\", alpha=0.2)\n",
    "for i in range(motif_prevalences.shape[0]):\n",
    "    ax[0].axhline(i, color=\"gray\", alpha=0.2)\n",
    "\n",
    "for i in range(motif_prevalences.shape[0]):\n",
    "    for j in range(motif_prevalences.shape[1]):\n",
    "        circle = plt.Circle((j + 0.5, motif_prevalences.shape[0] - i - 1 + 0.5), radius[i, j], alpha=0.3)\n",
    "        ax[0].add_patch(circle)\n",
    "        \n",
    "# Plot benchmark motif distances in each task\n",
    "\n",
    "# Create the benchmark array to show\n",
    "full_sim_matrix = np.empty((meme_best_sims.shape[0], meme_best_sims.shape[1] * 3))\n",
    "sim_matrices = [meme_best_sims, homer_best_sims, dichipmunk_best_sims]\n",
    "for i in range(3):\n",
    "    full_sim_matrix[:, np.arange(0, meme_best_sims.shape[1] * 3, 3) + i] = sim_matrices[i]\n",
    "hm = ax[1].imshow(full_sim_matrix, cmap=\"Oranges\")\n",
    "fig.colorbar(hm)\n",
    "ax[1].set_aspect(\"auto\")\n",
    "ax[1].set_xticks(np.arange(full_sim_matrix.shape[1]))\n",
    "ax[1].set_xticklabels(\n",
    "    sum([[\"task_%d_%s\" % (i, s) for s in (\"M\", \"H\", \"D\")] for i in range(meme_best_sims.shape[1])], []),\n",
    "    rotation=90\n",
    ")\n",
    "ax[1].set_yticks([])\n",
    "\n",
    "# Plot the database motif distances\n",
    "\n",
    "database_sims = np.array([database_best_sims[pair[0]][0] for pair in core_motif_defs])\n",
    "database_labels = [database_best_sims[pair[0]][1] for pair in core_motif_defs]\n",
    "ax[2].imshow(database_sims[:, None], cmap=\"Oranges\")\n",
    "\n",
    "# Create annotations\n",
    "for i in range(len(database_labels)):\n",
    "    ax[2].text(0, i, database_labels[i], ha=\"center\", va=\"center\")\n",
    "\n",
    "ax[2].set_aspect(\"auto\")\n",
    "ax[2].set_xticks([0])\n",
    "ax[2].set_xticklabels([\"Database\"])\n",
    "ax[2].set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show aggregate motifs\n",
    "for key, _ in core_motif_defs:\n",
    "    display(vdomh.h3(key))\n",
    "    viz_sequence.plot_weights(core_motif_cwms[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
