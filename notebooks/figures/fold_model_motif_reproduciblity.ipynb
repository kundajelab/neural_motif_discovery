{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/notebooks/reports/\"))\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "import plot.viz_sequence as viz_sequence\n",
    "from util import figure_to_vdom_image, create_motif_similarity_matrix, purine_rich_motif\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors\n",
    "import matplotlib.font_manager as font_manager\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"svg.fonttype\": \"none\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"TFM_TF_NAME\" in os.environ:\n",
    "    tf_name = os.environ[\"TFM_TF_NAME\"]\n",
    "else:\n",
    "    tf_name = \"E2F6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/users/amtseng/tfmodisco/figures/fold_model_motif_reproduciblity/%s_fold_model_motif_reproducibility\" % tf_name\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "tf_num_tasks = {\n",
    "    \"E2F6\": 2,\n",
    "    \"FOXA2\": 4,\n",
    "    \"SPI1\": 4,\n",
    "    \"CEBPB\": 7,\n",
    "    \"MAX\": 7,\n",
    "    \"GABPA\": 9,\n",
    "    \"MAFK\": 9,\n",
    "    \"JUND\": 14,\n",
    "    \"NR3C1-reddytime\": 16,\n",
    "    \"REST\": 20\n",
    "}\n",
    "\n",
    "tf_best_model_types = {\n",
    "    \"E2F6\": list(\"MM\"),\n",
    "    \"FOXA2\": list(\"SSMM\"),\n",
    "    \"SPI1\": list(\"MSSS\"),\n",
    "    \"CEBPB\": list(\"MMMMSMM\"),\n",
    "    \"MAX\": list(\"MMSMMSS\"),\n",
    "    \"GABPA\": list(\"MMMSMMMMM\"),\n",
    "    \"MAFK\": list(\"MMMMMMMMM\"),\n",
    "    \"JUND\": list(\"SMMSMSSSSSSSMS\"),\n",
    "    \"NR3C1-reddytime\": list(\"MMMSMMSMMMMSMMMM\"),\n",
    "    \"REST\": list(\"MMMMMMMMMSMMSMMSMMMM\")\n",
    "}\n",
    "\n",
    "num_tasks = tf_num_tasks[tf_name]\n",
    "best_model_types = tf_best_model_types[tf_name]\n",
    "\n",
    "seed = 20210910\n",
    "\n",
    "motif_file = \"/users/amtseng/tfmodisco/results/motifs/tfmodisco/%s_tfmodisco_motifs.h5\" % tf_name\n",
    "\n",
    "multitask_finetune_model_def_tsv = \"/users/amtseng/tfmodisco/results/model_stats/multitask_profile_finetune_stats.tsv\"\n",
    "singletask_finetune_model_def_tsv = \"/users/amtseng/tfmodisco/results/model_stats/singletask_profile_finetune_stats.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitize_fold = lambda fold: \"F\" + fold.split(\"_\")[1]\n",
    "sanitize_task = lambda task: \"T\" + task.split(\"_\")[1]\n",
    "\n",
    "def import_all_tfmodisco_motifs(motif_file):\n",
    "    \"\"\"\n",
    "    From a file containing all motifs for that TF, imports the\n",
    "    trimmed CWMs of all conditions as a dictionary. Returns a dictionary\n",
    "    of motifs, mapping a unique key to the trimmed CWM.\n",
    "    \"\"\"\n",
    "    motifs = {}\n",
    "    with h5py.File(motif_file, \"r\") as f:\n",
    "        # Multi-task, all 10 folds\n",
    "        mt = f[\"multitask\"]\n",
    "        for fold in mt.keys():\n",
    "            mt_fold = mt[fold]\n",
    "            for key in (\"count\", \"profile\"):\n",
    "                mt_fold_key = mt_fold[key]\n",
    "                for motif_key in mt_fold_key.keys():\n",
    "                    if motif_key.startswith(\"0_\"):\n",
    "                        # Positive metacluster only\n",
    "                        name = \"MT:%s:%s:%s\" % (sanitize_fold(fold), key[0].upper(), motif_key)\n",
    "                        motifs[name] = purine_rich_motif(mt_fold_key[motif_key][\"cwm_trimmed\"][:])\n",
    "        \n",
    "        # Single-task, all 10 folds for all tasks\n",
    "        st = f[\"singletask\"]\n",
    "        for task in st.keys():\n",
    "            st_task = st[task]\n",
    "            for fold in st_task.keys():\n",
    "                st_task_fold = st_task[fold]\n",
    "                for key in (\"count\", \"profile\"):\n",
    "                    st_task_fold_key = st_task_fold[key]\n",
    "                    for motif_key in st_task_fold_key.keys():\n",
    "                        if motif_key.startswith(\"0_\"):\n",
    "                            # Positive metacluster only\n",
    "                            name = \"ST:%s:%s:%s:%s\" % (sanitize_task(task), sanitize_fold(fold), key[0].upper(), motif_key)\n",
    "                            motifs[name] = purine_rich_motif(st_task_fold_key[motif_key][\"cwm_trimmed\"][:])\n",
    "        \n",
    "        # Multi-task fine-tune, all tasks plus aggregate task\n",
    "        mtft = f[\"multitask_finetune\"]\n",
    "        for task in mtft.keys():\n",
    "            mtft_task = mtft[task]\n",
    "            for key in (\"count\", \"profile\"):\n",
    "                mtft_task_key = mtft_task[key]\n",
    "                for motif_key in mtft_task_key.keys():\n",
    "                    if motif_key.startswith(\"0_\"):\n",
    "                        # Positive metacluster only\n",
    "                        name = \"MTFT:%s:%s:%s\" % (sanitize_task(task), key[0].upper(), motif_key)\n",
    "                        motifs[name] = purine_rich_motif(mtft_task_key[motif_key][\"cwm_trimmed\"][:])\n",
    "        \n",
    "        # Single-task fine-tune, all tasks\n",
    "        stft = f[\"singletask_finetune\"]\n",
    "        for task in stft.keys():\n",
    "            stft_task = stft[task]\n",
    "            for key in (\"count\", \"profile\"):\n",
    "                stft_task_key = stft_task[key]\n",
    "                for motif_key in stft_task_key.keys():\n",
    "                    if motif_key.startswith(\"0_\"):\n",
    "                        # Positive metacluster only\n",
    "                        name = \"STFT:%s:%s:%s\" % (sanitize_task(task), key[0].upper(), motif_key)\n",
    "                        motifs[name] = purine_rich_motif(stft_task_key[motif_key][\"cwm_trimmed\"][:])\n",
    "        \n",
    "    return motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_seqlets(motif_key):\n",
    "    \"\"\"\n",
    "    Fetches the number of seqlets initially mapped to the given motif from the\n",
    "    original TF-MoDISco file.\n",
    "    \"\"\"\n",
    "    base_path = \"/users/amtseng/tfmodisco/results/tfmodisco\"\n",
    "    cond_type = motif_key.split(\":\")[0]\n",
    "    if cond_type == \"MTFT\":\n",
    "        # Get best fold\n",
    "        best_mt_fold = None\n",
    "        with open(multitask_finetune_model_def_tsv, \"r\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.strip().split(\"\\t\")\n",
    "                if tokens[0] == tf_name and int(tokens[1]) == num_tasks - 1:\n",
    "                    assert best_mt_fold is None\n",
    "                    best_mt_fold = int(tokens[2])\n",
    "        task, head, pattern = motif_key.split(\":\")[1:]\n",
    "        task = task[1:]\n",
    "        head = \"profile\" if head == \"P\" else \"count\"\n",
    "        path = os.path.join(\n",
    "            base_path,\n",
    "            \"multitask_profile_finetune\",\n",
    "            \"%s_multitask_profile_finetune_fold%d\" % (tf_name, best_mt_fold)\n",
    "        )\n",
    "        if task == \"agg\":\n",
    "            path = os.path.join(\n",
    "                path,\n",
    "                \"%s_multitask_profile_finetune_fold%d_%s_tfm.h5\" % (tf_name, best_mt_fold, head)\n",
    "            )\n",
    "        else:\n",
    "            path = os.path.join(\n",
    "                path,\n",
    "                \"%s_multitask_profile_finetune_task%s_fold%d_%s_tfm.h5\" % (tf_name, task, best_mt_fold, head)\n",
    "            )\n",
    "    elif cond_type == \"STFT\":\n",
    "        # Get best fold\n",
    "        best_st_folds = []\n",
    "        with open(singletask_finetune_model_def_tsv, \"r\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.strip().split(\"\\t\")\n",
    "                if tokens[0] == tf_name:\n",
    "                    best_st_folds.append(int(tokens[2]))\n",
    "        assert len(best_st_folds) == num_tasks\n",
    "        task, head, pattern = motif_key.split(\":\")[1:]\n",
    "        task = task[1:]\n",
    "        head = \"profile\" if head == \"P\" else \"count\"\n",
    "        best_st_fold = best_st_folds[int(task)]\n",
    "        path = os.path.join(\n",
    "            base_path,\n",
    "            \"singletask_profile_finetune\",\n",
    "            \"%s_singletask_profile_finetune_fold%d\" % (tf_name, best_st_fold),\n",
    "            \"task_%s\" % task,\n",
    "            \"%s_singletask_profile_finetune_task%s_fold%d_%s_tfm.h5\" % (tf_name, task, best_st_fold, head)\n",
    "        )        \n",
    "    elif cond_type == \"MT\":\n",
    "        fold, head, pattern = motif_key.split(\":\")[1:]\n",
    "        fold = fold[1:]\n",
    "        head = \"profile\" if head == \"P\" else \"count\"\n",
    "        path = os.path.join(\n",
    "            base_path,\n",
    "            \"multitask_profile\",\n",
    "            \"%s_multitask_profile_fold%s\" % (tf_name, fold),\n",
    "            \"%s_multitask_profile_fold%s_%s_tfm.h5\" % (tf_name, fold, head)\n",
    "        )\n",
    "    elif cond_type == \"ST\":\n",
    "        task, fold, head, pattern = motif_key.split(\":\")[1:]\n",
    "        task = task[1:]\n",
    "        fold = fold[1:]\n",
    "        head = \"profile\" if head == \"P\" else \"count\"\n",
    "        path = os.path.join(\n",
    "            base_path,\n",
    "            \"singletask_profile\",\n",
    "            \"%s_singletask_profile_fold%s\" % (tf_name, fold),\n",
    "            \"task_%s\" % task,\n",
    "            \"%s_singletask_profile_task%s_fold%s_%s_tfm.h5\" % (tf_name, task, fold, head)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model condition type\")\n",
    "        \n",
    "    # Now that we have the path, import the number of seqlets for the given pattern\n",
    "    metacluster_key, pattern_key = pattern.split(\"_\")\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        metacluster = f[\"metacluster_idx_to_submetacluster_results\"][\"metacluster_%s\" % metacluster_key]\n",
    "        patterns = metacluster[\"seqlets_to_patterns_result\"][\"patterns\"]\n",
    "        seqlets = patterns[\"pattern_%s\" % pattern_key][\"seqlets_and_alnmts\"][\"seqlets\"]\n",
    "        return len(seqlets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cdf(ax, data, steps=1000, density=False, inverse=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a CDF to the given axes. `steps` is the number of steps in the\n",
    "    CDF. If `inverse` is True, plots an inverse CDF (AKA survivorship plot).\n",
    "    `density` is whether or not to normalize to fractions.\n",
    "    \"\"\"\n",
    "    hist, bin_edges = np.histogram(data, bins=steps)\n",
    "    if inverse:\n",
    "        cumsum = len(data) - np.cumsum(hist)\n",
    "    else:\n",
    "        cumsum = np.cumsum(hist)\n",
    "    if density:\n",
    "        cumsum = cumsum / len(data)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.\n",
    "    ax.step(bin_centers, cumsum, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_matrix_indices(matrix, num_clusters):\n",
    "    \"\"\"\n",
    "    Clusters matrix using k-means. Always clusters on the first\n",
    "    axis. Returns the indices needed to optimally order the matrix\n",
    "    by clusters.\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        # Don't cluster at all\n",
    "        return np.array([0])\n",
    "\n",
    "    num_clusters = min(num_clusters, len(matrix))\n",
    "    \n",
    "    # Perform k-means clustering\n",
    "    kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=num_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(matrix)\n",
    "\n",
    "    # Order cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = np.argsort(-np.mean(kmeans_centers, axis=1))\n",
    "\n",
    "    # Order the peaks so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "    return cluster_inds, cluster_assignments[cluster_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif_examples(motif_keys, motifs, cond_names, cond_inds):\n",
    "    \"\"\"\n",
    "    Creates a table of motifs. The full set of motifs and keys\n",
    "    are given, and `cond_names` and `cond_inds` are parallel lists\n",
    "    containing conditions and a list of indices to plot for each.\n",
    "    A pair of columns is created for each condition.\n",
    "    \"\"\"\n",
    "    assert len(cond_names) == len(cond_inds)\n",
    "    cols = []\n",
    "    heads = []\n",
    "    for i in range(len(cond_names)):\n",
    "        cols.append(vdomh.col(style={\"width\": str(10 / len(cond_inds)) + \"%\"}))\n",
    "        cols.append(vdomh.col(style={\"width\": str(90 / len(cond_inds)) + \"%\"}))\n",
    "        heads.append(vdomh.th(\"Motif ID\", style={\"text-align\": \"center\"}))\n",
    "        heads.append(vdomh.th(\"Motif (%s)\" % cond_names[i], style={\"text-align\": \"center\"}))\n",
    "    colgroup = vdomh.colgroup(*cols)\n",
    "    header = vdomh.thead(vdomh.tr(*heads))\n",
    "\n",
    "    max_length = max([len(inds) for inds in cond_inds])\n",
    "    rows = []\n",
    "    for row_i in range(max_length):\n",
    "        row = []\n",
    "        for col_i in range(len(cond_names)):\n",
    "            if row_i < len(cond_inds[col_i]):\n",
    "                motif_i = cond_inds[col_i][row_i]\n",
    "                fig = viz_sequence.plot_weights(\n",
    "                    motifs[motif_i], subticks_frequency=100, figsize=(20, 4), return_fig=True\n",
    "                )\n",
    "                fig.tight_layout()\n",
    "                row.extend([\n",
    "                    vdomh.td(motif_keys[motif_i]),\n",
    "                    vdomh.td(figure_to_vdom_image(fig))\n",
    "                ])\n",
    "            else:\n",
    "                row.extend([vdomh.td(), vdomh.td()])\n",
    "        rows.append(vdomh.tr(*row))\n",
    "    display(vdomh.table(colgroup, header, vdomh.tbody(*rows)))\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import motifs and construct similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_keys, motifs = zip(*import_all_tfmodisco_motifs(motif_file).items())\n",
    "motif_keys, motifs = list(motif_keys), list(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sim_matrix = create_motif_similarity_matrix(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of seqlest for each motif\n",
    "motif_num_seqlets = np.array([\n",
    "    get_num_seqlets(key) for key in tqdm.notebook.tqdm(motif_keys)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot similarity of each motif to closest motif in each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a dictionary mapping each condition to the column indices\n",
    "cond_inds = {}\n",
    "for i, key in enumerate(motif_keys):\n",
    "    cond_key = \":\".join(key.split(\":\")[:-2])  # Strip off last two pieces\n",
    "    try:\n",
    "        cond_inds[cond_key].append(i)\n",
    "    except KeyError:\n",
    "        cond_inds[cond_key] = [i]\n",
    "for key in list(cond_inds.keys()):\n",
    "    cond_inds[key] = np.array(cond_inds[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the number of seqlets over each condition separately\n",
    "motif_prop_seqlets = np.empty(len(motif_num_seqlets))\n",
    "for inds in cond_inds.values():\n",
    "    motif_prop_seqlets[inds] = motif_num_seqlets[inds] / np.sum(motif_num_seqlets[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a limited version of the similarity matrix, where the columns\n",
    "# are the highest similarity over the entire condition\n",
    "cond_sim_matrix = np.empty((len(motif_keys), len(cond_inds)))\n",
    "for i, cond_key in enumerate(cond_inds.keys()):\n",
    "    cond_sim_matrix[:, i] = np.max(raw_sim_matrix[:, cond_inds[cond_key]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order similarity matrix rows by optimal cluster order\n",
    "order_inds, cluster_ids = cluster_matrix_indices(\n",
    "    cond_sim_matrix,\n",
    "    max([len(inds) for inds in cond_inds.values()])\n",
    "    # Maximum number of clusters should be biggest condition size\n",
    ")\n",
    "cond_sim_matrix = cond_sim_matrix[order_inds]\n",
    "\n",
    "# Order motif keys and motifs\n",
    "sorted_motif_keys = [motif_keys[i] for i in order_inds]\n",
    "sorted_motifs = [motifs[i] for i in order_inds]\n",
    "sorted_motif_prop_seqlets = np.array([motif_prop_seqlets[i] for i in order_inds])\n",
    "\n",
    "# Sort each matrix row independently, most to least similar\n",
    "cond_sim_matrix = -np.sort(-cond_sim_matrix, axis=1)  # Negatives make it sort descending\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "make_cdf(ax, np.ravel(cond_sim_matrix), density=True)\n",
    "ax.set_title(\"CDF of similarities\")\n",
    "ax.set_xlabel(\"Similarity score\")\n",
    "plt.show()\n",
    "\n",
    "# Normalize the matrix entries to percentile\n",
    "cond_sim_matrix_perc = scipy.stats.rankdata(cond_sim_matrix).reshape(cond_sim_matrix.shape) / cond_sim_matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Motif prevalence by seqlets\")\n",
    "ax.set_xlabel(\"Motif rank by reproducibility\")\n",
    "ax.set_ylabel(\"Fraction of seqlets\")\n",
    "ax.plot(sorted_motif_prop_seqlets)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the CWM score of each motif in order\n",
    "sorted_motif_scores = np.array([np.max(cwm) for cwm in sorted_motifs])\n",
    "\n",
    "# Separate out profile and count CWMs\n",
    "profile_inds = np.array([i for i in range(len(sorted_motif_keys)) if sorted_motif_keys[i].split(\":\")[-2] == \"P\"])\n",
    "count_inds = np.array([i for i in range(len(sorted_motif_keys)) if sorted_motif_keys[i].split(\":\")[-2] == \"C\"])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "make_cdf(ax, sorted_motif_scores[profile_inds], density=True, label=\"Profile\")\n",
    "make_cdf(ax, sorted_motif_scores[count_inds], density=True, label=\"Count\")\n",
    "ax.set_title(\"CDF of CWM score\")\n",
    "ax.set_xlabel(\"CWM score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Normalize the CWM scores to map to percentile (i.e. map CDF x-axis to y-axis)\n",
    "# Do counts/profile CWMs separately\n",
    "sorted_motif_score_percs = np.empty_like(sorted_motif_scores)\n",
    "sorted_motif_score_percs[profile_inds] = scipy.stats.rankdata(sorted_motif_scores[profile_inds]) / len(profile_inds)\n",
    "sorted_motif_score_percs[count_inds] = scipy.stats.rankdata(sorted_motif_scores[count_inds]) / len(count_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "height = max(5, len(motif_keys) * 0.2) + 1\n",
    "width = max(5, len(cond_inds) * 0.1) + 4\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=2, ncols=4, figsize=(width, height),\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [(width - 6) / 0.1, 2, 2, 2],\n",
    "        \"height_ratios\": [height / 0.2, 1],\n",
    "        \"wspace\": 0.1,\n",
    "        \"hspace\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "hmap = ax[0, 0].imshow(cond_sim_matrix_perc, cmap=\"Greys_r\", aspect=\"auto\")  # auto aspect to stretch\n",
    "ax[0, 1].imshow(sorted_motif_score_percs[:, None], cmap=\"Greys_r\", aspect=\"auto\")\n",
    "ax[0, 2].imshow(sorted_motif_prop_seqlets[:, None], cmap=\"Greys_r\", aspect=\"auto\")\n",
    "\n",
    "# Cluster IDs may not be in order, so sort the groups\n",
    "diffs = np.concatenate([[0], np.diff(cluster_ids)])\n",
    "diffs[diffs != 0] = 1\n",
    "reordered_cluster_ids = np.cumsum(diffs)\n",
    "ax[0, 3].imshow(reordered_cluster_ids[:, None] % 20 / 20, cmap=\"tab20\", aspect=\"auto\")\n",
    "\n",
    "ax[0, 0].set_yticks(np.arange(len(motif_keys)))\n",
    "ax[0, 0].set_yticklabels(sorted_motif_keys)\n",
    "ax[0, 0].set_xticks([])\n",
    "ax[0, 0].set_title(\"Similarity of closest motif\")\n",
    "ax[0, 1].set_title(\"CWM\")\n",
    "ax[0, 2].set_title(\"#Seq\")\n",
    "ax[0, 3].set_title(\"Grp\")\n",
    "\n",
    "for i in range(1, 4):\n",
    "    ax[0, i].set_yticks([])\n",
    "    ax[0, i].set_xticks([])\n",
    "    ax[1, i].axis(\"off\")\n",
    "\n",
    "fig.colorbar(hmap, cax=ax[1, 0], orientation=\"horizontal\")\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"%s_fold_model_motif_reproducibility.svg\" % tf_name),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show some examples of motifs in each cluster, from highest to lowest reproducibility\n",
    "num_examples_to_show = 5\n",
    "cmap = cm.get_cmap(\"tab20\")\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "for cluster_id in np.unique(reordered_cluster_ids):\n",
    "    match_inds = np.where(reordered_cluster_ids == cluster_id)[0]\n",
    "    display(vdomh.h3(\"Cluster %d (%d motifs)\" % (cluster_id, len(match_inds))))\n",
    "    \n",
    "    group_color = matplotlib.colors.rgb2hex(cmap(cluster_id % 20 / 20))\n",
    "    fig, ax = plt.subplots(figsize=(1, 1))\n",
    "    circle = plt.Circle((0, 0), 10, color=group_color)\n",
    "    ax.add_patch(circle)\n",
    "    ax.axis(\"off\")\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()\n",
    "    \n",
    "    colgroup = vdomh.colgroup(\n",
    "        vdomh.col(style={\"width\": \"10%\"}),\n",
    "        vdomh.col(style={\"width\": \"90%\"})\n",
    "    )\n",
    "    header = vdomh.thead(vdomh.tr(\n",
    "        vdomh.th(\"Motif ID\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Motif\", style={\"text-align\": \"center\"})\n",
    "    ))\n",
    "\n",
    "    rows = []\n",
    "    inds_to_show = rng.choice(match_inds, size=min(num_examples_to_show, len(match_inds)), replace=False)\n",
    "    for i in inds_to_show:\n",
    "        fig = viz_sequence.plot_weights(\n",
    "            sorted_motifs[i], subticks_frequency=100, figsize=(20, 4), return_fig=True\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(out_path, \"%s_cluster_%d_motif_%s.svg\" % (tf_name, cluster_id, sorted_motif_keys[i])),\n",
    "            format=\"svg\"\n",
    "        )\n",
    "        rows.append(vdomh.tr(\n",
    "            vdomh.td(sorted_motif_keys[i]),\n",
    "            vdomh.td(figure_to_vdom_image(fig))\n",
    "        ))\n",
    "    display(vdomh.table(colgroup, header, vdomh.tbody(*rows)))\n",
    "    plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
