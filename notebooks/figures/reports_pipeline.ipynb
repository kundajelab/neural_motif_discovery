{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/notebooks/reports/\"))\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "import util\n",
    "import motif.match_motifs as match_motifs\n",
    "import motif.read_motifs as read_motifs\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import sklearn.cluster\n",
    "import scipy.cluster.hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"svg.fonttype\": \"none\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/users/amtseng/tfmodisco/figures/reports_pipeline\"\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = \"/users/amtseng/tfmodisco/results/\"\n",
    "\n",
    "motif_file_path = os.path.join(results_base, \"motifs/tfmodisco/SPI1_tfmodisco_cpmerged_motifs.h5\")\n",
    "\n",
    "seqlets_file_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/tfmodisco_results/cache\",\n",
    "    \"multitask_profile_finetune/E2F6_multitask_profile_finetune_fold1/E2F6_multitask_profile_finetune_fold1_profile/0_1_seqlets.npz\"\n",
    ")\n",
    "\n",
    "tomtom_query_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/tfmodisco_results/cache\",\n",
    "    \"multitask_profile_finetune/FOXA2_multitask_profile_finetune_fold7/FOXA2_multitask_profile_finetune_fold7_profile\",\n",
    "    \"tomtom/metacluster_0/query_motifs.txt\"\n",
    ")\n",
    "tomtom_results_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/tfmodisco_results/cache\",\n",
    "    \"multitask_profile_finetune/FOXA2_multitask_profile_finetune_fold7/FOXA2_multitask_profile_finetune_fold7_profile\",\n",
    "    \"tomtom/metacluster_0/tomtom/tomtom.tsv\"\n",
    ")\n",
    "tomtom_database = match_motifs.import_database_pfms(match_motifs.DATABASE_PATH)\n",
    "\n",
    "motif_subclusters_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_clustering/cache\",\n",
    "    \"multitask_profile_finetune/E2F6_multitask_profile_finetune_fold1/E2F6_multitask_profile_finetune_fold1_profile\",\n",
    "    \"all_motif_subclusters.h5\"\n",
    ")\n",
    "\n",
    "heatmap_file_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_heatmaps/cache\",\n",
    "    \"multitask_profile_finetune/SPI1_multitask_profile_finetune_task0/motif_clusters.h5\"\n",
    ")\n",
    "\n",
    "hits_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_hits/cache/tfm\",\n",
    "    \"BPNet/BPNet_Nanog_ChIPseq/BPNet_Nanog_ChIPseq_profile\",\n",
    "    \"filtered_hits.tsv\"\n",
    ")\n",
    "peak_hits_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_hits/cache/tfm\",\n",
    "    \"BPNet/BPNet_Nanog_ChIPseq/BPNet_Nanog_ChIPseq_profile\",\n",
    "    \"peak_matched_hits.tsv\"\n",
    ")\n",
    "\n",
    "cooccurrence_tfm_path = os.path.join(\n",
    "    results_base,\n",
    "    \"tfmodisco/BPNet/BPNet_Nanog_ChIPseq/BPNet_Nanog_ChIPseq_profile_tfm.h5\"\n",
    ")\n",
    "cooccurrence_file_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_hits/cache/tfm\",\n",
    "    \"BPNet/BPNet_Nanog_ChIPseq/BPNet_Nanog_ChIPseq_profile\",\n",
    "    \"cooccurrences.h5\"\n",
    ")\n",
    "cooccurrence_dist_path = os.path.join(\n",
    "    results_base,\n",
    "    \"reports/motif_hits/cache/tfm\",\n",
    "    \"BPNet/BPNet_Nanog_ChIPseq/BPNet_Nanog_ChIPseq_profile\",\n",
    "    \"intermotif_dists.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(motif_file_path, \"r\") as f:\n",
    "    motif_dset = f[\"multitask_finetune\"][\"task_agg\"][\"C0_0:P0_0\"]\n",
    "    pfm = motif_dset[\"pfm_trimmed\"][:]\n",
    "    cwm = motif_dset[\"cwm_trimmed\"][:]\n",
    "    hcwm = motif_dset[\"hcwm_trimmed\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwm_fig = viz_sequence.plot_weights(read_motifs.pfm_to_pwm(pfm), subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_repr_pwm.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "cwm_fig = viz_sequence.plot_weights(cwm, subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_repr_cwm.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "hcwm_fig = viz_sequence.plot_weights(hcwm, subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_repr_hcwm.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlet_dict = np.load(seqlets_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_profs = seqlet_dict[\"seqlet_true_profs\"]\n",
    "pred_profs = seqlet_dict[\"seqlet_pred_profs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlet_true_profs = np.reshape(true_profs, (-1, true_profs.shape[2], true_profs.shape[3]))\n",
    "seqlet_pred_profs = np.reshape(pred_profs, (-1, pred_profs.shape[2], pred_profs.shape[3]))\n",
    "\n",
    "assert len(seqlet_true_profs.shape) == 3\n",
    "assert seqlet_true_profs.shape == seqlet_pred_profs.shape\n",
    "num_profs, width, _ = seqlet_true_profs.shape\n",
    "\n",
    "# First, normalize the profiles along the output profile dimension\n",
    "def normalize(arr, axis=0):\n",
    "    arr_sum = np.sum(arr, axis=axis, keepdims=True)\n",
    "    arr_sum[arr_sum == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "    return arr / arr_sum\n",
    "true_profs_norm = normalize(seqlet_true_profs, axis=1)\n",
    "pred_profs_norm = normalize(seqlet_pred_profs, axis=1)\n",
    "\n",
    "# Compute the mean profiles across all examples\n",
    "true_profs_mean = np.mean(true_profs_norm, axis=0)\n",
    "pred_profs_mean = np.mean(pred_profs_norm, axis=0)\n",
    "\n",
    "# Perform k-means clustering on the predicted profiles, with the strands pooled\n",
    "kmeans_clusters = max(5, num_profs // 50)  # Set number of clusters based on number of profiles, with minimum\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=kmeans_clusters)\n",
    "cluster_assignments = kmeans.fit_predict(\n",
    "    np.reshape(pred_profs_norm, (pred_profs_norm.shape[0], -1))\n",
    ")\n",
    "\n",
    "# Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "kmeans_centers = kmeans.cluster_centers_\n",
    "cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "    scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "        scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "    )\n",
    ")\n",
    "\n",
    "# Order the profiles so that the cluster assignments follow the optimal ordering\n",
    "cluster_inds = []\n",
    "for cluster_id in cluster_order:\n",
    "    cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "cluster_inds = np.concatenate(cluster_inds)\n",
    "\n",
    "# Compute a matrix of profiles, normalized to the maximum height, ordered by clusters\n",
    "def make_profile_matrix(flat_profs, order_inds):\n",
    "    matrix = flat_profs[order_inds]\n",
    "    maxes = np.max(matrix, axis=1, keepdims=True)\n",
    "    maxes[maxes == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "    return matrix / maxes\n",
    "true_matrix = make_profile_matrix(true_profs_norm, cluster_inds)\n",
    "pred_matrix = make_profile_matrix(pred_profs_norm, cluster_inds)\n",
    "\n",
    "# Create a figure with the right dimensions\n",
    "mean_height = 4\n",
    "heatmap_height = min(num_profs * 0.004, 8)\n",
    "fig_height = mean_height + (2 * heatmap_height)\n",
    "fig, ax = plt.subplots(\n",
    "    3, 2, figsize=(16, fig_height), sharex=True,\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [1, 1],\n",
    "        \"height_ratios\": [mean_height / fig_height, heatmap_height / fig_height, heatmap_height / fig_height]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot the average predictions\n",
    "ax[0, 0].plot(true_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "ax[0, 0].plot(-true_profs_mean[:, 1], color=\"darkorange\")\n",
    "ax[0, 1].plot(pred_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "ax[0, 1].plot(-pred_profs_mean[:, 1], color=\"darkorange\")\n",
    "\n",
    "# Set axes on average predictions\n",
    "max_mean_val = max(np.max(true_profs_mean), np.max(pred_profs_mean))\n",
    "mean_ylim = max_mean_val * 1.05  # Make 5% higher\n",
    "ax[0, 0].set_title(\"True profiles\")\n",
    "ax[0, 0].set_ylabel(\"Average probability\")\n",
    "ax[0, 1].set_title(\"Predicted profiles\")\n",
    "for j in (0, 1):\n",
    "    ax[0, j].set_ylim(-mean_ylim, mean_ylim)\n",
    "    ax[0, j].label_outer()\n",
    "\n",
    "# Plot the heatmaps\n",
    "ax[1, 0].imshow(true_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "ax[1, 1].imshow(pred_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "ax[2, 0].imshow(true_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "ax[2, 1].imshow(pred_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "\n",
    "# Set axes on heatmaps\n",
    "for i in (1, 2):\n",
    "    for j in (0, 1):\n",
    "        ax[i, j].set_yticks([])\n",
    "        ax[i, j].set_yticklabels([])\n",
    "        ax[i, j].label_outer()\n",
    "width = true_matrix.shape[1]\n",
    "delta = 100\n",
    "num_deltas = (width // 2) // delta\n",
    "labels = list(range(max(-width // 2, -num_deltas * delta), min(width // 2, num_deltas * delta) + 1, delta))\n",
    "tick_locs = [label + max(width // 2, num_deltas * delta) for label in labels]\n",
    "for j in (0, 1):\n",
    "    ax[2, j].set_xticks(tick_locs)\n",
    "    ax[2, j].set_xticklabels(labels)\n",
    "    ax[2, j].set_xlabel(\"Distance from seqlet center (bp)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"profile_footprints.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summit distance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summit_dists = seqlet_dict[\"summit_dists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "num_bins = 50\n",
    "plt.hist(summit_dists, bins=num_bins, color=\"purple\")\n",
    "plt.title(\"Histogram of distance of seqlets to peak summits\")\n",
    "plt.xlabel(\"Signed distance from seqlet center to nearest peak summit (bp)\")\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"summit_dists.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOMTOM matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import motif of interest\n",
    "motif_index = 0\n",
    "with open(tomtom_query_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.strip() == \"MOTIF %d\" % motif_index:\n",
    "            motif = []\n",
    "            next(f)  # Get rid of header\n",
    "            line = next(f).strip()\n",
    "            while line:\n",
    "                motif.append(np.array([float(x) for x in line.split()]))\n",
    "                line = next(f).strip()\n",
    "            break\n",
    "query_motif = np.stack(motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TOMTOM hits\n",
    "tomtom_hits = pd.read_csv(tomtom_results_path, sep=\"\\t\", header=0, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tomtom_hits[tomtom_hits[\"Query_ID\"] == str(motif_index)].head(5).reset_index().iterrows():\n",
    "    match_id, q_val = row[\"Target_ID\"], row[\"q-value\"]\n",
    "    print(\"%s (q-val = %s)\" % (match_id, q_val))\n",
    "    match_motif = tomtom_database[match_id]\n",
    "    match_fig = viz_sequence.plot_weights(read_motifs.pfm_to_pwm(match_motif), subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "    plt.savefig(\n",
    "        os.path.join(out_path, \"tomtom_match_%d.svg\" % i),\n",
    "        format=\"svg\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fig = viz_sequence.plot_weights(read_motifs.pfm_to_pwm(query_motif), subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"tomtom_query.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intramotif heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_key = \"0_0\"\n",
    "\n",
    "sub_motifs = []\n",
    "with h5py.File(motif_subclusters_path, \"r\") as f:\n",
    "    embeddings = f[motif_key][\"embeddings\"][:]\n",
    "    clusters = f[motif_key][\"clusters\"][:]\n",
    "    for sub_key in f[motif_key]:\n",
    "        if sub_key.startswith(\"subcluster_\"):\n",
    "            sub_motifs.append(f[motif_key][sub_key][\"hcwm_trimmed\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.scatter(\n",
    "    embeddings[:,0], embeddings[:,1], c=clusters, cmap=\"tab20\", alpha=0.3\n",
    ")\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"subcluster_embeddings.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcluster_inds = [0, 1]\n",
    "for i in subcluster_inds:\n",
    "    sub_motif_fig = viz_sequence.plot_weights(sub_motifs[i], subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "    plt.savefig(\n",
    "        os.path.join(out_path, \"subcluster_hcwm_%d.svg\" % i),\n",
    "        format=\"svg\"\n",
    "    )\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.scatter(\n",
    "        embeddings[:,0], embeddings[:,1], c=(clusters == i), alpha=0.3\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermotif heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(heatmap_file_path, \"r\") as f:\n",
    "    dendrogram_order = f[\"dendrogram_order\"][:]\n",
    "    sim_matrix = f[\"similarity_matrix\"][:]\n",
    "    labels = list(f[\"all_motifs\"].keys())\n",
    "    motifs = [f[\"all_motifs\"][label][:] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters(linkage, goal_clusters, tolerance=(-2, 2), start=50, max_iter=10):\n",
    "    \"\"\"\n",
    "    From a linkage map, computes clusters with a goal of `goal_clusters` clusters.\n",
    "    Will allow the given tolerance. `start` is what distance threshold to check first.\n",
    "    `max_iter` is the maximum number of checks to do.\n",
    "    Returns the clustering.\n",
    "    \"\"\"\n",
    "    clusters = scipy.cluster.hierarchy.fcluster(\n",
    "        linkage, start, criterion=\"distance\"\n",
    "    )\n",
    "    \n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    if num_clusters > goal_clusters + tolerance[1] and max_iter:\n",
    "        return compute_clusters(linkage, goal_clusters, tolerance, start * 2, max_iter - 1)\n",
    "    elif num_clusters < goal_clusters - tolerance[0] and max_iter:\n",
    "        return compute_clusters(linkage, goal_clusters, tolerance, start / 2, max_iter - 1)\n",
    "    else:\n",
    "        return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = scipy.cluster.hierarchy.linkage(sim_matrix, method=\"ward\")\n",
    "expected_clusters = 12\n",
    "clusters = compute_clusters(linkage, expected_clusters, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=2, ncols=2, figsize=(20, 20),\n",
    "    gridspec_kw={\n",
    "        \"width_ratios\": [20, 1],\n",
    "        \"height_ratios\": [1, 4],\n",
    "        \"hspace\": 0,\n",
    "        \"wspace\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "cluster_color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "default_cluster_color = \"gray\"\n",
    "\n",
    "# Compute the color of every link based on cluster assignments\n",
    "# Adapted from https://stackoverflow.com/questions/38153829/custom-cluster-colors-of-scipy-dendrogram-in-python-link-color-func\n",
    "leaf_colors = [cluster_color_cycle[i % len(cluster_color_cycle)] for i in clusters]\n",
    "link_colors = {}\n",
    "for i, i_link in enumerate(linkage[:, :2].astype(int)):\n",
    "    color_0 = link_colors[i_link[0]] if i_link[0] > len(linkage) else leaf_colors[i_link[0]]\n",
    "    color_1 = link_colors[i_link[1]] if i_link[1] > len(linkage) else leaf_colors[i_link[1]]\n",
    "    link_colors[i + 1 + len(linkage)] = color_0 if color_0 == color_1 else default_cluster_color\n",
    "\n",
    "dend = scipy.cluster.hierarchy.dendrogram(\n",
    "    linkage, ax=ax[0, 0], link_color_func=(lambda x: link_colors[x])\n",
    ")\n",
    "\n",
    "order_inds = dend[\"leaves\"]\n",
    "sim_matrix_reordered = sim_matrix[:, order_inds][order_inds, :]\n",
    "heatmap = ax[1, 0].imshow(sim_matrix_reordered, aspect=\"auto\", cmap=\"Blues\")\n",
    "ax[1, 0].set_yticks([])\n",
    "ax[1, 0].set_xticks(range(len(sim_matrix)))\n",
    "ax[1, 0].set_xticklabels(np.array(labels)[order_inds], rotation=90, fontsize=10)\n",
    "\n",
    "fig.colorbar(heatmap, cax=ax[1, 1])\n",
    "\n",
    "ax[0, 0].axis(\"off\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_heatmap.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = 12\n",
    "match_inds = np.where(clusters == cluster_id)[0]\n",
    "\n",
    "matches = [motifs[i] for i in match_inds]\n",
    "for i, match in enumerate(matches):\n",
    "    print(labels[i])\n",
    "    match_fig = viz_sequence.plot_weights(match, subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "    plt.savefig(\n",
    "        os.path.join(out_path, \"motif_heatmap_const_%d.svg\" % i),\n",
    "        format=\"svg\"\n",
    "    )\n",
    "    plt.show()\n",
    "print(\"Aggregate\")\n",
    "agg = util.aggregate_motifs(matches)\n",
    "agg_fig = viz_sequence.plot_weights(agg, subticks_frequency=100, figsize=(20, 4), return_fig=True)\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_heatmap_agg.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif hit distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hits table and peak - hit mapping table\n",
    "hit_table = pd.read_csv(hits_path, sep=\"\\t\", header=0, index_col=0)\n",
    "peak_hit_table = pd.read_csv(peak_hits_path, sep=\"\\t\", header=0, index_col=False)\n",
    "peak_hit_table[\"filtered_hit_indices\"] = peak_hit_table[\"filtered_hit_indices\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_keys = np.unique(hit_table[\"key\"])\n",
    "\n",
    "motif_key_to_motif_index = {motif_keys[i] : i for i in range(len(motif_keys))}\n",
    "hit_ind_to_motif_index = hit_table[\"key\"].apply(lambda k: motif_key_to_motif_index[k]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct N x M array for N peaks and M motifs, holding the counts of each motif in each peak\n",
    "peak_hit_counts = np.zeros((len(peak_hit_table), len(motif_keys)), dtype=int)\n",
    "for _, row in peak_hit_table.iterrows():\n",
    "    peak_ind, hit_inds = row[\"peak_index\"], row[\"filtered_hit_indices\"]\n",
    "    if hit_inds != \"nan\":\n",
    "        hit_inds = np.array([int(x) for x in hit_inds.split(\",\")])\n",
    "        for hit_ind in hit_inds:\n",
    "            peak_hit_counts[peak_ind, hit_ind_to_motif_index[hit_ind]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of motif hits per peak\n",
    "motifs_per_peak = np.sum(peak_hit_counts, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "bins = np.concatenate([np.arange(np.max(motifs_per_peak) + 1), [np.inf]])\n",
    "ax.hist(motifs_per_peak, bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "ax.set_title(\"Cumulative distribution of number of motif hits per peak\")\n",
    "ax.set_xlabel(\"Number of motifs k in peak\")\n",
    "ax.set_ylabel(\"Proportion of peaks with at least k motifs\")\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"motif_hits_per_peak.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of peaks with each motif\n",
    "frac_peaks_with_motif = np.sum(peak_hit_counts > 0, axis=0) / len(peak_hit_counts)\n",
    "labels = np.array(motif_keys)\n",
    "sorted_inds = np.flip(np.argsort(frac_peaks_with_motif))\n",
    "frac_peaks_with_motif = frac_peaks_with_motif[sorted_inds]\n",
    "labels = labels[sorted_inds]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.bar(np.arange(len(labels)), frac_peaks_with_motif)\n",
    "ax.set_title(\"Proportion of peaks with each motif\")\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"peaks_per_motif_type.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of motif hits per peak for a single motif\n",
    "motif_key = \"0_1\"\n",
    "\n",
    "motifs_per_peak = peak_hit_counts[:, motif_key_to_motif_index[motif_key]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "bins = np.concatenate([np.arange(np.max(motifs_per_peak) + 1), [np.inf]])\n",
    "ax.hist(motifs_per_peak, bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "ax.set_title(\"Cumulative distribution of number of motif hits per peak\")\n",
    "ax.set_xlabel(\"Number of motifs k in peak\")\n",
    "ax.set_ylabel(\"Proportion of peaks with at least k motifs\")\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"single_motifs_per_peak.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurrence heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_motifs(tfm_results_path, trim=True, only_pos=True):\n",
    "    \"\"\"\n",
    "    Imports the PFMs to into a dictionary, mapping `(x, y)` to the PFM,\n",
    "    where `x` is the metacluster index and `y` is the pattern index.\n",
    "    Arguments:\n",
    "        `tfm_results_path`: path to HDF5 containing TF-MoDISco results\n",
    "        `out_dir`: where to save motifs\n",
    "        `trim`: if True, trim the motif flanks based on information content\n",
    "        `only_pos`: if True, only return motifs with positive contributions\n",
    "    Returns the dictionary of PFMs.\n",
    "    \"\"\" \n",
    "    pfms = {}\n",
    "    with h5py.File(tfm_results_path, \"r\") as f:\n",
    "        metaclusters = f[\"metacluster_idx_to_submetacluster_results\"]\n",
    "        num_metaclusters = len(metaclusters.keys())\n",
    "        for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "            metacluster = metaclusters[metacluster_key]\n",
    "            if \"patterns\" not in metacluster[\"seqlets_to_patterns_result\"]:\n",
    "                continue\n",
    "            patterns = metacluster[\"seqlets_to_patterns_result\"][\"patterns\"]\n",
    "            num_patterns = len(patterns[\"all_pattern_names\"][:])\n",
    "            for pattern_i, pattern_name in enumerate(patterns[\"all_pattern_names\"][:]):\n",
    "                pattern_name = pattern_name.decode()\n",
    "                pattern = patterns[pattern_name]\n",
    "                pfm = pattern[\"sequence\"][\"fwd\"][:]\n",
    "                cwm = pattern[\"task0_contrib_scores\"][\"fwd\"][:]\n",
    "                \n",
    "                # Check that the contribution scores are overall positive\n",
    "                if only_pos and np.sum(cwm) < 0:\n",
    "                    continue\n",
    "                    \n",
    "                if trim:\n",
    "                    pfm = read_motifs.trim_motif_by_ic(pfm, pfm)\n",
    "                    \n",
    "                pfms[\"%d_%d\" % (metacluster_i,pattern_i)] = pfm\n",
    "    return pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PFMs\n",
    "pfms = import_tfmodisco_motifs(cooccurrence_tfm_path)\n",
    "motif_keys = list(pfms.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cooccurrence_file_path, \"r\") as f:\n",
    "    pval_matrix = f[\"pvals\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_matrix_indices(matrix, num_clusters):\n",
    "    \"\"\"\n",
    "    Clusters matrix using k-means. Always clusters on the first\n",
    "    axis. Returns the indices needed to optimally order the matrix\n",
    "    by clusters.\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        # Don't cluster at all\n",
    "        return np.array([0])\n",
    "\n",
    "    num_clusters = min(num_clusters, len(matrix))\n",
    "    \n",
    "    # Perform k-means clustering\n",
    "    kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=num_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(matrix)\n",
    "\n",
    "    # Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "            scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Order the peaks so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "    return cluster_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 6  # Only show top pairs\n",
    "\n",
    "# Cluster by p-value\n",
    "num_motifs = len(pval_matrix)\n",
    "inds = cluster_matrix_indices(pval_matrix, max(5, num_motifs // 4))\n",
    "pval_matrix_ordered = pval_matrix[inds][:, inds]\n",
    "motif_keys_ordered = np.array(motif_keys)[inds]\n",
    "\n",
    "# Plot the p-value matrix\n",
    "\n",
    "fig_width = max(5, top_k)\n",
    "p_fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n",
    "\n",
    "# Replace 0s with minimum value (we'll label them properly later)\n",
    "zero_mask = pval_matrix_ordered == 0\n",
    "non_zeros = pval_matrix_ordered[~zero_mask]\n",
    "if not len(non_zeros):\n",
    "    logpval_matrix = np.tile(np.inf, pval_matrix_ordered.shape)\n",
    "else:\n",
    "    min_val = np.min(pval_matrix_ordered[~zero_mask])\n",
    "    pval_matrix_ordered[zero_mask] = min_val\n",
    "    logpval_matrix = -np.log10(pval_matrix_ordered)\n",
    "\n",
    "hmap = ax.imshow(logpval_matrix[:top_k, :top_k])\n",
    "\n",
    "ax.set_xticks(np.arange(top_k))\n",
    "ax.set_yticks(np.arange(top_k))\n",
    "ax.set_xticklabels(motif_keys_ordered[:top_k], rotation=45)\n",
    "ax.set_yticklabels(motif_keys_ordered[:top_k])\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(top_k):\n",
    "    for j in range(top_k):\n",
    "        if zero_mask[i, j]:\n",
    "            text = \"Inf\"\n",
    "        else:\n",
    "            text = \"%.2f\" % np.abs(logpval_matrix[i, j])\n",
    "        ax.text(j, i, text, ha=\"center\", va=\"center\")\n",
    "p_fig.colorbar(hmap, orientation=\"horizontal\")\n",
    "\n",
    "ax.set_title(\"-log(p) significance of peaks with both motifs\")\n",
    "p_fig.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"cooccur_heatmap.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurrence distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cooccurrence_dist_path, \"r\") as f:\n",
    "    distance_dict = {}\n",
    "    for key in f.keys():\n",
    "        distance_dict[tuple(key.split(\":\"))] = f[key][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_violin_plot(ax, dist_list, colors):\n",
    "    \"\"\"\n",
    "    Creates a violin plot on the given instantiated axes.\n",
    "    `dist_list` is a list of vectors. `colors` is a parallel\n",
    "    list of colors for each violin.\n",
    "    \"\"\"\n",
    "    num_perfs = len(dist_list)\n",
    "\n",
    "    q1, med, q3 = np.stack([\n",
    "        np.nanpercentile(data, [25, 50, 70], axis=0) for data in dist_list\n",
    "    ], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    lower_outlier = q1 - (1.5 * iqr)\n",
    "    upper_outlier = q3 + (1.5 * iqr)\n",
    "\n",
    "\n",
    "    sorted_clipped_data = [  # Remove outliers based on outlier rule\n",
    "        np.sort(vec[(vec >= lower_outlier[i]) & (vec <= upper_outlier[i])])\n",
    "        for i, vec in enumerate(dist_list)\n",
    "    ]\n",
    "\n",
    "    plot_parts = ax.violinplot(\n",
    "        sorted_clipped_data, showmeans=False, showmedians=False, showextrema=False\n",
    "    )\n",
    "    violin_parts = plot_parts[\"bodies\"]\n",
    "    for i in range(num_perfs):\n",
    "        violin_parts[i].set_facecolor(colors[i])\n",
    "        violin_parts[i].set_edgecolor(colors[i])\n",
    "        violin_parts[i].set_alpha(0.7)\n",
    "\n",
    "    inds = np.arange(1, num_perfs + 1)\n",
    "    ax.vlines(inds, q1, q3, color=\"black\", linewidth=5, zorder=1)\n",
    "    ax.scatter(inds, med, marker=\"o\", color=\"white\", s=30, zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=top_k, ncols=top_k, figsize=(top_k * 4, top_k * 4)\n",
    ")\n",
    "if type(ax) is not np.ndarray:\n",
    "    ax = np.array([[ax]])\n",
    "\n",
    "# Map motif key to axis index\n",
    "key_to_index = dict(zip(motif_keys_ordered, np.arange(len(motif_keys_ordered))))\n",
    "\n",
    "def clean_subplot(ax):\n",
    "    # Do this instead of ax.axis(\"off\"), which would also remove any\n",
    "    # axis labels\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    for orient in (\"top\", \"bottom\", \"left\", \"right\"):\n",
    "        ax.spines[orient].set_visible(False)\n",
    "\n",
    "# Create violins\n",
    "for i in range(top_k):\n",
    "    for j in range(i, top_k):\n",
    "        key_1, key_2 = motif_keys_ordered[i], motif_keys_ordered[j]\n",
    "        key_pair, rev_key_pair = (key_1, key_2), (key_2, key_1)\n",
    "        axis_1, axis_2 = key_to_index[key_1], key_to_index[key_2]\n",
    "        # Always plot lower triangle\n",
    "        if axis_1 < axis_2:\n",
    "            axis_1, axis_2 = axis_2, axis_1\n",
    "\n",
    "        if key_pair in distance_dict or rev_key_pair in distance_dict:\n",
    "            if rev_key_pair in distance_dict:\n",
    "                key_pair = rev_key_pair\n",
    "            dist = distance_dict[key_pair] \n",
    "            create_violin_plot(ax[axis_1, axis_2], [dist], [\"mediumorchid\"])\n",
    "            ax[axis_1, axis_2].set_xticks([])  # Remove x-axis labels, as they don't mean much\n",
    "            if axis_1 != axis_2:\n",
    "                # If off diagonal, clean the axes of the symmetric cell\n",
    "                clean_subplot(ax[axis_2, axis_1])\n",
    "        else:\n",
    "            clean_subplot(ax[axis_1, axis_2])\n",
    "            clean_subplot(ax[axis_2, axis_1])\n",
    "\n",
    "# Make motif labels\n",
    "for i in range(top_k):\n",
    "    ax[i, 0].set_ylabel(motif_keys_ordered[i])\n",
    "    ax[-1, i].set_xlabel(motif_keys_ordered[i])\n",
    "\n",
    "# Remove x-axis labels/ticks\n",
    "ax[-1, -1].set_xticks([])\n",
    "fig.suptitle(\"Distance distributions between co-occurring motifs\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(out_path, \"coocurr_dist.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
