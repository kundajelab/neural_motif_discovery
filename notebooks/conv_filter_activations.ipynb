{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import model.util as model_util\n",
    "import model.profile_models as profile_models\n",
    "import model.train_profile_model as train_profile_model\n",
    "import model.profile_performance as profile_performance\n",
    "import feature.util as feature_util\n",
    "import feature.make_profile_dataset as make_profile_dataset\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tqdm\n",
    "from modisco.visualization import viz_sequence\n",
    "tqdm.tqdm_notebook(range(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the files and model, and some constants\n",
    "files_spec_path = \"/users/amtseng/tfmodisco/data/processed/ENCODE/config/TEAD4/TEAD4_training_paths.json\"\n",
    "model_path = \"/users/amtseng/tfmodisco/models/trained_models/TEAD4_fold7/3/model_ckpt_epoch_10.h5\"\n",
    "\n",
    "reference_fasta = \"/users/amtseng/genomes/hg38.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/hg38.canon.chrom.sizes\"\n",
    "input_length = 1346\n",
    "profile_length = 1000\n",
    "num_tasks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_json_path = \"/users/amtseng/tfmodisco/data/processed/ENCODE/chrom_splits.json\"\n",
    "with open(splits_json_path, \"r\") as f:\n",
    "    splits_json = json.load(f)\n",
    "train_chroms, val_chroms, test_chroms = \\\n",
    "    splits_json[\"1\"][\"train\"], splits_json[\"1\"][\"val\"], \\\n",
    "    splits_json[\"1\"][\"test\"]\n",
    "all_chroms = train_chroms + val_chroms + test_chroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the file specs\n",
    "with open(files_spec_path, \"r\") as f:\n",
    "    files_spec = json.load(f)\n",
    "peak_beds = files_spec[\"peak_beds\"]\n",
    "profile_hdf5 = files_spec[\"profile_hdf5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model\n",
    "custom_objects = {\n",
    "    \"kb\": keras.backend,\n",
    "    \"profile_loss\": train_profile_model.get_profile_loss_function(num_tasks, profile_length),\n",
    "    \"count_loss\": train_profile_model.get_count_loss_function(num_tasks)\n",
    "}\n",
    "new_model = keras.models.load_model(model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Use classes from `make_profile_dataset` to prepare positive and negative inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "loader = make_profile_dataset.create_data_loader(\n",
    "    peak_beds, profile_hdf5, \"SummitCenteringCoordsBatcher\", batch_size,\n",
    "    reference_fasta, chrom_sizes, input_length, profile_length, 1,\n",
    "    None, True, 0, None, chrom_set=all_chroms, return_coords=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get first layer filter activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filters in the existing model\n",
    "filters = model.get_layer(\"dil_conv_1\").get_weights()\n",
    "filter_size, num_filters = filters[0].shape[0], filters[0].shape[2]\n",
    "num_windows = input_length - filter_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that takes in input sequence and passes it through an\n",
    "# identical first convolutional layer\n",
    "filter_model_input = keras.layers.Input(shape=(input_length, 4), name=\"input_seq\")\n",
    "filter_model_conv = keras.layers.Conv1D(\n",
    "    filters=num_filters, kernel_size=filter_size, padding=\"valid\",\n",
    "    activation=\"relu\", dilation_rate=1, name=\"dil_conv_1\"\n",
    ")\n",
    "filter_model = keras.Model(\n",
    "    inputs=filter_model_input, outputs=filter_model_conv(filter_model_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the weights of this layer to be the same as the imported model\n",
    "filter_model.get_layer(\"dil_conv_1\").set_weights(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enq = keras.utils.OrderedEnqueuer(loader, use_multiprocessing=True)\n",
    "workers, queue_size = 10, 20\n",
    "enq.start(workers, queue_size)\n",
    "para_batch_gen = enq.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(enq.sequence)\n",
    "num_per_batch = batch_size * 2  # With revcomp\n",
    "num_samples_exp = num_batches * num_per_batch\n",
    "num_samples_seen = 0\n",
    "all_coords = np.empty((num_samples_exp, 3), dtype=object)\n",
    "all_input_seqs = np.empty((num_samples_exp, input_length, 4))\n",
    "all_activations = np.empty((num_samples_exp, num_windows, num_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each input example, record the set of activations seen for each filter\n",
    "for i in tqdm.notebook.trange(len(enq.sequence)):\n",
    "    input_seqs, profiles, statuses, coords, peaks = next(para_batch_gen)\n",
    "    \n",
    "    start, end = num_samples_seen, num_samples_seen + input_seqs.shape[0]\n",
    "    \n",
    "    all_coords[start:end] = coords\n",
    "    all_input_seqs[start:end] = input_seqs\n",
    "    \n",
    "    activations = filter_model.predict_on_batch(input_seqs)\n",
    "    all_activations[start:end] = activations\n",
    "    \n",
    "    num_samples_seen += input_seqs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords = all_coords[:num_samples_seen]\n",
    "all_input_seqs = all_input_seqs[:num_samples_seen]\n",
    "all_activations = all_activations[:num_samples_seen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enq.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get output predictions after nullifying each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the first layer filters, nullify so that the output is always\n",
    "# just the average activation, then rerun the data to get output predictions\n",
    "all_log_pred_profs = np.empty((num_samples_exp, num_filters, num_tasks, profile_length, 2))\n",
    "all_log_pred_counts = np.empty((num_samples_exp, num_filters, num_tasks, 2))\n",
    "\n",
    "filter_weights = model.get_layer(\"dil_conv_1\").get_weights()\n",
    "for filter_index in range(num_filters):\n",
    "    # Nullify the filter\n",
    "    filter_weights_copy = [x.copy() for x in filter_weights]\n",
    "    filter_weights_copy[0][:, :, filter_index] = 0  # Weights to 0\n",
    "    filter_weights_copy[1][filter_index] = np.mean(all_activations[:, :, filter_index])  # Bias to average\n",
    "    \n",
    "    # Set the weights to nullify the filter\n",
    "    model.get_layer(\"dil_conv_1\").set_weights(filter_weights_copy)\n",
    "    \n",
    "    enq = keras.utils.OrderedEnqueuer(loader, use_multiprocessing=True)\n",
    "    workers, queue_size = 10, 20\n",
    "    enq.start(workers, queue_size)\n",
    "    para_batch_gen = enq.get()\n",
    "    num_samples_seen = 0\n",
    "    for i in tqdm.notebook.trange(len(enq.sequence)):\n",
    "        input_seqs, profiles, statuses, coords, peaks = next(para_batch_gen)\n",
    "\n",
    "        start, end = num_samples_seen, num_samples_seen + input_seqs.shape[0]\n",
    "        \n",
    "        log_pred_profs, log_pred_counts = model.predict_on_batch([input_seqs, profiles[:,:num_tasks,:,:]])\n",
    "\n",
    "        all_log_pred_profs[start:end, filter_index, :, :, :] = log_pred_profs\n",
    "        all_log_pred_counts[start:end, filter_index, :, :] = log_pred_counts\n",
    "\n",
    "        num_samples_seen += input_seqs.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
