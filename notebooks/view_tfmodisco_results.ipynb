{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import modisco\n",
    "from modisco.visualization import viz_sequence\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "tf_name = os.environ[\"TFM_RESULTS_TF_NAME\"]\n",
    "fold = int(os.environ[\"TFM_RESULTS_FOLD\"])\n",
    "if \"TFM_RESULTS_TASK_INDEX\" in os.environ:\n",
    "    task_index = int(os.environ[\"TFM_RESULTS_TASK_INDEX\"])\n",
    "else:\n",
    "    task_index = None\n",
    "    \n",
    "print(\"TF name: %s\" % tf_name)\n",
    "print(\"Fold: %s\" % fold)\n",
    "print(\"Task index: %s\" % task_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Skip to results](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and constants\n",
    "input_length, profile_length = 1346, 1000\n",
    "shap_score_center_size = 400\n",
    "profile_display_center_size = 400\n",
    "\n",
    "# Get chromosome set based on fold\n",
    "with open(\"/users/amtseng/tfmodisco/data/processed/ENCODE/chrom_splits.json\", \"r\") as f:\n",
    "    chrom_splits = json.load(f)\n",
    "    chrom_set = chrom_splits[str(fold)][\"test\"]\n",
    "    \n",
    "preds_path = \"/users/amtseng/tfmodisco/results/peak_predictions/{0}/{0}_peak_prediction_performance.h5\".format(tf_name)\n",
    "if task_index is None:\n",
    "    shap_scores_path = \"/users/amtseng/tfmodisco/results/shap_scores/{0}/{0}_shap_scores.h5\".format(tf_name)\n",
    "    tfm_results_path = \"/users/amtseng/tfmodisco/results/tfmodisco/{0}/{0}_tfm.h5\".format(tf_name)\n",
    "else:\n",
    "    shap_scores_path = \"/users/amtseng/tfmodisco/results/shap_scores/{0}/{0}_task{1}_shap_scores.h5\".format(tf_name, task_index)\n",
    "    tfm_results_path = \"/users/amtseng/tfmodisco/results/tfmodisco/{0}/{0}_task{1}_tfm.h5\".format(tf_name, task_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_shap_scores(shap_scores_path, chrom_set):\n",
    "    \"\"\"\n",
    "    Imports the set of SHAP scores used for the TF-MoDISco run. The SHAP scores\n",
    "    are not cut down to a centered size yet.\n",
    "    Arguments:\n",
    "        `shap_scores_path`: path to HDF5 containing SHAP scores used to run\n",
    "            TF-MoDISco, in the same order\n",
    "        `chrom_set`: set of chromosomes used\n",
    "    Returns an N x I x 4 array of hypothetical scores, an N x I x 4 array of\n",
    "    input sequences, and an N x 3 object array of corresponding coordinates,\n",
    "    all limited to `chrom_set`.\n",
    "    \"\"\"\n",
    "    with h5py.File(shap_scores_path, \"r\") as f:\n",
    "        all_chroms = f[\"coords_chrom\"][:].astype(str)\n",
    "        coords_mask = np.isin(all_chroms, chrom_set)\n",
    "        coords_chrom = all_chroms[coords_mask]\n",
    "        coords_start = f[\"coords_start\"][:][coords_mask]\n",
    "        coords_end = f[\"coords_end\"][:][coords_mask]\n",
    "        one_hot_seqs = f[\"input_seqs\"][:][coords_mask]\n",
    "        hyp_scores = f[\"hyp_scores\"][:][coords_mask]\n",
    "    \n",
    "    coords = np.empty((len(coords_chrom), 3), dtype=object)\n",
    "    coords[:, 0] = coords_chrom\n",
    "    coords[:, 1] = coords_start\n",
    "    coords[:, 2] = coords_end\n",
    "    \n",
    "    return hyp_scores, one_hot_seqs, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_profiles(preds_path, fold):\n",
    "    \"\"\"\n",
    "    Imports the set of profile predictions for a particular fold.\n",
    "    Arguments:\n",
    "        `preds_path`: path to predictions/performance metrics of the model\n",
    "        `chrom_set`: set of chromosomes used\n",
    "        `fold`: fold number as an integer\n",
    "    Returns an M x T x O x 2 array of true profile counts, an M x T x O x 2\n",
    "    array of predicted profile probabilities, and an M x 3 object array of\n",
    "    corresponding coordinates in the fold.\n",
    "    \"\"\"\n",
    "    fold_key = \"fold%d\" % fold\n",
    "    with h5py.File(preds_path, \"r\") as f:\n",
    "        fold_true_profs = f[fold_key][\"predictions\"][\"true_profs\"][:]\n",
    "        fold_log_pred_profs = f[fold_key][\"predictions\"][\"log_pred_profs\"][:]\n",
    "        \n",
    "        coords = np.empty((len(fold_true_profs), 3), dtype=object)\n",
    "        coords[:, 0] = f[fold_key][\"coords\"][\"coords_chrom\"][:].astype(str)\n",
    "        coords[:, 1] = f[fold_key][\"coords\"][\"coords_start\"][:]\n",
    "        coords[:, 2] = f[fold_key][\"coords\"][\"coords_end\"][:]\n",
    "    \n",
    "    return fold_true_profs, np.exp(fold_log_pred_profs), coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_subset_inds(coord_subset, coord_superset):\n",
    "    \"\"\"\n",
    "    Given two arrays of coordinates, computes a set of indices over the superset\n",
    "    for the coordinates contained in the subset.\n",
    "    Arguments:\n",
    "        `coord_subset`: N x 3 object array of coordinates\n",
    "        `coord_superset`: M x 3 object array of coordinates\n",
    "    Returns an 1D integer array which contains indices of `coord_superset` which\n",
    "    correspond to values in `coord_subset`. The goal is such that if this array\n",
    "    were used to select out of `coord_superset`, the result would be identical to\n",
    "    `coord_subset`. Note that if there are repeated coordinates in `coord_subset`\n",
    "    and `coord_superset`, the same number of repeats will in `coord_subset` will\n",
    "    be selected, and they may be duplicates.\n",
    "    \"\"\"\n",
    "    inds = []\n",
    "    for chrom, start, end in coord_subset:\n",
    "        # This is pretty inefficient; a better solution might utilize sorting, but fuck it\n",
    "        super_matches = np.where(\n",
    "            (coord_superset[:, 0] == chrom) &\n",
    "            (coord_superset[:, 1] == start) &\n",
    "            (coord_superset[:, 2] == end)\n",
    "        )[0]\n",
    "        if not len(super_matches):\n",
    "            raise ValueError(\"Warning: %s:%d-%d in subset is not in superset\" % (chrom, start, end))\n",
    "        inds.append(super_matches[0])\n",
    "    return np.array(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profiles(\n",
    "    seqlets_arr, one_hot_seqs, true_profs, pred_profs, input_length, profile_length,\n",
    "    input_center_cut_size, profile_center_cut_size, task_index=None\n",
    "):\n",
    "    \"\"\"\n",
    "    From the seqlets object of a TF-MoDISco pattern's seqlets and alignments,\n",
    "    extracts the predicted and observed profiles of the model.\n",
    "    Arguments:\n",
    "        `seqlets_arr`: a TF-MoDISco pattern's seqlets object array (N-array)\n",
    "        `one_hot_seqs`: an N x I x 4 array of input sequences\n",
    "        `true_profs`: an N x T x O x 2 array of true profile counts\n",
    "        `pred_profs`: an N x T x O x 2 array of predicted profile probabilities\n",
    "        `input_length`: length of original input sequences, I\n",
    "        `profile_length`: length of profile predictions, O\n",
    "        `input_center_cut_size`: centered cut size of SHAP scores used\n",
    "        `profile_center_cut_size`: size to cut profiles to when returning them, P\n",
    "        `task_index`: index of task to focus on for profiles; if None, returns\n",
    "            profiles for all tasks\n",
    "    Returns an N x (T or 1) x P x 2 array of true profile counts, an\n",
    "    N x (T or 1) x P x 2 array of predicted profile probabilities, and an\n",
    "    N x Q x 4 array of one-hot seqlet sequences, where P is the profile cut size\n",
    "    and Q is the seqlet length. Returned profiles are centered at the same center\n",
    "    as the seqlets.\n",
    "    Note that it is important that the seqlet indices match exactly with the indices\n",
    "    out of the N. This should be the exact sequences in the original SHAP scores.\n",
    "    \"\"\"\n",
    "    true_seqlet_profs, pred_seqlet_profs, seqlet_seqs = [], [], []\n",
    "    \n",
    "    def seqlet_coord_to_profile_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2) - ((input_length - profile_length) // 2)\n",
    "    \n",
    "    def seqlet_coord_to_input_coord(seqlet_coord):\n",
    "        return seqlet_coord + ((input_length - input_center_cut_size) // 2)\n",
    "        \n",
    "    # For each seqlet, fetch the true/predicted profiles\n",
    "    for seqlet in seqlets_arr:\n",
    "        coord_index = seqlet.coor.example_idx\n",
    "        seqlet_start = seqlet.coor.start\n",
    "        seqlet_end = seqlet.coor.end\n",
    "        seqlet_rc = seqlet.coor.is_revcomp\n",
    "        \n",
    "        # Get indices of profile to cut out\n",
    "        seqlet_center = (seqlet_start + seqlet_end) // 2\n",
    "        prof_center = seqlet_coord_to_profile_coord(seqlet_center)\n",
    "        prof_start = prof_center - (profile_center_cut_size // 2)\n",
    "        prof_end = prof_start + profile_center_cut_size\n",
    "        \n",
    "        task_start, task_end = (task_index, task_index + 1) if task_index is not None else (None, None)\n",
    "        true_prof = true_profs[coord_index, task_start:task_end, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        pred_prof = pred_profs[coord_index, task_start:task_end, prof_start:prof_end]  # (T or 1) x P x 2\n",
    "        true_seqlet_profs.append(true_prof)\n",
    "        pred_seqlet_profs.append(pred_prof)\n",
    "        \n",
    "        # Get indices of input sequence corresponding to seqlet\n",
    "        inp_start = seqlet_coord_to_input_coord(seqlet_start)\n",
    "        inp_end = seqlet_coord_to_input_coord(seqlet_end)\n",
    "        if seqlet_rc:\n",
    "            seqlet_seqs.append(np.flip(one_hot_seqs[coord_index, inp_start:inp_end], axis=(0, 1)))\n",
    "        else:\n",
    "            seqlet_seqs.append(one_hot_seqs[coord_index, inp_start:inp_end])\n",
    "        \n",
    "    return np.stack(true_seqlet_profs), np.stack(pred_seqlet_profs), np.stack(seqlet_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_results(shap_scores_path, tfm_results_path, input_center_cut_size, chrom_set):\n",
    "    \"\"\"\n",
    "    Imports the TF-MoDISco results object.\n",
    "    Arguments:\n",
    "        `shap_scores_path`: path to HDF5 containing SHAP scores used to run\n",
    "            TF-MoDISco, in the same order\n",
    "        `tfm_results_path`: path to HDF5 containing TF-MoDISco results\n",
    "        `input_center_cut_size`: centered cut size of SHAP scores used\n",
    "        `chrom_set`: set of chromosomes used\n",
    "    \"\"\"\n",
    "    hyp_scores, one_hot_seqs, coords = import_shap_scores(shap_scores_path, chrom_set)\n",
    "        \n",
    "    # Cut everything to `input_center_cut_size`\n",
    "    seq_len = one_hot_seqs.shape[1]\n",
    "    start = (seq_len // 2) - (input_center_cut_size // 2)\n",
    "    end = start + input_center_cut_size\n",
    "    one_hot_seqs = one_hot_seqs[:, start:end]\n",
    "    hyp_scores = hyp_scores[:, start:end]\n",
    "    act_scores = hyp_scores * one_hot_seqs\n",
    "    \n",
    "    track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(\n",
    "        task_names=[\"task0\"],\n",
    "        contrib_scores={\"task0\": act_scores},\n",
    "        hypothetical_contribs={\"task0\": hyp_scores},\n",
    "        one_hot=one_hot_seqs\n",
    "    )\n",
    "    \n",
    "    with h5py.File(tfm_results_path,\"r\") as f:\n",
    "        return modisco.tfmodisco_workflow.workflow.TfModiscoResults.from_hdf5(f, track_set=track_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(seqlet_true_profs, seqlet_pred_profs, kmeans_clusters=5):\n",
    "    \"\"\"\n",
    "    Plots the given profiles with a heatmap.\n",
    "    Arguments:\n",
    "        `seqlet_true_profs`: an N x O x 2 NumPy array of true profiles, either as raw\n",
    "            counts or probabilities (they will be normalized)\n",
    "        `seqlet_pred_profs`: an N x O x 2 NumPy array of predicted profiles, either as\n",
    "            raw counts or probabilities (they will be normalized)\n",
    "        `kmeans_cluster`: when displaying profile heatmaps, there will be this\n",
    "            many clusters\n",
    "    \"\"\"\n",
    "    assert len(seqlet_true_profs.shape) == 3\n",
    "    assert seqlet_true_profs.shape == seqlet_pred_profs.shape\n",
    "    num_profs, width, _ = seqlet_true_profs.shape\n",
    "    \n",
    "    # First, normalize the profiles along the output profile dimension\n",
    "    def normalize(arr, axis=0):\n",
    "        arr_sum = np.sum(arr, axis=axis, keepdims=True)\n",
    "        arr_sum[arr_sum == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return arr / arr_sum\n",
    "    true_profs_norm = normalize(seqlet_true_profs, axis=1)\n",
    "    pred_profs_norm = normalize(seqlet_pred_profs, axis=1)\n",
    "    \n",
    "    # Perform k-means clustering on the true profiles, with the strands pooled\n",
    "    cluster_assignments = sklearn.cluster.KMeans(n_clusters=5).fit_predict(\n",
    "        np.reshape(true_profs_norm, (true_profs_norm.shape[0], -1))\n",
    "    )\n",
    "    # print(\"Cluster sizes: \" + \"  \".join(str(x) for x in np.unique(cluster_assignments, return_counts=True)[1]))\n",
    "    cluster_inds = np.argsort(cluster_assignments)\n",
    "    \n",
    "    # Compute the mean profiles across all examples\n",
    "    true_profs_mean = np.mean(true_profs_norm, axis=0)\n",
    "    pred_profs_mean = np.mean(pred_profs_norm, axis=0)\n",
    "    \n",
    "    # Compute a matrix of profiles, normalized to the maximum height, ordered by clusters\n",
    "    def make_profile_matrix(flat_profs, order_inds):\n",
    "        matrix = flat_profs[order_inds]\n",
    "        maxes = np.max(matrix, axis=1, keepdims=True)\n",
    "        maxes[maxes == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return matrix / maxes\n",
    "    true_matrix = make_profile_matrix(true_profs_norm, cluster_inds)\n",
    "    pred_matrix = make_profile_matrix(pred_profs_norm, cluster_inds)\n",
    "    \n",
    "    # Create a figure with the right dimensions\n",
    "    mean_height = 4\n",
    "    heatmap_height = num_profs * 0.004\n",
    "    fig_height = mean_height + (2 * heatmap_height)\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 2, figsize=(16, fig_height), sharex=True,\n",
    "        gridspec_kw={\n",
    "            \"width_ratios\": [1, 1],\n",
    "            \"height_ratios\": [mean_height / fig_height, heatmap_height / fig_height, heatmap_height / fig_height]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Plot the average predictions\n",
    "    ax[0, 0].plot(true_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 0].plot(-true_profs_mean[:, 1], color=\"darkorange\")\n",
    "    ax[0, 1].plot(pred_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 1].plot(-pred_profs_mean[:, 1], color=\"darkorange\")\n",
    "\n",
    "    # Set axes on average predictions\n",
    "    max_mean_val = max(np.max(true_profs_mean), np.max(pred_profs_mean))\n",
    "    mean_ylim = max_mean_val * 1.05  # Make 5% higher\n",
    "    ax[0, 0].set_title(\"True profiles\")\n",
    "    ax[0, 0].set_ylabel(\"Average probability\")\n",
    "    ax[0, 1].set_title(\"Predicted profiles\")\n",
    "    for j in (0, 1):\n",
    "        ax[0, j].set_ylim(-mean_ylim, mean_ylim)\n",
    "        ax[0, j].label_outer()\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    ax[1, 0].imshow(true_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[1, 1].imshow(pred_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[2, 0].imshow(true_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "    ax[2, 1].imshow(pred_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "\n",
    "    # Set axes on heatmaps\n",
    "    for i in (1, 2):\n",
    "        for j in (0, 1):\n",
    "            ax[i, j].set_yticks([])\n",
    "            ax[i, j].set_yticklabels([])\n",
    "            ax[i, j].label_outer()\n",
    "    width = true_matrix.shape[1]\n",
    "    delta = 100\n",
    "    num_deltas = (width // 2) // delta\n",
    "    labels = list(range(max(-width // 2, -num_deltas * delta), min(width // 2, num_deltas * delta) + 1, delta))\n",
    "    tick_locs = [label + max(width // 2, num_deltas * delta) for label in labels]\n",
    "    for j in (0, 1):\n",
    "        ax[2, j].set_xticks(tick_locs)\n",
    "        ax[2, j].set_xticklabels(labels)\n",
    "        ax[2, j].set_xlabel(\"Distance from peak summit (bp)\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SHAP scores and profile predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SHAP coordinates and one-hot sequences\n",
    "hyp_scores, one_hot_seqs, shap_coords = import_shap_scores(shap_scores_path, chrom_set)\n",
    "\n",
    "# Import the set of all profiles and their coordinates for the fold\n",
    "fold_true_profs, fold_pred_profs, fold_pred_coords = import_profiles(preds_path, fold)\n",
    "\n",
    "# Subset the profiles to exactly the coordinates that match the SHAP coordinates\n",
    "pred_inds = get_coord_subset_inds(shap_coords, fold_pred_coords)\n",
    "true_profs, pred_profs, pred_coords = \\\n",
    "    fold_true_profs[pred_inds], fold_pred_profs[pred_inds], fold_pred_coords[pred_inds]\n",
    "assert np.all(pred_coords == shap_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "### Plot some SHAP score tracks\n",
    "Plot the central region of some randomly selected actual importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index in np.random.choice(hyp_scores.shape[0], size=5, replace=False):\n",
    "    viz_sequence.plot_weights((hyp_scores[index] * one_hot_seqs[index])[600:800], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and plot TF-MoDISco results\n",
    "Plot all motifs by metacluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TF-MoDISco results object\n",
    "tfm_obj = import_tfmodisco_results(shap_scores_path, tfm_results_path, shap_score_center_size, chrom_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metaclusters = tfm_obj.metacluster_idx_to_submetacluster_results\n",
    "num_metaclusters = len(metaclusters.keys())\n",
    "for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "    metacluster = metaclusters[metacluster_key]\n",
    "    print(\"Metacluster %d/%d\" % (metacluster_i + 1, num_metaclusters))\n",
    "    print(\"==========================================\")\n",
    "    patterns = metacluster.seqlets_to_patterns_result.patterns\n",
    "    if not patterns:\n",
    "        break\n",
    "    num_patterns = len(patterns)\n",
    "    for pattern_i, pattern in enumerate(patterns):\n",
    "        seqlets = pattern.seqlets\n",
    "        print(\"Pattern %d/%d\" % (pattern_i + 1, num_patterns))\n",
    "        print(\"--------------------------------------\")\n",
    "\n",
    "        print(\"%d seqlets\" % len(seqlets))\n",
    "        print(\"Sequence\")\n",
    "        viz_sequence.plot_weights(pattern[\"sequence\"].fwd)\n",
    "        print(\"Hypothetical contributions\")\n",
    "        viz_sequence.plot_weights(pattern[\"task0_hypothetical_contribs\"].fwd)\n",
    "        print(\"Contribution_scores\")\n",
    "        viz_sequence.plot_weights(pattern[\"task0_contrib_scores\"].fwd)\n",
    "        \n",
    "        seqlet_true_profs, seqlet_pred_profs, seqlet_seqs = extract_profiles(\n",
    "            seqlets, one_hot_seqs, true_profs, pred_profs, input_length, profile_length,\n",
    "            shap_score_center_size, profile_display_center_size, task_index=task_index\n",
    "        )\n",
    "\n",
    "        assert np.all(np.sum(seqlet_seqs, axis=0) / len(seqlet_seqs) == pattern[\"sequence\"].fwd)\n",
    "        # ^Sanity check: PFM derived from seqlets match the PFM stored in the pattern\n",
    "        print(\"Predicted/observed profiles\")\n",
    "        plot_profiles(\n",
    "            # Flatten to NT x O x 2\n",
    "            np.reshape(seqlet_true_profs, (-1, seqlet_true_profs.shape[2], seqlet_true_profs.shape[3])),\n",
    "            np.reshape(seqlet_pred_profs, (-1, seqlet_pred_profs.shape[2], seqlet_pred_profs.shape[3]))\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
