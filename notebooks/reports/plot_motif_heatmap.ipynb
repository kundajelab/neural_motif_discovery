{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to results\n",
    "[Results](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "from util import figure_to_vdom_image\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import scipy.signal\n",
    "import scipy.cluster.hierarchy\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "motif_files = os.environ[\"TFM_MOTIF_FILES\"].split(\",\")\n",
    "group_names = os.environ[\"TFM_GROUP_NAMES\"].split(\",\")\n",
    "if \"TFM_HEATMAP_CACHE\" in os.environ:\n",
    "    tfm_heatmap_cache_dir = os.environ[\"TFM_HEATMAP_CACHE\"]\n",
    "else:\n",
    "    tfm_heatmap_cache_dir = None\n",
    "    \n",
    "assert len(motif_files) == len(group_names)\n",
    "assert len(group_names) == len(set(group_names))\n",
    "\n",
    "print(\"Motif files: %s\" % motif_files)\n",
    "print(\"Group names: %s\" % group_names)\n",
    "print(\"Saved heatmap cache: %s\" % tfm_heatmap_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "cluster_color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "default_cluster_color = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tfm_heatmap_cache_dir:\n",
    "    os.makedirs(tfm_heatmap_cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For plotting and organizing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_motifs(motif_files, group_names):\n",
    "    \"\"\"\n",
    "    Imports a set of motifs from the saved HDF5 files.\n",
    "    `group_names` is a list of group names, one for each motif file.\n",
    "    Returns a list of motifs as L x 4 arrays, a parallel list of\n",
    "    motif names, and a dictionary mapping group names to lists of\n",
    "    motif names.\n",
    "    \"\"\"\n",
    "    motifs, motif_names = [], []\n",
    "    groups = {}\n",
    "    for motif_file, stem in zip(motif_files, group_names):\n",
    "        groups[stem] = []\n",
    "        with h5py.File(motif_file, \"r\") as f:\n",
    "            for key in f.keys():\n",
    "                motif_name = \"%s:%s\" % (stem, key)\n",
    "                motif_names.append(motif_name)\n",
    "                motifs.append(f[key][\"cwm_trimmed\"][:])\n",
    "                groups[stem].append(motif_name)\n",
    "    return motifs, motif_names, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_similarity_score(motif_1, motif_2, average=False, align_to_longer=True):\n",
    "    \"\"\"\n",
    "    Computes the motif similarity score between two motifs by\n",
    "    the summed cosine similarity, maximized over all possible sliding\n",
    "    windows. Also returns the index relative to the start of `motif_2`\n",
    "    where `motif_1` should be placed to maximize this score.\n",
    "    If `average` is True, then use average of similarity of overlap.\n",
    "    If `align_to_longer` is True, always use the longer motif as the basis\n",
    "    for the index computation (if tie use `motif_2`). Otherwise, always use\n",
    "    `motif_2`.\n",
    "    \"\"\"\n",
    "    # Normalize\n",
    "    motif_1 = motif_1 - np.mean(motif_1, axis=1, keepdims=True)\n",
    "    motif_2 = motif_2 - np.mean(motif_2, axis=1, keepdims=True)\n",
    "    motif_1 = motif_1 / np.sqrt(np.sum(motif_1 * motif_1, axis=1, keepdims=True))\n",
    "    motif_2 = motif_2 / np.sqrt(np.sum(motif_2 * motif_2, axis=1, keepdims=True))\n",
    "    \n",
    "    # Always make motif_2 longer\n",
    "    if align_to_longer and len(motif_1) > len(motif_2):\n",
    "        motif_1, motif_2 = motif_2, motif_1\n",
    "    \n",
    "    # Pad motif_2 by len(motif_1) - 1 on either side\n",
    "    orig_motif_2_len = len(motif_2)\n",
    "    pad_size = len(motif_1) - 1\n",
    "    motif_2 = np.pad(motif_2, ((pad_size, pad_size), (0, 0)))\n",
    "    \n",
    "    if average:\n",
    "        # Compute overlap sizes\n",
    "        overlap_sizes = np.empty(orig_motif_2_len + pad_size)\n",
    "        overlap_sizes[:pad_size] = np.arange(1, len(motif_1))\n",
    "        overlap_sizes[-pad_size:] = np.flip(np.arange(1, len(motif_1)))\n",
    "        overlap_sizes[pad_size:-pad_size] = len(motif_1)\n",
    "    \n",
    "    # Compute similarities across all sliding windows\n",
    "    scores = np.empty(orig_motif_2_len + pad_size)\n",
    "    for i in range(orig_motif_2_len + pad_size):\n",
    "        scores[i] = np.sum(motif_1 * motif_2[i : i + len(motif_1)])\n",
    "    if average:\n",
    "        scores = scores / overlap_sizes\n",
    "    return np.max(scores), np.argmax(scores) - pad_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(motifs, show_progress=True):\n",
    "    \"\"\"\n",
    "    Computes a similarity matrix over the pairs of motifs using cross\n",
    "    correlation. `motifs` is a list of N motifs, where each is an L x 4\n",
    "    array (may be different Ls).\n",
    "    Returns an N x N array of distances.\n",
    "    \"\"\"\n",
    "    num_motifs = len(motifs)\n",
    "    sim_matrix = np.empty((num_motifs, num_motifs))\n",
    "    t_iter = tqdm.notebook.trange(num_motifs) if show_progress else range(num_motifs)\n",
    "    for i in t_iter:\n",
    "        for j in range(i, num_motifs):\n",
    "            sim, _ = motif_similarity_score(motifs[i], motifs[j])\n",
    "            sim_matrix[i, j] = sim\n",
    "            sim_matrix[j, i] = sim\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters(linkage, goal_clusters, tolerance=(-2, 2), start=50, max_iter=10):\n",
    "    \"\"\"\n",
    "    From a linkage map, computes clusters with a goal of `goal_clusters` clusters.\n",
    "    Will allow the given tolerance. `start` is what distance threshold to check first.\n",
    "    `max_iter` is the maximum number of checks to do.\n",
    "    Returns the clustering.\n",
    "    \"\"\"\n",
    "    clusters = scipy.cluster.hierarchy.fcluster(\n",
    "        linkage, start, criterion=\"distance\"\n",
    "    )\n",
    "    \n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    if num_clusters > goal_clusters + tolerance[1] and max_iter:\n",
    "        return compute_clusters(linkage, goal_clusters, tolerance, start * 2, max_iter - 1)\n",
    "    elif num_clusters < goal_clusters - tolerance[0] and max_iter:\n",
    "        return compute_clusters(linkage, goal_clusters, tolerance, start / 2, max_iter - 1)\n",
    "    else:\n",
    "        return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(sim_matrix, labels, linkage, clusters):\n",
    "    \"\"\"\n",
    "    Given a similariy matrix and labels, plots a heatmap with\n",
    "    dendrogram. `linkage` is the linkage map computed on the matrix, and\n",
    "    `clusters` is the cluster ID of each entry.\n",
    "    Returns the figure and the indices in which to order the entries.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=2, ncols=2, figsize=(20, 20),\n",
    "        gridspec_kw={\n",
    "            \"width_ratios\": [20, 1],\n",
    "            \"height_ratios\": [1, 4],\n",
    "            \"hspace\": 0,\n",
    "            \"wspace\": 0.1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Compute the color of every link based on cluster assignments\n",
    "    # Adapted from https://stackoverflow.com/questions/38153829/custom-cluster-colors-of-scipy-dendrogram-in-python-link-color-func\n",
    "    leaf_colors = [cluster_color_cycle[i % len(cluster_color_cycle)] for i in clusters]\n",
    "    link_colors = {}\n",
    "    for i, i_link in enumerate(linkage[:, :2].astype(int)):\n",
    "        color_0 = link_colors[i_link[0]] if i_link[0] > len(linkage) else leaf_colors[i_link[0]]\n",
    "        color_1 = link_colors[i_link[1]] if i_link[1] > len(linkage) else leaf_colors[i_link[1]]\n",
    "        link_colors[i + 1 + len(linkage)] = color_0 if color_0 == color_1 else default_cluster_color\n",
    "\n",
    "    dend = scipy.cluster.hierarchy.dendrogram(\n",
    "        linkage, ax=ax[0, 0], link_color_func=(lambda x: link_colors[x])\n",
    "    )\n",
    "\n",
    "    order_inds = dend[\"leaves\"]\n",
    "    sim_matrix_reordered = sim_matrix[:, order_inds][order_inds, :]\n",
    "    heatmap = ax[1, 0].imshow(sim_matrix_reordered, aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[1, 0].set_yticks([])\n",
    "    ax[1, 0].set_xticks(range(len(sim_matrix)))\n",
    "    ax[1, 0].set_xticklabels(np.array(labels)[order_inds], rotation=90, fontsize=10)\n",
    "\n",
    "    fig.colorbar(heatmap, cax=ax[1, 1])\n",
    "\n",
    "    ax[0, 0].axis(\"off\")\n",
    "    ax[0, 1].axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig, order_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_motifs(motifs):\n",
    "    \"\"\"\n",
    "    Aggregates a list of L x 4 (not all the same L) motifs into a single\n",
    "    L x 4 motif.\n",
    "    \"\"\"\n",
    "    # Compute similarity matrix\n",
    "    sim_matrix = compute_similarity_matrix(motifs, show_progress=False)\n",
    "\n",
    "    # Sort motifs by how similar it is to everyone else\n",
    "    inds = np.flip(np.argsort(np.sum(sim_matrix, axis=0)))\n",
    "    \n",
    "    # Have the consensus start with the most similar\n",
    "    consensus = np.zeros_like(motifs[inds[0]])\n",
    "    consensus = consensus + motifs[inds[0]]\n",
    "    \n",
    "    # For each successive motif, add it into the consensus\n",
    "    for i in inds[1:]:\n",
    "        motif = motifs[i]\n",
    "        _, index = motif_similarity_score(motif, consensus, align_to_longer=False)\n",
    "        if index >= 0:\n",
    "            start, end = index, index + len(motif)\n",
    "            consensus[start:end] = consensus[start:end] + motif[:len(consensus) - index]\n",
    "        else:\n",
    "            end = len(motif) + index\n",
    "            consensus[:end] = consensus[:end] + motif[-index:-index + len(consensus)]\n",
    "    return consensus / len(motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "### Show motifs clusters\n",
    "For all of the aggregated motifs, show the motif clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs, motif_names, motif_groups = import_motifs(motif_files, group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip all motifs to be the purine-rich version\n",
    "for i, motif in enumerate(motifs):\n",
    "    if np.sum(motif[:, [0, 2]]) < 0.5 * np.sum(motif):\n",
    "        motifs[i] = np.flip(motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix\n",
    "sim_matrix = compute_similarity_matrix(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linkage\n",
    "linkage = scipy.cluster.hierarchy.linkage(sim_matrix, method=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute clusters\n",
    "expected_clusters = np.max([len(m) for m in motif_groups.values()])\n",
    "clusters = compute_clusters(linkage, expected_clusters, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vdomh.h4(\"Number of motifs: %d\" % len(clusters)))\n",
    "display(vdomh.h4(\"Number of clusters: %d\" % len(np.unique(clusters))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "fig, order_inds = plot_heatmap(sim_matrix, motif_names, linkage, clusters)\n",
    "if tfm_heatmap_cache_dir:\n",
    "    fig.savefig(os.path.join(tfm_heatmap_cache_dir, \"motif_cluster_heatmap.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show aggregated and constituent motifs for each cluster\n",
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"50%\"}),\n",
    "    vdomh.col(style={\"width\": \"50%\"})\n",
    ")\n",
    "\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Aggregate motif\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Constituent motifs\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "all_consensus = {}\n",
    "cluster_ids, counts = np.unique(clusters, return_counts=True)\n",
    "cluster_ids = cluster_ids[np.flip(np.argsort(counts))]\n",
    "for i, cluster_id in enumerate(cluster_ids):\n",
    "    match_inds = np.where(clusters == cluster_id)[0]\n",
    "    matches = [motifs[j] for j in match_inds]\n",
    "    match_names = [motif_names[j] for j in match_inds]\n",
    "    \n",
    "    consensus = aggregate_motifs(matches)\n",
    "    all_consensus[cluster_id] = consensus\n",
    "    \n",
    "    display(vdomh.h3(\"Cluster %d (%d/%d)\" % (cluster_id, i + 1, len(cluster_ids))))\n",
    "    display(vdomh.h4(\"%d motifs\" % len(matches)))\n",
    "    \n",
    "    agg_fig = viz_sequence.plot_weights(consensus, figsize=(20, 4), return_fig=True)\n",
    "    agg_fig.tight_layout()\n",
    "    const_figs = []\n",
    "    for motif, motif_name in zip(matches, match_names):\n",
    "        fig = viz_sequence.plot_weights(motif, figsize=(20, 4), return_fig=True)\n",
    "        plt.title(motif_name)\n",
    "        fig.tight_layout()\n",
    "        const_figs.append(figure_to_vdom_image(fig))\n",
    "\n",
    "    body = vdomh.tbody(vdomh.tr(vdomh.td(figure_to_vdom_image(agg_fig)), vdomh.td(*const_figs)))\n",
    "    display(vdomh.table(colgroup, header, body))\n",
    "    \n",
    "    if tfm_heatmap_cache_dir:\n",
    "        agg_fig.savefig(os.path.join(tfm_heatmap_cache_dir, \"cluster_%d_aggregate_motif.png\" % cluster_id))\n",
    "        \n",
    "    plt.close(\"all\")\n",
    "\n",
    "if tfm_heatmap_cache_dir:\n",
    "    with h5py.File(os.path.join(tfm_heatmap_cache_dir, \"motif_clusters.h5\"), \"w\") as f:\n",
    "        f.create_dataset(\"motif_names\", data=np.array(motif_names).astype(\"S\"), compression=\"gzip\")\n",
    "        all_motifs = f.create_group(\"all_motifs\")\n",
    "        for name, motif in zip(motif_names, motifs):\n",
    "            all_motifs.create_dataset(name, data=motif, compression=\"gzip\")\n",
    "        f.create_dataset(\"similarity_matrix\", data=sim_matrix, compression=\"gzip\")\n",
    "        f.create_dataset(\"dendrogram_order\", data=order_inds, compression=\"gzip\")\n",
    "        f.create_dataset(\"clusters\", data=clusters, compression=\"gzip\")\n",
    "        agg_motifs = f.create_group(\"cluster_motifs\")\n",
    "        for cluster_id, consensus in all_consensus.items():\n",
    "            agg_motifs.create_dataset(str(cluster_id), data=consensus, compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
