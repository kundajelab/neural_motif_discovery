{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to results\n",
    "[Within-motif heterogeneity](#motif-subclusters)\n",
    "\n",
    "[Clustering of peaks](#peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "from tfmodisco.run_tfmodisco import import_shap_scores, import_tfmodisco_results\n",
    "from motif.read_motifs import pfm_info_content\n",
    "import motif.moods as moods\n",
    "import plot.viz_sequence as viz_sequence\n",
    "from util import figure_to_vdom_image, import_peak_table\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import modisco\n",
    "import sklearn.decomposition\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "tfm_results_path = os.environ[\"TFM_TFM_PATH\"]\n",
    "shap_scores_path = os.environ[\"TFM_SHAP_PATH\"]\n",
    "hyp_score_key = os.environ[\"TFM_HYP_SCORE_KEY\"]\n",
    "task_index = int(os.environ[\"TFM_TASK_INDEX\"])\n",
    "embeddings_path = os.environ[\"TFM_EMB_PATH\"]\n",
    "moods_dir = os.environ[\"TFM_MOODS_DIR\"]\n",
    "\n",
    "print(\"TF-MoDISco results path: %s\" % tfm_results_path)\n",
    "print(\"DeepSHAP scores path: %s\" % shap_scores_path)\n",
    "print(\"Importance score key: %s\" % hyp_score_key)\n",
    "print(\"Task index: %d\" % task_index)\n",
    "print(\"Embeddings path: %s\" % embeddings_path)\n",
    "print(\"MOODS directory: %s\" % moods_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "input_length = 2114\n",
    "shap_score_center_size = 400\n",
    "\n",
    "base_path = \"/users/amtseng/tfmodisco/\"\n",
    "data_path = os.path.join(base_path, \"data/processed/ENCODE/\")\n",
    "labels_path = os.path.join(data_path, \"labels/%s\" % tf_name)\n",
    "\n",
    "# Paths to original called peaks\n",
    "all_peak_beds = sorted([item for item in os.listdir(labels_path) if item.endswith(\".bed.gz\")])\n",
    "if task_index is None:\n",
    "    peak_bed_paths = [os.path.join(labels_path, item) for item in all_peak_beds]\n",
    "else:\n",
    "    peak_bed_paths = [os.path.join(labels_path, all_peak_beds[task_index])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For plotting and organizing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfmodisco_motif_subclusters(tfm_results):\n",
    "    \"\"\"\n",
    "    From an imported TF-MoDISco results object, computes the subclustering\n",
    "    of heterogeneity within each motif/pattern.\n",
    "    \"\"\"\n",
    "    metaclusters = tfm_results.metacluster_idx_to_submetacluster_results\n",
    "    num_metaclusters = len(metaclusters.keys())\n",
    "    for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "        metacluster = metaclusters[metacluster_key]\n",
    "        patterns = metacluster.seqlets_to_patterns_result.patterns\n",
    "        if not patterns:\n",
    "            break\n",
    "        num_patterns = len(patterns)\n",
    "        for pattern_i, pattern in enumerate(patterns):\n",
    "            # Compute subclustering for each pattern (motif)\n",
    "            pattern.compute_subclusters_and_embedding(\n",
    "                pattern_comparison_settings=modisco.affinitymat.core.PatternComparisonSettings(\n",
    "                    track_names=[\"task0_hypothetical_contribs\", \"task0_contrib_scores\"],\n",
    "                    track_transformer=modisco.affinitymat.L1Normalizer(),\n",
    "                    min_overlap=None  # This argument is irrelevant here\n",
    "                ),\n",
    "                perplexity=30, n_jobs=4, verbose=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_hcwm(pfm, hcwm):\n",
    "    # Trim motif based on information content\n",
    "    ic = pfm_info_content(pfm)\n",
    "    pass_inds = np.where(ic >= 0.2)[0]  # Cut off flanks with less than 0.2 IC\n",
    "\n",
    "    # Expand trimming to +/- 4bp on either side\n",
    "    start, end = max(0, np.min(pass_inds) - 4), min(len(pfm), np.max(pass_inds) + 4 + 1)\n",
    "    return hcwm[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif_heterogeneity(tfm_results):\n",
    "    colgroup = vdomh.colgroup(\n",
    "        vdomh.col(style={\"width\": \"5%\"}),\n",
    "        vdomh.col(style={\"width\": \"5%\"}),\n",
    "        vdomh.col(style={\"width\": \"50%\"}),\n",
    "        vdomh.col(style={\"width\": \"40%\"})\n",
    "    )\n",
    "    header = vdomh.thead(\n",
    "        vdomh.tr(\n",
    "            vdomh.th(\"Subpattern\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"Seqlets\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"Embeddings\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"hCWM\", style={\"text-align\": \"center\"})\n",
    "        )\n",
    "    )\n",
    "\n",
    "    metaclusters = tfm_results.metacluster_idx_to_submetacluster_results\n",
    "    num_metaclusters = len(metaclusters.keys())\n",
    "    for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "        metacluster = metaclusters[metacluster_key]\n",
    "        display(vdomh.h3(\"Metacluster %d/%d\" % (metacluster_i + 1, num_metaclusters)))\n",
    "        patterns = metacluster.seqlets_to_patterns_result.patterns\n",
    "        if not patterns:\n",
    "            break\n",
    "        num_patterns = len(patterns)\n",
    "        for pattern_i, pattern in enumerate(patterns):\n",
    "            display(vdomh.h4(\"Pattern %d/%d\" % (pattern_i + 1, num_patterns)))\n",
    "\n",
    "            embedding = pattern.twod_embedding\n",
    "            subpattern_clusters = pattern.subclusters\n",
    "\n",
    "            # Aggregate motif\n",
    "            pfm = pattern[\"sequence\"].fwd\n",
    "            hcwm = pattern[\"task0_hypothetical_contribs\"].fwd\n",
    "            trimmed_hcwm = trim_hcwm(pfm, hcwm)\n",
    "            hcwm_fig = viz_sequence.plot_weights(\n",
    "                trimmed_hcwm, subticks_frequency=(len(trimmed_hcwm) + 1), return_fig=True\n",
    "            )\n",
    "            emb_fig, ax = plt.subplots()\n",
    "            ax.scatter(\n",
    "                embedding[:,0], embedding[:,1], c=subpattern_clusters, cmap=\"tab20\", alpha=0.3\n",
    "            )\n",
    "\n",
    "            table_rows = [vdomh.tr(\n",
    "                vdomh.td(\"Agg.\"),\n",
    "                vdomh.td(str(len(pattern.seqlets))),\n",
    "                vdomh.td(figure_to_vdom_image(emb_fig)),\n",
    "                vdomh.td(figure_to_vdom_image(hcwm_fig))\n",
    "            )]\n",
    "\n",
    "            for subpattern_key, subpattern in pattern.subcluster_to_subpattern.items():\n",
    "                pfm = subpattern[\"sequence\"].fwd\n",
    "                hcwm = subpattern[\"task0_hypothetical_contribs\"].fwd\n",
    "                trimmed_hcwm = trim_hcwm(pfm, hcwm)\n",
    "                hcwm_fig = viz_sequence.plot_weights(\n",
    "                    trimmed_hcwm, subticks_frequency=(len(trimmed_hcwm) + 1), return_fig=True\n",
    "                )\n",
    "                emb_fig, ax = plt.subplots()\n",
    "                ax.scatter(\n",
    "                    embedding[:,0], embedding[:,1], c=(subpattern_clusters == subpattern_key), alpha=0.3\n",
    "                )\n",
    "\n",
    "                table_rows.append(vdomh.tr(\n",
    "                    vdomh.td(str(subpattern_key)),\n",
    "                    vdomh.td(str(len(subpattern.seqlets))),\n",
    "                    vdomh.td(figure_to_vdom_image(emb_fig)),\n",
    "                    vdomh.td(figure_to_vdom_image(hcwm_fig))\n",
    "                ))\n",
    "\n",
    "            table = vdomh.table(header, vdomh.tbody(*table_rows))\n",
    "            display(table)\n",
    "            plt.close(\"all\")  # Remove all standing figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_motifs(tfm_results_path, trim=True, only_pos=True):\n",
    "    \"\"\"\n",
    "    Imports hCWMs to into a dictionary, mapping `(x, y)` to the hCWM,\n",
    "    where `x` is the metacluster index and `y` is the pattern index.\n",
    "    Arguments:\n",
    "        `tfm_results_path`: path to HDF5 containing TF-MoDISco results\n",
    "        `out_dir`: where to save motifs\n",
    "        `trim`: if True, trim the motif flanks based on total importance\n",
    "        `only_pos`: if True, only return motifs with positive contributions\n",
    "    Returns the dictionary of hCWM.\n",
    "    \"\"\" \n",
    "    hcwms = {}\n",
    "    with h5py.File(tfm_results_path, \"r\") as f:\n",
    "        metaclusters = f[\"metacluster_idx_to_submetacluster_results\"]\n",
    "        num_metaclusters = len(metaclusters.keys())\n",
    "        for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "            metacluster = metaclusters[metacluster_key]\n",
    "            if \"patterns\" not in metacluster[\"seqlets_to_patterns_result\"]:\n",
    "                continue\n",
    "            patterns = metacluster[\"seqlets_to_patterns_result\"][\"patterns\"]\n",
    "            num_patterns = len(patterns[\"all_pattern_names\"][:])\n",
    "            for pattern_i, pattern_name in enumerate(patterns[\"all_pattern_names\"][:]):\n",
    "                pattern_name = pattern_name.decode()\n",
    "                pattern = patterns[pattern_name]\n",
    "                pfm = pattern[\"sequence\"][\"fwd\"][:]\n",
    "                hcwm = pattern[\"task0_hypothetical_contribs\"][\"fwd\"][:]\n",
    "                cwm = pattern[\"task0_contrib_scores\"][\"fwd\"][:]\n",
    "                \n",
    "                # Check that the contribution scores are overall positive\n",
    "                if only_pos and np.sum(cwm) < 0:\n",
    "                    continue\n",
    "                    \n",
    "                if trim:\n",
    "                    hcwm = trim_hcwm(pfm, hcwm)\n",
    "                    \n",
    "                hcwms[\"%d_%d\" % (metacluster_i,pattern_i)] = hcwm\n",
    "    return hcwms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_peak_indices(hit_table, motif_keys):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of NumPy arrays, mapping each motif key to\n",
    "    the set of peak indices that contain that motif.\n",
    "    \"\"\"\n",
    "    hit_peak_indices = {}\n",
    "    for motif_key in motif_keys:\n",
    "        hit_peak_indices[motif_key] = hit_table[hit_table[\"key\"] == motif_key][\"peak_index\"].values\n",
    "    return hit_peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_transform(matrix):\n",
    "    \"\"\"\n",
    "    Converts N x D matrix into transformed N x 2 matrix using\n",
    "    UMAP. First projects down to 50 components using PCA.\n",
    "    \"\"\"\n",
    "    # First reduce using PCA\n",
    "    centered = matrix - np.mean(matrix, axis=0, keepdims=True)\n",
    "    pca = sklearn.decomposition.PCA(n_components=50)\n",
    "    reduced = pca.fit_transform(centered)\n",
    "\n",
    "    # Run UMAP\n",
    "    um = umap.UMAP(verbose=False)\n",
    "    return um.fit_transform(centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak_clustering(embeddings_path, motif_keys, hcwms, hit_emb_indices):\n",
    "    colgroup = vdomh.colgroup(\n",
    "        vdomh.col(style={\"width\": \"5%\"}),\n",
    "        vdomh.col(style={\"width\": \"55\"}),\n",
    "        vdomh.col(style={\"width\": \"40%\"})\n",
    "    )\n",
    "    header = vdomh.thead(\n",
    "        vdomh.tr(\n",
    "            vdomh.th(\"Motif key\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"Embeddings\", style={\"text-align\": \"center\"}),\n",
    "            vdomh.th(\"hCWM\", style={\"text-align\": \"center\"})\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    embeddings_reader = h5py.File(embeddings_path, \"r\")\n",
    "    num_layers = embeddings_reader[\"embeddings\"][\"mean\"].shape[1]\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        display(vdomh.h3(\"Layer %d/%d\" % (i + 1, num_layers)))\n",
    "        \n",
    "        embeddings = np.concatenate([\n",
    "            embeddings_reader[\"embeddings\"][\"mean\"][:, i],\n",
    "            embeddings_reader[\"embeddings\"][\"std\"][:, i],\n",
    "            embeddings_reader[\"embeddings\"][\"max\"][:, i],\n",
    "            embeddings_reader[\"embeddings\"][\"min\"][:, i]\n",
    "        ], axis=1)  # Shape: N x (F * 4)\n",
    "\n",
    "        umap_trans = umap_transform(embeddings)\n",
    "        \n",
    "        table_rows = []\n",
    "        for motif_key in motif_keys:\n",
    "            hcwm = hcwms[motif_key]\n",
    "            hcwm_fig = viz_sequence.plot_weights(\n",
    "                hcwm, subticks_frequency=(len(hcwm) + 1), return_fig=True\n",
    "            )\n",
    "            emb_fig, ax = plt.subplots()\n",
    "            subset = np.zeros(len(embeddings), dtype=int)\n",
    "            subset[hit_emb_indices[motif_key]] = 1\n",
    "            ax.scatter(\n",
    "                umap_trans[:,0], umap_trans[:,1], c=subset, alpha=0.1\n",
    "            )\n",
    "\n",
    "            table_rows.append(vdomh.tr(\n",
    "                vdomh.td(motif_key),\n",
    "                vdomh.td(figure_to_vdom_image(emb_fig)),\n",
    "                vdomh.td(figure_to_vdom_image(hcwm_fig))\n",
    "            ))\n",
    "\n",
    "        table = vdomh.table(header, vdomh.tbody(*table_rows))\n",
    "        display(table)\n",
    "        plt.close(\"all\")  # Remove all standing figures\n",
    "    \n",
    "    embeddings_reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TF-MoDISco results\n",
    "Run motif subclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SHAP coordinates and one-hot sequences\n",
    "hyp_scores, _, one_hot_seqs, shap_coords = import_shap_scores(\n",
    "    shap_scores_path, hyp_score_key, center_cut_size=shap_score_center_size, remove_non_acgt=True\n",
    ")\n",
    "# This cuts the sequences/scores off just as how TF-MoDISco saw them, but the coordinates are uncut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TF-MoDISco results object\n",
    "tfm_obj = import_tfmodisco_results(tfm_results_path, hyp_scores, one_hot_seqs, shap_score_center_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute subclusters (needed for older versions of TF-MoDISco); this takes awhile!\n",
    "compute_tfmodisco_motif_subclusters(tfm_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import motif hits\n",
    "For each motif, determine the peaks that contain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hCWMs\n",
    "hcwms = import_tfmodisco_motifs(tfm_results_path)\n",
    "motif_keys = list(hcwms.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the motif hits\n",
    "hit_table = moods.import_moods_hits(os.path.join(moods_dir, \"moods_filtered_collapsed_scored.bed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_peak_indices = get_hit_peak_indices(hit_table, motif_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import peaks\n",
    "peak_table = import_peak_table(peak_bed_paths)\n",
    "\n",
    "# Expand to input length\n",
    "peak_table[\"peak_start\"] = \\\n",
    "    (peak_table[\"peak_start\"] + peak_table[\"summit_offset\"]) - (input_length // 2)\n",
    "peak_table[\"peak_end\"] = peak_table[\"peak_start\"] + input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(embeddings_path, \"r\") as f:\n",
    "    emb_coords_table = pd.DataFrame({\n",
    "        \"chrom\": f[\"coords\"][\"coords_chrom\"][:].astype(str),\n",
    "        \"start\": f[\"coords\"][\"coords_start\"][:],\n",
    "        \"end\": f[\"coords\"][\"coords_end\"][:]\n",
    "    })\n",
    "emb_coords_table[\"start\"] = \\\n",
    "    ((emb_coords_table[\"start\"] + emb_coords_table[\"end\"]) // 2) - (input_length // 2)\n",
    "emb_coords_table[\"end\"] = emb_coords_table[\"start\"] + input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the peak indices to embedding indices\n",
    "peak_coords_table = peak_table[[\"chrom\", \"peak_start\", \"peak_end\"]]\n",
    "\n",
    "matched_inds = peak_coords_table.reset_index().merge(\n",
    "    emb_coords_table.reset_index(), how=\"left\", left_on=[\"chrom\", \"peak_start\", \"peak_end\"],\n",
    "    right_on=[\"chrom\", \"start\", \"end\"]\n",
    ")[[\"index_x\", \"index_y\"]].values\n",
    "order_inds = np.empty(int(np.max(matched_inds[:, 0])) + 1)\n",
    "order_inds[matched_inds[:, 0].astype(int)] = matched_inds[:, 1]\n",
    "order_inds = np.nan_to_num(order_inds, nan=-1).astype(int)\n",
    "\n",
    "assert np.all(\n",
    "    peak_coords_table.values[order_inds >= 0] == \\\n",
    "    emb_coords_table.iloc[order_inds].values[order_inds >= 0]\n",
    ")  # Make sure the coordinates match up, at least those for which there was a match\n",
    "\n",
    "# Convert peak indices into embedding indices\n",
    "hit_emb_indices = {}\n",
    "for key in hit_peak_indices:\n",
    "    emb_inds = order_inds[hit_peak_indices[key]]\n",
    "    # Remove -1s; this removes anything where there was a peak but\n",
    "    # not a computed embedding\n",
    "    hit_emb_indices[key] = emb_inds[emb_inds >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"motif-subclusters\"></a>\n",
    "### Within-motif heterogeneity\n",
    "For each motif, show the subclusters that exist within the TF-MoDISco-identified subpatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_motif_heterogeneity(tfm_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"peaks\"></a>\n",
    "### Peak clustering\n",
    "For each peak, cluster the peaks by embeddings to highlight the structure of different peaks and different motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_peak_clustering(embeddings_path, motif_keys, hcwms, hit_emb_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
