{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[Motifs derived from filter-activating sequences](#filter-activating)\n",
    "\n",
    "[Motifs from filter weights](#filter-weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "from motif.read_motifs import pfm_info_content, pfm_to_pwm\n",
    "from util import figure_to_vdom_image\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pyfaidx\n",
    "import matplotlib.pyplot as plt\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "filter_activations_path = os.environ[\"TFM_FILTER_ACTIVATIONS\"]\n",
    "filter_weights_path = os.environ[\"TFM_FILTER_WEIGHTS\"]\n",
    "\n",
    "if \"TFM_MOTIF_CACHE\" in os.environ:\n",
    "    activation_motifs_cache_dir = os.environ[\"TFM_MOTIF_CACHE\"]\n",
    "else:\n",
    "    activation_motifs_cache_dir = None\n",
    "\n",
    "print(\"Path to filter activations: %s\" % filter_activations_path)\n",
    "print(\"Path to filter weights: %s\" % filter_weights_path)\n",
    "print(\"Saved activation-derived motifs cache: %s\" % activation_motifs_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants/paths\n",
    "input_length = 2114\n",
    "filter_width = 21\n",
    "reference_genome_path = \"/users/amtseng/genomes/hg38.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation_motifs_cache_dir:\n",
    "    os.makedirs(activation_motifs_cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "For extracting motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_to_one_hot(seqs):\n",
    "    \"\"\"\n",
    "    Converts a list of DNA (\"ACGT\") sequences to one-hot encodings, where the\n",
    "    position of 1s is ordered alphabetically by \"ACGT\". `seqs` must be a list\n",
    "    of N strings, where every string is the same length L. Returns an N x L x 4\n",
    "    NumPy array of one-hot encodings, in the same order as the input sequences.\n",
    "    All bases will be converted to upper-case prior to performing the encoding.\n",
    "    Any bases that are not \"ACGT\" will be given an encoding of all 0s.\n",
    "    \"\"\"\n",
    "    seq_len = len(seqs[0])\n",
    "    assert np.all(np.array([len(s) for s in seqs]) == seq_len)\n",
    "\n",
    "    # Join all sequences together into one long string, all uppercase\n",
    "    seq_concat = \"\".join(seqs).upper()\n",
    "\n",
    "    one_hot_map = np.identity(5)[:, :-1]\n",
    "\n",
    "    # Convert string into array of ASCII character codes;\n",
    "    base_vals = np.frombuffer(bytearray(seq_concat, \"utf8\"), dtype=np.int8)\n",
    "\n",
    "    # Anything that's not an A, C, G, or T gets assigned a higher code\n",
    "    base_vals[~np.isin(base_vals, np.array([65, 67, 71, 84]))] = 85\n",
    "\n",
    "    # Convert the codes into indices in [0, 4], in ascending order by code\n",
    "    _, base_inds = np.unique(base_vals, return_inverse=True)\n",
    "\n",
    "    # Get the one-hot encoding for those indices, and reshape back to separate\n",
    "    return one_hot_map[base_inds].reshape((len(seqs), seq_len, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filter_activation_motifs(filter_activations_path, reference_genome_path):\n",
    "    \"\"\"\n",
    "    Extracts the motifs that correspond to each filter. Returns an\n",
    "    F x W x 4 array, where F is the number of filters and W is the width\n",
    "    of each filter. The order of filters matches those in the saved HDF5/model.\n",
    "    \"\"\"\n",
    "    reader = h5py.File(filter_activations_path, \"r\")\n",
    "    activations_reader = reader[\"activations\"]\n",
    "    num_coords, two, num_windows, num_filters = activations_reader.shape\n",
    "    \n",
    "    assert two == 2\n",
    "    assert num_windows == input_length - filter_width + 1\n",
    "    \n",
    "    print(\"Importing coordinates...\")\n",
    "    coords = np.empty((num_coords, 3), dtype=object)\n",
    "    coords[:, 0] = reader[\"coords\"][\"coords_chrom\"][:].astype(str)\n",
    "    coords[:, 1] = reader[\"coords\"][\"coords_start\"][:]\n",
    "    coords[:, 2] = reader[\"coords\"][\"coords_end\"][:]\n",
    "    \n",
    "    print(\"Fetching one-hot sequences...\")\n",
    "    genome_reader = pyfaidx.Fasta(reference_genome_path)\n",
    "    one_hot_seqs = np.empty((num_coords, input_length, 4))\n",
    "    batch_size = 128\n",
    "    num_batches = int(np.ceil(num_coords / batch_size))\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        one_hot_seqs[batch_slice] = dna_to_one_hot([\n",
    "            genome_reader[chrom][start:end].seq for chrom, start, end in coords[batch_slice]\n",
    "        ])\n",
    "    \n",
    "    pfms = np.empty((num_filters, filter_width, 4))\n",
    "    for filter_index in range(num_filters):\n",
    "        print(\"Extracting motif for filter %d...\" % filter_index)\n",
    "    \n",
    "        print(\"\\tComputing maximum activation...\")\n",
    "        acts = activations_reader[:, :, :, filter_index]\n",
    "        max_act = np.max(acts)\n",
    "        \n",
    "        inds = np.where(acts >= 0.5 * max_act)\n",
    "        \n",
    "        windows, num_windows = np.zeros((filter_width, 4)), 0\n",
    "        for coord_index, strand_index, pos_index in tqdm.notebook.tqdm(\n",
    "            zip(*inds), total=len(inds[0]), desc=\"Extracting windows...\"\n",
    "        ):\n",
    "            if strand_index == 0:\n",
    "                window = one_hot_seqs[coord_index, pos_index : pos_index + filter_width]\n",
    "            else:\n",
    "                # Reverse complement; the positions are flipped\n",
    "                window = np.flip(\n",
    "                    one_hot_seqs[coord_index, input_length - filter_width - pos_index : input_length - pos_index],\n",
    "                    axis=(0, 1)\n",
    "                )\n",
    "            windows = windows + window\n",
    "            num_windows += 1\n",
    "        \n",
    "        pfms[filter_index] = windows / num_windows\n",
    "    \n",
    "    return pfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filter_influence(filter_activations_path):\n",
    "    \"\"\"\n",
    "    Extracts the influence of each filter by computing the difference\n",
    "    in cross entropy when each filter is nullified.\n",
    "    Returns an F-array, where F is the number of filters, containing the\n",
    "    change in average cross entropy (after nullification - before\n",
    "    nullification). The order of filters matches those in the saved\n",
    "    HDF5/model.\n",
    "    \"\"\"\n",
    "    reader = h5py.File(filter_activations_path, \"r\")\n",
    "    print(\"Reading in cross entropies...\")\n",
    "    before_null_cross_ents = reader[\"predictions\"][\"cross_ents\"][:]\n",
    "    after_null_cross_ents = reader[\"nullified_predictions\"][\"cross_ents\"][:]\n",
    "    \n",
    "    before_null = np.nanmean(before_null_cross_ents)\n",
    "    \n",
    "    num_filters = after_null_cross_ents.shape[1]\n",
    "    \n",
    "    influences = []\n",
    "    for filter_index in tqdm.notebook.trange(num_filters):\n",
    "        after_null = np.nanmean(after_null_cross_ents[:, filter_index])\n",
    "        influences.append(after_null - before_null)\n",
    "        \n",
    "    return np.array(influences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_activation_motifs(filter_pfms, filter_influences, path):\n",
    "    \"\"\"\n",
    "    Saves the filter-activation-derived PFMs and influence values.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        f.create_dataset(\"pfms\", data=filter_pfms, compression=\"gzip\")\n",
    "        f.create_dataset(\"influences\", data=filter_influences, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activation_motifs(path):\n",
    "    \"\"\"\n",
    "    Loads the filter-activation-derived PFMs and influence values.\n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        return f[\"pfms\"][:], f[\"influences\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract motifs from filter activations\n",
    "Extract the motifs derived from each filter, ranked by filter influence.\n",
    "\n",
    "Deriving a filter's motif: \n",
    "1. Identify the top 10000 most well-predicted input sequences, ranked by cross entropy\n",
    "2. For each window in each of these sequences, compute the filter activation for each 1st-layer filter\n",
    "3. A filter's motif is the aggregation of sequence windows which activate that filter to at least half its maximum activation (over the top 10000 most well-predicted inputs)\n",
    "\n",
    "Deriving a filter's influence:\n",
    "1. Identify the top 10000 most well-predicted input sequences, ranked by cross entropy\n",
    "2. Nullify each filter by setting it to the average activation over these 10000 most well-predicted inputs\n",
    "3. A filter's influence is the average change in cross entropy before and after nullification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_motifs = True\n",
    "if activation_motifs_cache_dir:\n",
    "    # Import if it exists\n",
    "    cache_path = os.path.join(activation_motifs_cache_dir, \"filter_activation_motifs.h5\")\n",
    "    if os.path.exists(cache_path) and os.stat(cache_path).st_size:\n",
    "        filter_pfms, filter_influences = load_activation_motifs(cache_path)\n",
    "        compute_motifs = False\n",
    "\n",
    "if compute_motifs:\n",
    "    # Extract PFMs of highly-activating sequences\n",
    "    filter_pfms = extract_filter_activation_motifs(filter_activations_path, reference_genome_path)\n",
    "\n",
    "    # Compute influence of each filter\n",
    "    filter_influences = compute_filter_influence(filter_activations_path)\n",
    "\n",
    "    if activation_motifs_cache_dir:\n",
    "        save_activation_motifs(filter_pfms, filter_influences, cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract motifs from filter weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the filter weights themselves\n",
    "filter_weights = np.load(filter_weights_path)\n",
    "assert len(filter_weights.shape) == 3\n",
    "assert filter_weights.shape[:2] == (filter_width, 4)\n",
    "filter_weights = np.transpose(filter_weights, axes=(2, 0, 1))  # Shape: F x W x 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filter-activating\"></a>\n",
    "### Motifs derived from filter-activating sequences\n",
    "\n",
    "For each filter, its motif is constructed by averaging all of the sequences that activate it at least to half of its maximal activation. We show the PWMs. The filters are ranked by influence (i.e. the average difference in prediction cross entropy when the filter is nullified--that is, replaced with its average activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"85%\"})\n",
    ")\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Rank\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Filter index\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Influence\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"PWM\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "body = []\n",
    "for i, filter_index in enumerate(np.flip(np.argsort(filter_influences))):\n",
    "    pwm = pfm_to_pwm(filter_pfms[filter_index])\n",
    "    if np.sum(pwm[:, [0, 2]]) < 0.5 * np.sum(pwm):\n",
    "        # Flip to purine-rich version\n",
    "        pwm = np.flip(pwm, axis=(0, 1))\n",
    "    fig = viz_sequence.plot_weights(pwm, figsize=(20, 4), return_fig=True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    body.append(\n",
    "        vdomh.tr(\n",
    "            vdomh.td(str(i + 1)),\n",
    "            vdomh.td(str(filter_index)),\n",
    "            vdomh.td(\"%.3f\" % filter_influences[filter_index]),\n",
    "            vdomh.td(figure_to_vdom_image(fig))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if activation_motifs_cache_dir:\n",
    "        # Save motif PWM\n",
    "        fig.savefig(os.path.join(activation_motifs_cache_dir, \"filter_activation_motif_%d.png\" % filter_index))\n",
    "\n",
    "display(vdomh.table(colgroup, header, vdomh.tbody(*body)))\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filter-weights\"></a>\n",
    "### Motifs derived from filter weights\n",
    "\n",
    "For each filter, we show its corresponding motif simply as the mean-normalized multiplicative weights in the filter. For consistency, we rank the filters by influence (as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"85%\"})\n",
    ")\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"Rank\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Filter index\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Influence\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Mean-normalized filter weights\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "body = []\n",
    "for i, filter_index in enumerate(np.flip(np.argsort(filter_influences))):\n",
    "    weights = filter_weights[filter_index]\n",
    "    weights = weights - np.mean(weights, axis=1, keepdims=True)\n",
    "    if np.sum(weights[:, [0, 2]]) < 0.5 * np.sum(weights):\n",
    "        # Flip to purine-rich version\n",
    "        weights = np.flip(weights, axis=(0, 1))\n",
    "    fig = viz_sequence.plot_weights(weights, figsize=(20, 4), return_fig=True)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    body.append(\n",
    "        vdomh.tr(\n",
    "            vdomh.td(str(i + 1)),\n",
    "            vdomh.td(str(filter_index)),\n",
    "            vdomh.td(\"%.3f\" % filter_influences[filter_index]),\n",
    "            vdomh.td(figure_to_vdom_image(fig))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if activation_motifs_cache_dir:\n",
    "        # Save motif PWM\n",
    "        fig.savefig(os.path.join(activation_motifs_cache_dir, \"filter_weight_motif_%d.png\" % filter_index))\n",
    "\n",
    "display(vdomh.table(colgroup, header, vdomh.tbody(*body)))\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
