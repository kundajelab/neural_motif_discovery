{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct links to results\n",
    "[Summary of motifs](#motif-summary)\n",
    "\n",
    "[Motif footprints and distributions](#footprint-dists)\n",
    "\n",
    "[Motif instance prevalences](#prevalence)\n",
    "\n",
    "[Co-occurrence statistics](#cooccur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/users/amtseng/tfmodisco/src/\"))\n",
    "from motif.read_motifs import pfm_to_pwm\n",
    "from util import figure_to_vdom_image, purine_rich_motif\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import sklearn.cluster\n",
    "import scipy.cluster.hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import vdom.helpers as vdomh\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters/fetch arguments\n",
    "tfm_results_cache_dir = os.environ[\"TFM_RESULTS_CACHE_DIR\"]\n",
    "motif_hits_cache_dir = os.environ[\"TFM_MOTIF_HITS_CACHE_DIR\"]\n",
    "if \"TFM_MOTIF_KEYS\" in os.environ:\n",
    "    motif_keys = os.environ[\"TFM_MOTIF_KEYS\"].split(\",\")\n",
    "else:\n",
    "    motif_keys = None\n",
    "\n",
    "print(\"Saved TF-MoDISco results cache: %s\" % tfm_results_cache_dir)\n",
    "print(\"Saved motif hits cache: %s\" % motif_hits_cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_file = os.path.join(tfm_results_cache_dir, \"all_motifs.h5\")\n",
    "if not motif_keys:\n",
    "    with h5py.File(motif_file, \"r\") as f:\n",
    "        motif_keys = sorted(f.keys(), key=lambda k: (int(k.split(\"_\")[0]), int(k.split(\"_\")[1])))\n",
    "        motif_keys = [key for key in motif_keys if key.startswith(\"0_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(seqlet_true_profs, seqlet_pred_profs, kmeans_clusters=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots the given profiles with a heatmap.\n",
    "    Arguments:\n",
    "        `seqlet_true_profs`: an N x O x 2 NumPy array of true profiles, either as raw\n",
    "            counts or probabilities (they will be normalized)\n",
    "        `seqlet_pred_profs`: an N x O x 2 NumPy array of predicted profiles, either as\n",
    "            raw counts or probabilities (they will be normalized)\n",
    "        `kmeans_cluster`: when displaying profile heatmaps, there will be this\n",
    "            many clusters\n",
    "        `save_path`: if provided, save the profile matrices here\n",
    "    Returns the figure.\n",
    "    \"\"\"\n",
    "    assert len(seqlet_true_profs.shape) == 3\n",
    "    assert seqlet_true_profs.shape == seqlet_pred_profs.shape\n",
    "    num_profs, width, _ = seqlet_true_profs.shape\n",
    "\n",
    "    # First, normalize the profiles along the output profile dimension\n",
    "    def normalize(arr, axis=0):\n",
    "        arr_sum = np.sum(arr, axis=axis, keepdims=True)\n",
    "        arr_sum[arr_sum == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return arr / arr_sum\n",
    "    true_profs_norm = normalize(seqlet_true_profs, axis=1)\n",
    "    pred_profs_norm = normalize(seqlet_pred_profs, axis=1)\n",
    "\n",
    "    # Compute the mean profiles across all examples\n",
    "    true_profs_mean = np.mean(true_profs_norm, axis=0)\n",
    "    pred_profs_mean = np.mean(pred_profs_norm, axis=0)\n",
    "\n",
    "    # Perform k-means clustering on the predicted profiles, with the strands pooled\n",
    "    kmeans_clusters = max(5, num_profs // 50)  # Set number of clusters based on number of profiles, with minimum\n",
    "    kmeans = sklearn.cluster.KMeans(n_clusters=kmeans_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(\n",
    "        np.reshape(pred_profs_norm, (pred_profs_norm.shape[0], -1))\n",
    "    )\n",
    "\n",
    "    # Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "            scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Order the profiles so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "\n",
    "    # Compute a matrix of profiles, normalized to the maximum height, ordered by clusters\n",
    "    def make_profile_matrix(flat_profs, order_inds):\n",
    "        matrix = flat_profs[order_inds]\n",
    "        maxes = np.max(matrix, axis=1, keepdims=True)\n",
    "        maxes[maxes == 0] = 1  # If 0, keep 0 as the quotient instead of dividing by 0\n",
    "        return matrix / maxes\n",
    "    true_matrix = make_profile_matrix(true_profs_norm, cluster_inds)\n",
    "    pred_matrix = make_profile_matrix(pred_profs_norm, cluster_inds)\n",
    "    \n",
    "    if save_path:\n",
    "        np.savez_compressed(\n",
    "            true_profs_mean=true_profs_mean, pred_profs_mean=pred_profs_mean,\n",
    "            true_matrix=true_matrix, pred_matrix=pred_matrix\n",
    "        )\n",
    "\n",
    "    # Create a figure with the right dimensions\n",
    "    mean_height = 4\n",
    "    heatmap_height = min(num_profs * 0.004, 8)\n",
    "    fig_height = mean_height + (2 * heatmap_height)\n",
    "    fig, ax = plt.subplots(\n",
    "        3, 2, figsize=(16, fig_height), sharex=True,\n",
    "        gridspec_kw={\n",
    "            \"width_ratios\": [1, 1],\n",
    "            \"height_ratios\": [mean_height / fig_height, heatmap_height / fig_height, heatmap_height / fig_height]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Plot the average predictions\n",
    "    ax[0, 0].plot(true_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 0].plot(-true_profs_mean[:, 1], color=\"darkorange\")\n",
    "    ax[0, 1].plot(pred_profs_mean[:, 0], color=\"darkslateblue\")\n",
    "    ax[0, 1].plot(-pred_profs_mean[:, 1], color=\"darkorange\")\n",
    "\n",
    "    # Set axes on average predictions\n",
    "    max_mean_val = max(np.max(true_profs_mean), np.max(pred_profs_mean))\n",
    "    mean_ylim = max_mean_val * 1.05  # Make 5% higher\n",
    "    ax[0, 0].set_title(\"True profiles\")\n",
    "    ax[0, 0].set_ylabel(\"Average probability\")\n",
    "    ax[0, 1].set_title(\"Predicted profiles\")\n",
    "    for j in (0, 1):\n",
    "        ax[0, j].set_ylim(-mean_ylim, mean_ylim)\n",
    "        ax[0, j].label_outer()\n",
    "\n",
    "    # Plot the heatmaps\n",
    "    ax[1, 0].imshow(true_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[1, 1].imshow(pred_matrix[:, :, 0], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Blues\")\n",
    "    ax[2, 0].imshow(true_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "    ax[2, 1].imshow(pred_matrix[:, :, 1], interpolation=\"nearest\", aspect=\"auto\", cmap=\"Oranges\")\n",
    "\n",
    "    # Set axes on heatmaps\n",
    "    for i in (1, 2):\n",
    "        for j in (0, 1):\n",
    "            ax[i, j].set_yticks([])\n",
    "            ax[i, j].set_yticklabels([])\n",
    "            ax[i, j].label_outer()\n",
    "    width = true_matrix.shape[1]\n",
    "    delta = 100\n",
    "    num_deltas = (width // 2) // delta\n",
    "    labels = list(range(max(-width // 2, -num_deltas * delta), min(width // 2, num_deltas * delta) + 1, delta))\n",
    "    tick_locs = [label + max(width // 2, num_deltas * delta) for label in labels]\n",
    "    for j in (0, 1):\n",
    "        ax[2, j].set_xticks(tick_locs)\n",
    "        ax[2, j].set_xticklabels(labels)\n",
    "        ax[2, j].set_xlabel(\"Distance from seqlet center (bp)\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summit_dists(summit_dists):\n",
    "    \"\"\"\n",
    "    Plots the distribution of seqlet distances to summits.\n",
    "    Arguments:\n",
    "        `summit_dists`: the array of distances as returned by\n",
    "            `get_summit_distances`\n",
    "    Returns the figure.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    num_bins = max(len(summit_dists) // 30, 20)\n",
    "    plt.hist(summit_dists, bins=num_bins, color=\"purple\")\n",
    "    plt.title(\"Histogram of distance of seqlets to peak summits\")\n",
    "    plt.xlabel(\"Signed distance from seqlet center to nearest peak summit (bp)\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_matrix_indices(matrix, num_clusters):\n",
    "    \"\"\"\n",
    "    Clusters matrix using k-means. Always clusters on the first\n",
    "    axis. Returns the indices needed to optimally order the matrix\n",
    "    by clusters.\n",
    "    \"\"\"\n",
    "    if len(matrix) == 1:\n",
    "        # Don't cluster at all\n",
    "        return np.array([0])\n",
    "\n",
    "    num_clusters = min(num_clusters, len(matrix))\n",
    "    \n",
    "    # Perform k-means clustering\n",
    "    kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=num_clusters)\n",
    "    cluster_assignments = kmeans.fit_predict(matrix)\n",
    "\n",
    "    # Perform hierarchical clustering on the cluster centers to determine optimal ordering\n",
    "    kmeans_centers = kmeans.cluster_centers_\n",
    "    cluster_order = scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(\n",
    "            scipy.cluster.hierarchy.linkage(kmeans_centers, method=\"centroid\"), kmeans_centers\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Order the peaks so that the cluster assignments follow the optimal ordering\n",
    "    cluster_inds = []\n",
    "    for cluster_id in cluster_order:\n",
    "        cluster_inds.append(np.where(cluster_assignments == cluster_id)[0])\n",
    "    cluster_inds = np.concatenate(cluster_inds)\n",
    "    return cluster_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_violin_plot(ax, dist_list, colors):\n",
    "    \"\"\"\n",
    "    Creates a violin plot on the given instantiated axes.\n",
    "    `dist_list` is a list of vectors. `colors` is a parallel\n",
    "    list of colors for each violin.\n",
    "    \"\"\"\n",
    "    num_perfs = len(dist_list)\n",
    "\n",
    "    q1, med, q3 = np.stack([\n",
    "        np.nanpercentile(data, [25, 50, 70], axis=0) for data in dist_list\n",
    "    ], axis=1)\n",
    "    iqr = q3 - q1\n",
    "    lower_outlier = q1 - (1.5 * iqr)\n",
    "    upper_outlier = q3 + (1.5 * iqr)\n",
    "\n",
    "\n",
    "    sorted_clipped_data = [  # Remove outliers based on outlier rule\n",
    "        np.sort(vec[(vec >= lower_outlier[i]) & (vec <= upper_outlier[i])])\n",
    "        for i, vec in enumerate(dist_list)\n",
    "    ]\n",
    "\n",
    "    plot_parts = ax.violinplot(\n",
    "        sorted_clipped_data, showmeans=False, showmedians=False, showextrema=False\n",
    "    )\n",
    "    violin_parts = plot_parts[\"bodies\"]\n",
    "    for i in range(num_perfs):\n",
    "        violin_parts[i].set_facecolor(colors[i])\n",
    "        violin_parts[i].set_edgecolor(colors[i])\n",
    "        violin_parts[i].set_alpha(0.7)\n",
    "\n",
    "    inds = np.arange(1, num_perfs + 1)\n",
    "    ax.vlines(inds, q1, q3, color=\"black\", linewidth=5, zorder=1)\n",
    "    ax.scatter(inds, med, marker=\"o\", color=\"white\", s=30, zorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"motif-summary\"></a>\n",
    "## Summary of motifs\n",
    "\n",
    "Motifs are trimmed based on information content, and presented in descending order by number of supporting seqlets. The motifs are separated by metacluster. The motifs are presented as PWMs, CWMs, and eCWMs. We show the forward orientation, which is defined as the orientation that is richer in purines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colgroup = vdomh.colgroup(\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"5%\"}),\n",
    "    vdomh.col(style={\"width\": \"30%\"}),\n",
    "    vdomh.col(style={\"width\": \"30%\"}),\n",
    "    vdomh.col(style={\"width\": \"30%\"})\n",
    ")\n",
    "header = vdomh.thead(\n",
    "    vdomh.tr(\n",
    "        vdomh.th(\"ID\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"Seqlets\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"PWM\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"CWM\", style={\"text-align\": \"center\"}),\n",
    "        vdomh.th(\"eCWM\", style={\"text-align\": \"center\"})\n",
    "    )\n",
    ")\n",
    "\n",
    "body = []\n",
    "\n",
    "motif_file = os.path.join(tfm_results_cache_dir, \"all_motifs.h5\")\n",
    "with h5py.File(motif_file, \"r\") as f:\n",
    "    for motif_key in motif_keys:\n",
    "        pfm, cwm, hcwm = f[motif_key][\"pfm_trimmed\"][:], f[motif_key][\"cwm_trimmed\"][:], f[motif_key][\"hcwm_trimmed\"][:]\n",
    "        pwm = pfm_to_pwm(pfm)\n",
    "        \n",
    "        if np.sum(pwm[:, [0, 2]]) > 0.5 * np.sum(pwm):\n",
    "            # Forward is purine-rich, reverse-complement is pyrimidine-rich\n",
    "            pass\n",
    "        else:\n",
    "            pwm, cwm, hcwm = np.flip(pwm), np.flip(cwm), np.flip(hcwm)\n",
    "            \n",
    "        pwm_fig = viz_sequence.plot_weights(pwm, figsize=(20, 4), return_fig=True)\n",
    "        pwm_fig.tight_layout()\n",
    "        cwm_fig = viz_sequence.plot_weights(cwm, figsize=(20, 4), return_fig=True)\n",
    "        cwm_fig.tight_layout()\n",
    "        hcwm_fig = viz_sequence.plot_weights(hcwm, figsize=(20, 4), return_fig=True)\n",
    "        hcwm_fig.tight_layout()\n",
    "        \n",
    "        seqlets_file = os.path.join(tfm_results_cache_dir, \"%s_seqlets.npz\" % motif_key)\n",
    "        with np.load(seqlets_file) as g:\n",
    "            num_seqlets = len(g[\"seqlet_seqs\"])\n",
    "        \n",
    "        body.append(\n",
    "            vdomh.tr(\n",
    "                vdomh.td(motif_key),\n",
    "                vdomh.td(str(num_seqlets)),\n",
    "                vdomh.td(figure_to_vdom_image(pwm_fig)),\n",
    "                vdomh.td(figure_to_vdom_image(cwm_fig)),\n",
    "                vdomh.td(figure_to_vdom_image(hcwm_fig))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "display(vdomh.table(colgroup, header, vdomh.tbody(*body)))\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"footprint-dists\"></a>\n",
    "## Motif footprints and distributions\n",
    "For each motif, we show the binding footprint as the set of observed and model-predicted profiles surrounding instances of the motif. We also show the distribution of distances between instances of the motif and the nearest called peak summit. For clarity, we reproduce the CWM as shown above for each motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(motif_file, \"r\") as f:\n",
    "    for motif_key in motif_keys:\n",
    "        display(vdomh.h4(\"Motif %s\" % motif_key))\n",
    "        \n",
    "        cwm = f[motif_key][\"cwm_trimmed\"][:]\n",
    "        viz_sequence.plot_weights(purine_rich_motif(cwm), figsize=(10, 2), return_fig=True)\n",
    "        plt.show()\n",
    "        \n",
    "        seqlets_file = os.path.join(tfm_results_cache_dir, \"%s_seqlets.npz\" % motif_key)\n",
    "        with np.load(seqlets_file) as g:\n",
    "            seqlet_true_profs, seqlet_pred_profs = g[\"seqlet_true_profs\"], g[\"seqlet_pred_profs\"]\n",
    "            plot_profiles(\n",
    "                # Flatten to NT x O x 2\n",
    "                np.reshape(seqlet_true_profs, (-1, seqlet_true_profs.shape[2], seqlet_true_profs.shape[3])),\n",
    "                np.reshape(seqlet_pred_profs, (-1, seqlet_pred_profs.shape[2], seqlet_pred_profs.shape[3]))\n",
    "            )\n",
    "            plot_summit_dists(g[\"summit_dists\"])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prevalence\"></a>\n",
    "## Motif instance prevalences\n",
    "We show a cumulative distribution of how many motif instances are found per peak. We also show a bar plot of how many instances of each motif were found across all peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_path = os.path.join(motif_hits_cache_dir, \"filtered_hits.tsv\")\n",
    "peak_hits_path = os.path.join(motif_hits_cache_dir, \"peak_matched_hits.tsv\")\n",
    "\n",
    "with h5py.File(motif_file, \"r\") as f:\n",
    "    all_motif_keys = sorted(f.keys())\n",
    "\n",
    "hit_table = pd.read_csv(hits_path, sep=\"\\t\", header=0, index_col=0)\n",
    "peak_hit_table = pd.read_csv(peak_hits_path, sep=\"\\t\", header=0, index_col=False)\n",
    "peak_hit_table[\"filtered_hit_indices\"] = peak_hit_table[\"filtered_hit_indices\"].astype(str)\n",
    "\n",
    "motif_key_to_motif_index = {all_motif_keys[i] : i for i in range(len(all_motif_keys))}\n",
    "hit_table[\"motif_index\"] = hit_table[\"key\"].apply(lambda k: motif_key_to_motif_index[k]).values\n",
    "\n",
    "# Construct N x M array for N peaks and M motifs, holding the counts of each motif in each peak\n",
    "peak_hit_counts = np.zeros((len(peak_hit_table), len(all_motif_keys)), dtype=int)\n",
    "for _, row in peak_hit_table.iterrows():\n",
    "    peak_ind, hit_inds = row[\"peak_index\"], row[\"filtered_hit_indices\"]\n",
    "    if hit_inds != \"nan\":\n",
    "        hit_inds = np.array([int(x) for x in hit_inds.split(\",\")])\n",
    "        for hit_ind in hit_inds:\n",
    "            peak_hit_counts[peak_ind, hit_table.loc[hit_ind][\"motif_index\"]] += 1\n",
    "            \n",
    "# Limit the peak hit counts to only the motifs we care about\n",
    "keep_inds = np.array([i for i in range(len(all_motif_keys)) if all_motif_keys[i] in motif_keys])\n",
    "peak_hit_counts = peak_hit_counts[:, keep_inds]\n",
    "\n",
    "# Number of motif hits per peak\n",
    "motifs_per_peak = np.sum(peak_hit_counts, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "bins = np.concatenate([np.arange(np.max(motifs_per_peak) + 1), [np.inf]])\n",
    "ax.hist(motifs_per_peak, bins=bins, density=True, histtype=\"step\", cumulative=True)\n",
    "ax.set_title(\"Cumulative distribution of number of motif hits per peak\")\n",
    "ax.set_xlabel(\"Number of motifs k in peak\")\n",
    "ax.set_ylabel(\"Proportion of peaks with at least k motifs\")\n",
    "plt.show()\n",
    "\n",
    "# Number of peaks with each motif\n",
    "frac_peaks_with_motif = np.sum(peak_hit_counts > 0, axis=0) / len(peak_hit_counts)\n",
    "labels = np.array(motif_keys)\n",
    "sorted_inds = np.flip(np.argsort(frac_peaks_with_motif))\n",
    "frac_peaks_with_motif = frac_peaks_with_motif[sorted_inds]\n",
    "labels = labels[sorted_inds]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.bar(np.arange(len(labels)), frac_peaks_with_motif)\n",
    "ax.set_title(\"Proportion of peaks with each motif\")\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cooccur\"></a>\n",
    "## Co-occurrence statistics\n",
    "We show the significance of motifs co-occurring with each other in peaks. This can two motifs that tend to co-occur each each other, or a single motif that tends to occur multiple times in single peaks. We show a heatmap of co-occurrence significance across all pairs of motifs. For significantly co-occurring motifs, we compute the distribution of distances between motifs in peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_file_path = os.path.join(motif_hits_cache_dir, \"cooccurrences.h5\")\n",
    "with h5py.File(cooccurrence_file_path, \"r\") as f:\n",
    "    pval_matrix = f[\"pvals\"][:]\n",
    "    \n",
    "with h5py.File(motif_file, \"r\") as f:\n",
    "    all_motif_keys = sorted(f.keys())\n",
    "    \n",
    "# Limit matrix to the keys we want\n",
    "keep_inds = np.array([i for i in range(len(pval_matrix)) if all_motif_keys[i] in motif_keys])\n",
    "pval_matrix = pval_matrix[keep_inds][:, keep_inds]\n",
    "\n",
    "# Cluster by p-value\n",
    "num_motifs = len(pval_matrix)\n",
    "inds = cluster_matrix_indices(pval_matrix, max(5, num_motifs // 4))\n",
    "pval_matrix_ordered = pval_matrix[inds][:, inds]\n",
    "motif_keys_ordered = np.array(motif_keys)[inds]\n",
    "\n",
    "# Plot the p-value matrix\n",
    "\n",
    "fig_width = max(5, num_motifs)\n",
    "p_fig, ax = plt.subplots(figsize=(fig_width, fig_width))\n",
    "\n",
    "# Replace 0s with minimum value (we'll label them properly later)\n",
    "zero_mask = pval_matrix_ordered == 0\n",
    "non_zeros = pval_matrix_ordered[~zero_mask]\n",
    "if not len(non_zeros):\n",
    "    logpval_matrix = np.tile(np.inf, pval_matrix_ordered.shape)\n",
    "else:\n",
    "    min_val = np.min(pval_matrix_ordered[~zero_mask])\n",
    "    pval_matrix_ordered[zero_mask] = min_val\n",
    "    logpval_matrix = -np.log10(pval_matrix_ordered)\n",
    "\n",
    "hmap = ax.imshow(logpval_matrix[:num_motifs, :num_motifs])\n",
    "\n",
    "ax.set_xticks(np.arange(num_motifs))\n",
    "ax.set_yticks(np.arange(num_motifs))\n",
    "ax.set_xticklabels(motif_keys_ordered[:num_motifs], rotation=45)\n",
    "ax.set_yticklabels(motif_keys_ordered[:num_motifs])\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(num_motifs):\n",
    "    for j in range(num_motifs):\n",
    "        if zero_mask[i, j]:\n",
    "            text = \"Inf\"\n",
    "        else:\n",
    "            text = \"%.2f\" % np.abs(logpval_matrix[i, j])\n",
    "        ax.text(j, i, text, ha=\"center\", va=\"center\")\n",
    "p_fig.colorbar(hmap, orientation=\"horizontal\")\n",
    "\n",
    "ax.set_title(\"-log(p) significance of peaks with both motifs\")\n",
    "p_fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_dist_path = os.path.join(motif_hits_cache_dir, \"intermotif_dists.h5\")\n",
    "if os.path.exists(cooccurrence_dist_path):\n",
    "    with h5py.File(cooccurrence_dist_path, \"r\") as f:\n",
    "        distance_dict = {}\n",
    "        for key in f.keys():\n",
    "            distance_dict[tuple(key.split(\":\"))] = f[key][:]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=len(motif_keys), ncols=len(motif_keys), figsize=(len(motif_keys) * 4, len(motif_keys) * 4)\n",
    "    )\n",
    "    if type(ax) is not np.ndarray:\n",
    "        ax = np.array([[ax]])\n",
    "\n",
    "    # Map motif key to axis index\n",
    "    key_to_index = dict(zip(motif_keys_ordered, np.arange(len(motif_keys_ordered))))\n",
    "\n",
    "    def clean_subplot(ax):\n",
    "        # Do this instead of ax.axis(\"off\"), which would also remove any\n",
    "        # axis labels\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "        for orient in (\"top\", \"bottom\", \"left\", \"right\"):\n",
    "            ax.spines[orient].set_visible(False)\n",
    "\n",
    "    # Create violins\n",
    "    for i in range(len(motif_keys)):\n",
    "        for j in range(i, len(motif_keys)):\n",
    "            key_1, key_2 = motif_keys_ordered[i], motif_keys_ordered[j]\n",
    "            key_pair, rev_key_pair = (key_1, key_2), (key_2, key_1)\n",
    "            axis_1, axis_2 = key_to_index[key_1], key_to_index[key_2]\n",
    "            # Always plot lower triangle\n",
    "            if axis_1 < axis_2:\n",
    "                axis_1, axis_2 = axis_2, axis_1\n",
    "\n",
    "            if key_pair in distance_dict or rev_key_pair in distance_dict:\n",
    "                if rev_key_pair in distance_dict:\n",
    "                    key_pair = rev_key_pair\n",
    "                dist = distance_dict[key_pair] \n",
    "                create_violin_plot(ax[axis_1, axis_2], [dist], [\"mediumorchid\"])\n",
    "                ax[axis_1, axis_2].set_xticks([])  # Remove x-axis labels, as they don't mean much\n",
    "                if axis_1 != axis_2:\n",
    "                    # If off diagonal, clean the axes of the symmetric cell\n",
    "                    clean_subplot(ax[axis_2, axis_1])\n",
    "            else:\n",
    "                clean_subplot(ax[axis_1, axis_2])\n",
    "                clean_subplot(ax[axis_2, axis_1])\n",
    "\n",
    "    # Make motif labels\n",
    "    for i in range(len(motif_keys)):\n",
    "        ax[i, 0].set_ylabel(motif_keys_ordered[i])\n",
    "        ax[-1, i].set_xlabel(motif_keys_ordered[i])\n",
    "\n",
    "    # Remove x-axis labels/ticks\n",
    "    ax[-1, -1].set_xticks([])\n",
    "    fig.suptitle(\"Distance distributions between significantly co-occurring motifs\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
