### `raw/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/raw/`
- `ENCODE/`
	- Contains ChIP-seq data fetched from ENCODE
	- `encode_tf_chip_experiments.tsv`
		- A metadata file listing various experiments from ENCODE, filtered for those that are TF-ChIPseq experiments, aligned to hg38, and status released (and not retracted, for example)
		- Downloaded with the following command:
			```
			wget -O encode_tf_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=TF+ChIP-seq&assembly=GRCh38"
			```
	- `encode_control_chip_experiments.tsv`
		- A metadata file listing various control experiments from ENCODE (i.e. for a particular cell-line, a ChIP-seq experiment with no immunoprecipitation), filtered for those that are aligned to hg38 and have a status of released
		- Downloaded with the following command:
			```
			wget -O encode_control_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=Control+ChIP-seq&assembly=GRCh38"
			```
	- `encode_tf_chip_files.tsv`
		- A metadata file listing various ENCODE files, filtered for those that are aligned to hg38, status released, and of the relevant output types (i.e. unfiltered alignments, called peaks, and optimal IDR-filtered peaks)
		- Downloaded with the following commands:
			```
			FIRST=1; for otype in "unfiltered alignments" "peaks and background as input for IDR" "optimal IDR thresholded peaks"; do wget -O - "https://www.encodeproject.org/report.tsv?type=File&status=released&assembly=GRCh38&output_type=$otype" | awk -v first=$FIRST '(first == 1) || NR > 2' >> encode_tf_chip_files.tsv; FIRST=2; done
			```
		- The API for the download of the experiment and files metadata is described [here](https://app.swaggerhub.com/apis-docs/encodeproject/api/basic_search/)
	- The files for each TF are downloaded by `download_ENCODE_data.py`

### `interim/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/interim/`
- Raw data that has been processed to an intermediate form
- `ENCODE/`
	- There is a subdirectory for each TF; each such directory contains a set of BigWigs and peak files for that TF
		- Labels are generated by the alignments and peaks from `raw/`, using `generate_ENCODE_profile_labels.sh`
		- In addition to bedTools, this script also requires bedGraphToBigWig from UCSC Tools, as well as the [hg38 chromosome sizes with chrEBV included](https://github.com/ENCODE-DCC/encValData/blob/master/GRCh38/GRCh38_EBV.chrom.sizes)
		- Note that we start with the _unfiltered_ alignments from ENCODE and filter them ourselves using samtools
			- The filtering process we do is identical, but we keep duplicate reads, because those can be useful for profile prediction

- `ZNF248/`
	- Data that's already been preprocessed somewhat by Abhi
	- `ChIPseq`
		- Data from ENCODE experiment [ENCSR338SEM](https://www.encodeproject.org/experiments/ENCSR338SEM/)
		- `ZNF248_ENCSR338SEM_HEK293_{neg,pos}.bw` copied from `/oak/stanford/groups/akundaje/manyu/C2H2_ZNF_project/train_profile_models_2020/process_datasets/ENCODE_datasets/ENCSR338SEM/{neg,pos}_strand.bw`
			- Note that the BigWigs were processed using the same pipeline as the other TFs (same flags), starting from unfiltered alignments ENCFF447DQM and ENCFF793HDZ
		- `ZNF248_ENCSR338SEM_HEK293_all_peakints.bed.gz` is zipped version of `/oak/stanford/groups/akundaje/manyu/C2H2_ZNF_project/train_profile_models_2020/process_datasets/ENCODE_datasets/ENCSR338SEM/spp_idr.bed`, since that is IDR thresholded peaks for TFs
			- Note that Abhi used `spp_macs2_merged_idr.bed` for training his models
		- `control_pooled_HEK293_{neg,pos}.bw` copied from `/oak/stanford/groups/akundaje/manyu/C2H2_ZNF_project/train_profile_models_2020/process_datasets/ENCODE_datasets/pooled_control/{neg,pos}_strand.bw`
			- Note that these are simply the pooled alignments from ENCSR157LMX, ENCSR274OGE, ENCSR342AGU, ENCSR354FNX, ENCSR429LAP, ENCSR688NWK (these six are the control experiments listed for ENCSR338SEM)
				- Note this is alignments, not unfiltered alignments
	- `ChIPexo`
		- Original data from [this paper](https://www.nature.com/articles/nature21683)
		- Data processed by Georgi
		- Peaks and BigWigs copied from `/oak/stanford/groups/akundaje/manyu/C2H2_ZNF_project/ChipExo_modeling/TFs/ZNF248/`
			- Original files from `/oak/stanford/groups/akundaje/marinovg/TF-models/2018-09-12-KZNF-ChIP-exo-datasets-GSE78099/ZNF248-SRR5197087/`
			- Negative track is `ZNF248-SRR5197087.hg20-male.36mers.unique.5p.counts.minus.absValue.bigWig`, positive track is `ZNF248-SRR5197087.hg20-male.36mers.unique.5p.counts.plus.bigWig`, and IDR peaks are `ZNF248-SRR5197087.hg20-male.36mers.unique.MACS-2.1.0.shift75_extsize150.p1e-1_peaks.narrowPeak.narrowPeak.sorted.IDR.0.05-noBL.gz`
		- There are no controls

### `processed/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/processed/`
- `ENCODE/`
	- Processed data ready for profile models
	- `labels/`
		- HDF5 containing BigWig tracks for training, and BED files in NarrowPeak format for the peaks
			- The BED files are copied directly from `interim/`
		- Made from BigWigs in `interim/` using `create_ENCODE_TFChIP_profile_hdf5.py/`
	- `config/`
		- Training configuration files like paths to training data in `labels/`, and parameter configurations like number of tasks
	- `chrom_splits.json`
		- This defines the chromosome splits for hg38, based on chromosome size, for appropriate training, validation, and test sets

- `ZNF248/`
	- Like each of the subdirectories in `ENCODE/`

- `AI-TAC/`
	- Contains data and models for [this paper](https://www.biorxiv.org/content/10.1101/2019.12.21.885814v1)
	- `data/`
		- Data used to train AI-TAC models
		- `cell_type_array.npy` (shape N x 81)
			- Normalized peak heights for all cell types; this is the target output
			- For each input sequence, the model tries to learn an output for each of the 81 cell types that correlates with the peak heights here
		- `one_hot_seqs.npy` (shape N x 4 x 251)
			- One-hot encoded sequences
		- `peak_names.npy` (shape N)
			- ID assigned to each peak (open chromatin region)
		- `chromosomes.npy` (shape N)
			- Chromosome of each peak, for easily splitting data
		- `cell_type_names.npy` (shape N x 3)
			- Names of each immune cell type for each of the 81 cell types, along with lineage designation of each cell type
	- `models/`
		- `AITAC.ckpt`
			- The saved PyTorch model state for the main AITAC model
			- The model architecture is `ConvNet`, defined [here](https://github.com/smaslova/AI-TAC/blob/master/code/aitac.py)
		- `keras_sigmoid.*`
			- The weights and architecture for a Keras model that is the equivalent of the main AI-TAC model, but retrained with a sigmoid final layer to restrict the outputs between 0 and 1

- `mappability/`
	- BigWig tracks of read mappabilities, using UMAP, for various k-mer lengths
	- Downloaded from `http://hgdownload.soe.ucsc.edu/gbdb/hg38/hoffmanMappability/k24.Umap.MultiTrackMappability.bw` and `http://hgdownload.soe.ucsc.edu/gbdb/hg38/hoffmanMappability/k100.Umap.MultiTrackMappability.bw`

- `motif_databases/`
	- Known motifs downloaded from other sources
	- `JASPAR2020_CORE_vertebrates_non-redundant_pfms_meme.txt`
		- Vertebrate motifs from JASPAR in MEME format (from [here](http://jaspar.genereg.net/downloads/))
		- The motif IDs have been concatenated with the names with an underscore using: `awk '{if ($1 == "MOTIF") {print $1 " " $2 "_" $3} else {print $0}}'`
	- `HOCOMOCOv11_full_HUMAN_mono_meme_format.meme`
		- HOCOMOCO v11 human motifs in MEME format (from [here](https://hocomoco11.autosome.ru/downloads_v11))
	- `HOCOMOCO_JASPAR_motifs.txt`
		- Combination of both JASPAR and HOCOMOCO motifs
