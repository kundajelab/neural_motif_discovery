### `raw/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/raw/`
- `ENCODE/`
	- Contains ChIP-seq data fetched from ENCODE
	- `encode_tf_chip_experiments.tsv`
		- A metadata file listing various experiments from ENCODE, filtered for those that are TF-ChIPseq experiments, aligned to hg38, and status released (and not retracted, for example)
		- Downloaded with the following command:
			```
			wget -O encode_tf_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=TF+ChIP-seq&assembly=GRCh38"
			```
	- `encode_control_chip_experiments.tsv`
		- A metadata file listing various control experiments from ENCODE (i.e. for a particular cell-line, a ChIP-seq experiment with no immunoprecipitation), filtered for those that are aligned to hg38 and have a status of released
		- Downloaded with the following command:
			```
			wget -O encode_control_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=Control+ChIP-seq&assembly=GRCh38"
			```
	- `encode_tf_chip_files.tsv`
		- A metadata file listing various ENCODE files, filtered for those that are aligned to hg38, status released, and of the relevant output types (i.e. unfiltered alignments, called peaks, and optimal IDR-filtered peaks)
		- Downloaded with the following commands:
			```
			FIRST=1; for otype in "unfiltered alignments" "peaks and background as input for IDR" "optimal IDR thresholded peaks"; do wget -O - "https://www.encodeproject.org/report.tsv?type=File&status=released&assembly=GRCh38&output_type=$otype" | awk -v first=$FIRST '(first == 1) || NR > 2' >> encode_tf_chip_files.tsv; FIRST=2; done
			```
		- The API for the download of the experiment and files metadata is described [here](https://app.swaggerhub.com/apis-docs/encodeproject/api/basic_search/)
	- The files for each TF are downloaded by `download_ENCODE_data.py`

### `interim/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/interim/`
- Raw data that has been processed to an intermediate form
- `ENCODE/`
	- Processed data needed to train profile models
	- Labels generated by the alignments and peaks from `raw/`, using `generate_ENCODE_profile_labels.sh`
		- In addition to bedTools, this script also requires bedGraphToBigWig from UCSC Tools, as well as the [hg38 chromosome sizes with chrEBV included](https://github.com/ENCODE-DCC/encValData/blob/master/GRCh38/GRCh38_EBV.chrom.sizes)
		- Note that we start with the _unfiltered_ alignments from ENCODE and filter them ourselves
			- The filtering process we do is identical, but we keep duplicate reads, because those can be useful for profile prediction
	- `randomized_labels/`
	- `config/`
		- Config files for training specific TF datasets
- `BPNet`
	- Data from the orignal BPNet paper
	- Originally downloaded from here:
		- Oct4
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Oct4/counts.pos.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Oct4/counts.neg.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Oct4/idr-optimal-set.summit.bed.gz
		- Sox2
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Sox2/counts.pos.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Sox2/counts.neg.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Sox2/idr-optimal-set.summit.bed.gz
		- Nanog
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Nanog/counts.pos.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Nanog/counts.neg.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Nanog/idr-optimal-set.summit.bed.gz
		- Nanog
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Klf4/counts.pos.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Klf4/counts.neg.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/Klf4/idr-optimal-set.summit.bed.gz
		- Control tracks (the above 4 are all the same cell line)
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/patchcap/counts.pos.bw`
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/chip-nexus/patchcap/counts.neg.bw`
		- Fasta file
			- `/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/data/mm10_no_alt_analysis_set_ENCODE.fasta`
	- The peak files were split into training and holdout sets using `split_peaks.sh`

### `processed/`
Links to `/mnt/lab_data2/amtseng/tfmodisco/data/processed/`
- Intermediate data that has been processed and finalized into TileDB databases
	- TileDB databases made by `create_ENCODE_profile_dbs.sh`
- TileDB databases are organized by ENCODE experiment; see the README in these directories to see what eac experiment is
